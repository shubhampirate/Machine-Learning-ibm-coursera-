{"cells":[{"cell_type":"markdown","metadata":{},"source":["<p style=\"text-align:center\">\n","    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML241ENSkillsNetwork31576874-2022-01-01\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n","    </a>\n","</p>\n"]},{"cell_type":"markdown","metadata":{},"source":["# **K Nearest Neighbor**\n"]},{"cell_type":"markdown","metadata":{},"source":["Estimated time needed: **30** minutes\n"]},{"cell_type":"markdown","metadata":{},"source":["In this lab, you will learn about and practice the K Nearest Neighbor (KNN) model. KNN is a straightforward but very effective model that can be used for both classification and regression tasks. If the feature space is not very large, KNN can be a high-interpretable model because you can explain and understand how a prediction is made by looking at its nearest neighbors.\n"]},{"cell_type":"markdown","metadata":{},"source":["We will be using a tumor sample dataset containing lab test results about tumor samples. The objective is to classify whether a tumor is malicious (cancer) or benign. As such, it is a typical binary classification task.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Objectives\n"]},{"cell_type":"markdown","metadata":{},"source":["After completing this lab, you will be able to:\n"]},{"cell_type":"markdown","metadata":{},"source":["*   Train KNN models with different neighbor hyper-parameters\n","*   Evaluate KNN models on classification tasks\n","*   Tune the number of neighbors and find the optimized one for a specific task\n"]},{"cell_type":"markdown","metadata":{},"source":["***\n"]},{"cell_type":"markdown","metadata":{},"source":["First, let's install `seaborn` for visualization tasks and import required libraries for this lab.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n","# !mamba install -qy pandas==1.3.3 numpy==1.21.2 ipywidgets==7.4.2 scipy==7.4.2 tqdm==4.62.3 matplotlib==3.5.0 seaborn==0.9.0\n","# Note: If your environment doesn't support \"!mamba install\", use \"!pip install\"."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn import metrics\n","# Evaluation metrics related methods\n","from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_recall_fscore_support, precision_score, recall_score\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Define a random seed to reproduce any random process\n","rs = 123"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Ignore any deprecation warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "]},{"cell_type":"markdown","metadata":{},"source":["## Load and explore the tumor sample dataset\n"]},{"cell_type":"markdown","metadata":{},"source":["We first load the dataset `tumor.csv` as a Pandas dataframe:\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Read datast in csv format\n","dataset_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML241EN-SkillsNetwork/labs/datasets/tumor.csv\"\n","tumor_df = pd.read_csv(dataset_url)"]},{"cell_type":"markdown","metadata":{},"source":["Then, let's quickly take a look at the head of the dataframe.\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Clump</th>\n","      <th>UnifSize</th>\n","      <th>UnifShape</th>\n","      <th>MargAdh</th>\n","      <th>SingEpiSize</th>\n","      <th>BareNuc</th>\n","      <th>BlandChrom</th>\n","      <th>NormNucl</th>\n","      <th>Mit</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>7</td>\n","      <td>10</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Clump  UnifSize  UnifShape  MargAdh  SingEpiSize  BareNuc  BlandChrom  \\\n","0      5         1          1        1            2        1           3   \n","1      5         4          4        5            7       10           3   \n","2      3         1          1        1            2        2           3   \n","3      6         8          8        1            3        4           3   \n","4      4         1          1        3            2        1           3   \n","\n","   NormNucl  Mit  Class  \n","0         1    1      0  \n","1         2    1      0  \n","2         1    1      0  \n","3         7    1      0  \n","4         1    1      0  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["tumor_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["And, display its columns.\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["Index(['Clump', 'UnifSize', 'UnifShape', 'MargAdh', 'SingEpiSize', 'BareNuc',\n","       'BlandChrom', 'NormNucl', 'Mit', 'Class'],\n","      dtype='object')"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["tumor_df.columns"]},{"cell_type":"markdown","metadata":{},"source":["Each observation in this dataset contains lab test results about a tumor sample, such as clump or shapes. Based on these lab test results or features, we want to build a classification model to predict if this tumor sample is malicious (cancer) or benign. The target variable `y` is specified in the `Class` column.\n"]},{"cell_type":"markdown","metadata":{},"source":["Then, let's split the dataset into input `X` and output `y`:\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["X = tumor_df.iloc[:, :-1]\n","y = tumor_df.iloc[:, -1:]"]},{"cell_type":"markdown","metadata":{},"source":["And, we first check the statistics summary of features in `X`:\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Clump</th>\n","      <th>UnifSize</th>\n","      <th>UnifShape</th>\n","      <th>MargAdh</th>\n","      <th>SingEpiSize</th>\n","      <th>BareNuc</th>\n","      <th>BlandChrom</th>\n","      <th>NormNucl</th>\n","      <th>Mit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>683.000000</td>\n","      <td>683.000000</td>\n","      <td>683.000000</td>\n","      <td>683.000000</td>\n","      <td>683.000000</td>\n","      <td>683.000000</td>\n","      <td>683.000000</td>\n","      <td>683.000000</td>\n","      <td>683.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>4.442167</td>\n","      <td>3.150805</td>\n","      <td>3.215227</td>\n","      <td>2.830161</td>\n","      <td>3.234261</td>\n","      <td>3.544656</td>\n","      <td>3.445095</td>\n","      <td>2.869693</td>\n","      <td>1.603221</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>2.820761</td>\n","      <td>3.065145</td>\n","      <td>2.988581</td>\n","      <td>2.864562</td>\n","      <td>2.223085</td>\n","      <td>3.643857</td>\n","      <td>2.449697</td>\n","      <td>3.052666</td>\n","      <td>1.732674</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>4.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>6.000000</td>\n","      <td>5.000000</td>\n","      <td>5.000000</td>\n","      <td>4.000000</td>\n","      <td>4.000000</td>\n","      <td>6.000000</td>\n","      <td>5.000000</td>\n","      <td>4.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            Clump    UnifSize   UnifShape     MargAdh  SingEpiSize  \\\n","count  683.000000  683.000000  683.000000  683.000000   683.000000   \n","mean     4.442167    3.150805    3.215227    2.830161     3.234261   \n","std      2.820761    3.065145    2.988581    2.864562     2.223085   \n","min      1.000000    1.000000    1.000000    1.000000     1.000000   \n","25%      2.000000    1.000000    1.000000    1.000000     2.000000   \n","50%      4.000000    1.000000    1.000000    1.000000     2.000000   \n","75%      6.000000    5.000000    5.000000    4.000000     4.000000   \n","max     10.000000   10.000000   10.000000   10.000000    10.000000   \n","\n","          BareNuc  BlandChrom    NormNucl         Mit  \n","count  683.000000  683.000000  683.000000  683.000000  \n","mean     3.544656    3.445095    2.869693    1.603221  \n","std      3.643857    2.449697    3.052666    1.732674  \n","min      1.000000    1.000000    1.000000    1.000000  \n","25%      1.000000    2.000000    1.000000    1.000000  \n","50%      1.000000    3.000000    1.000000    1.000000  \n","75%      6.000000    5.000000    4.000000    1.000000  \n","max     10.000000   10.000000   10.000000   10.000000  "]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["X.describe()"]},{"cell_type":"markdown","metadata":{},"source":["As we can see from the above cell output, all features are numeric and ranged between 1 to 10. This is very convenient as we do not need to scale the feature values as they are already in the same range.\n"]},{"cell_type":"markdown","metadata":{},"source":["Next, let's check the class distribution of output `y`:\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["Class\n","0        0.650073\n","1        0.349927\n","dtype: float64"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["y.value_counts(normalize=True)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["<AxesSubplot:xlabel='Class'>"]},"execution_count":13,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["y.value_counts().plot.bar(color=['green', 'red'])"]},{"cell_type":"markdown","metadata":{},"source":["We have about 65% benign tumors (`Class = 0`) and 35% cancerous tumors (`Class = 1`), which is not a very imbalanced class distribution.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Process and split training and testing datasets\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# Split 80% as training dataset\n","# and 20% as testing dataset\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state = rs)"]},{"cell_type":"markdown","metadata":{},"source":["## Train and evaluate a KNN classifier with the number of neighbors set to 2\n"]},{"cell_type":"markdown","metadata":{},"source":["Training a KNN classifier is very similar to training other classifiers in `sklearn`, we first need to define a `KNeighborsClassifier` object. Here we use `n_neighbors=2` argument to specify how many neighbors will be used for prediction, and we keep other arguments to be their default values.\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# Define a KNN classifier with `n_neighbors=2`\n","knn_model = KNeighborsClassifier(n_neighbors=2)"]},{"cell_type":"markdown","metadata":{},"source":["Then we can train the model with `X_train` and `y_train`, and we use ravel() method to convert the data frame `y_train` to a vector.\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["KNeighborsClassifier(n_neighbors=2)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["knn_model.fit(X_train, y_train.values.ravel())"]},{"cell_type":"markdown","metadata":{},"source":["And, we can make predictions on the `X_test` dataframe.\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["preds = knn_model.predict(X_test)"]},{"cell_type":"markdown","metadata":{},"source":["To evaluate the KNN classifier, we provide a pre-defined method to return the commonly used evaluation metrics such as accuracy, recall, precision, f1score, and so on, based on the true classes in the 'y_test' and model predictions.\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["def evaluate_metrics(yt, yp):\n","    results_pos = {}\n","    results_pos['accuracy'] = accuracy_score(yt, yp)\n","    precision, recall, f_beta, _ = precision_recall_fscore_support(yt, yp, average='binary')\n","    results_pos['recall'] = recall\n","    results_pos['precision'] = precision\n","    results_pos['f1score'] = f_beta\n","    return results_pos"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["{'accuracy': 0.9416058394160584,\n"," 'recall': 0.875,\n"," 'precision': 0.9545454545454546,\n"," 'f1score': 0.9130434782608695}"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["evaluate_metrics(y_test, preds)"]},{"cell_type":"markdown","metadata":{},"source":["We can see that there is a great classification performance on the tumor sample dataset. This means the KNN model can effectively recognize cancerous tumors.\n","Next, it's your turn to try a different number of neighbors to see if we could get even better performance.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Coding exercise: Train and evaluate a KNN classifier with number of neighbors set to 5\n"]},{"cell_type":"markdown","metadata":{},"source":["First, define a KNN classifier with KNeighborsClassifier class:\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["# Type your code here\n","model = KNeighborsClassifier(n_neighbors=5)"]},{"cell_type":"markdown","metadata":{},"source":["Then train the model with `X_train` and `y_train`:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Type your code here\n"]},{"cell_type":"markdown","metadata":{},"source":["And, make predictions on `X_test` dataframe:\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["{'accuracy': 0.9781021897810219,\n"," 'recall': 0.9791666666666666,\n"," 'precision': 0.9591836734693877,\n"," 'f1score': 0.9690721649484536}"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["# Type your code here\n","model = KNeighborsClassifier(n_neighbors=5)\n","model.fit(X_train, y_train.values.ravel())\n","preds = model.predict(X_test)\n","evaluate_metrics(y_test, preds)"]},{"cell_type":"markdown","metadata":{},"source":["At last, you can evaluate your KNN model with provided `evaluate_metrics()` method.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Tune the number of neighbors to find the optmized one\n"]},{"cell_type":"markdown","metadata":{},"source":["OK, you may wonder which `n_neighbors` argument may give you the best classification performance. We can try different `n_neighbors` (the K value) and check which `K` gives the best classification performance.\n"]},{"cell_type":"markdown","metadata":{},"source":["Here we could try K from 1 to 50, and store the aggregated `f1score` for each k into a list.\n"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# Try K from 1 to 50\n","max_k = 50\n","# Create an empty list to store f1score for each k\n","f1_scores = []"]},{"cell_type":"markdown","metadata":{},"source":["Then we will train 50 KNN classifiers with K ranged from 1 to 50.\n"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>F1 Score</th>\n","    </tr>\n","    <tr>\n","      <th>K</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.9485</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.9130</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.9485</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.9583</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.9691</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.9583</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.9583</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.9474</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.9474</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.9474</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.9474</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.9474</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0.9474</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0.9474</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>0.9583</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>0.9583</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>0.9583</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>0.9583</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>0.9583</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>0.9583</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>0.9583</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>0.9583</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>0.9583</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>0.9583</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>0.9583</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>0.9583</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>0.9583</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>0.9474</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>0.9474</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>0.9474</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>0.9474</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>0.9474</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>0.9474</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>0.9362</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>0.9362</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>0.9362</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>0.9362</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>0.9362</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>0.9362</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>0.9362</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>0.9362</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>0.9362</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>0.9362</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>0.9362</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>0.9362</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>0.9362</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>0.9362</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>0.9362</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>0.9362</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>0.9362</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    F1 Score\n","K           \n","1     0.9485\n","2     0.9130\n","3     0.9485\n","4     0.9583\n","5     0.9691\n","6     0.9583\n","7     0.9583\n","8     0.9474\n","9     0.9474\n","10    0.9474\n","11    0.9474\n","12    0.9474\n","13    0.9474\n","14    0.9474\n","15    0.9583\n","16    0.9583\n","17    0.9583\n","18    0.9583\n","19    0.9583\n","20    0.9583\n","21    0.9583\n","22    0.9583\n","23    0.9583\n","24    0.9583\n","25    0.9583\n","26    0.9583\n","27    0.9583\n","28    0.9474\n","29    0.9474\n","30    0.9474\n","31    0.9474\n","32    0.9474\n","33    0.9474\n","34    0.9362\n","35    0.9362\n","36    0.9362\n","37    0.9362\n","38    0.9362\n","39    0.9362\n","40    0.9362\n","41    0.9362\n","42    0.9362\n","43    0.9362\n","44    0.9362\n","45    0.9362\n","46    0.9362\n","47    0.9362\n","48    0.9362\n","49    0.9362\n","50    0.9362"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["for k in range(1, max_k + 1):\n","    # Create a KNN classifier\n","    knn = KNeighborsClassifier(n_neighbors=k)\n","    # Train the classifier\n","    knn = knn.fit(X_train, y_train.values.ravel())\n","    preds = knn.predict(X_test)\n","    # Evaluate the classifier with f1score\n","    f1 = f1_score(preds, y_test)\n","    f1_scores.append((k, round(f1_score(y_test, preds), 4)))\n","# Convert the f1score list to a dataframe\n","f1_results = pd.DataFrame(f1_scores, columns=['K', 'F1 Score'])\n","f1_results.set_index('K')"]},{"cell_type":"markdown","metadata":{},"source":["This is a long list and different to analysis, so let's visualize the list using a linechart.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot F1 results\n","ax = f1_results.plot(figsize=(12, 12))\n","ax.set(xlabel='Num of Neighbors', ylabel='F1 Score')\n","ax.set_xticks(range(1, max_k, 2));\n","plt.ylim((0.85, 1))\n","plt.title('KNN F1 Score')"]},{"cell_type":"markdown","metadata":{},"source":["As we can see from the F1 score linechart, the best `K` value is 5 with about `0.9691` f1score.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Next steps\n"]},{"cell_type":"markdown","metadata":{},"source":["Great! Now you have learned about and applied the KNN model to solve a real-world tumor type classification problem. You also tuned the KNN to find the best K value. Later, you will continue learning other popular classification models with different structures, assumptions, cost functions, and application scenarios.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Authors\n"]},{"cell_type":"markdown","metadata":{},"source":["[Yan Luo](https://www.linkedin.com/in/yan-luo-96288783/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML241ENSkillsNetwork31576874-2022-01-01)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Other Contributors\n"]},{"cell_type":"markdown","metadata":{},"source":["## Change Log\n"]},{"cell_type":"markdown","metadata":{},"source":["| Date (YYYY-MM-DD) | Version | Changed By | Change Description          |\n","| ----------------- | ------- | ---------- | --------------------------- |\n","| 2021-11-9         | 1.0     | Yan        | Created the initial version |\n","| 2022-3-29         | 1.1     | Steve Hord | QA Pass                     |\n"]},{"cell_type":"markdown","metadata":{},"source":["Copyright Â© 2021 IBM Corporation. All rights reserved.\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.0 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"vscode":{"interpreter":{"hash":"369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"}}},"nbformat":4,"nbformat_minor":4}
