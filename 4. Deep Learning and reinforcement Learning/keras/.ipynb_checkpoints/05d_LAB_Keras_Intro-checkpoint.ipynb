{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 5, Part d: Keras Intro LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "from keras.models  import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import adam_v2,gradient_descent_v2, rmsprop_v2\n",
    "sgd = gradient_descent_v2.SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set \n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('diabetes.csv', names=names, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>6</td>\n",
       "      <td>134</td>\n",
       "      <td>80</td>\n",
       "      <td>37</td>\n",
       "      <td>370</td>\n",
       "      <td>46.2</td>\n",
       "      <td>0.238</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>12</td>\n",
       "      <td>140</td>\n",
       "      <td>82</td>\n",
       "      <td>43</td>\n",
       "      <td>325</td>\n",
       "      <td>39.2</td>\n",
       "      <td>0.528</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>68</td>\n",
       "      <td>49</td>\n",
       "      <td>579</td>\n",
       "      <td>42.4</td>\n",
       "      <td>0.702</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>64</td>\n",
       "      <td>22</td>\n",
       "      <td>66</td>\n",
       "      <td>35.8</td>\n",
       "      <td>0.545</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>60</td>\n",
       "      <td>33</td>\n",
       "      <td>192</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.966</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "231               6                     134              80              37   \n",
       "375              12                     140              82              43   \n",
       "409               1                     172              68              49   \n",
       "372               0                      84              64              22   \n",
       "35                4                     103              60              33   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "231      370  46.2              0.238   46             1  \n",
       "375      325  39.2              0.528   58             1  \n",
       "409      579  42.4              0.702   28             1  \n",
       "372       66  35.8              0.545   21             0  \n",
       "35       192  24.0              0.966   33             0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise 1: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.766\n",
      "roc-auc is 0.824\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(12,input_shape = (8,),activation = 'sigmoid'))\n",
    "model_1.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                108       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 1s 21ms/step - loss: 0.8897 - accuracy: 0.3455 - val_loss: 0.8593 - val_accuracy: 0.3594\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8686 - accuracy: 0.3455 - val_loss: 0.8406 - val_accuracy: 0.3594\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.8494 - accuracy: 0.3472 - val_loss: 0.8238 - val_accuracy: 0.3594\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.8320 - accuracy: 0.3490 - val_loss: 0.8085 - val_accuracy: 0.3594\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8163 - accuracy: 0.3490 - val_loss: 0.7947 - val_accuracy: 0.3542\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.8020 - accuracy: 0.3455 - val_loss: 0.7823 - val_accuracy: 0.3542\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.7890 - accuracy: 0.3472 - val_loss: 0.7710 - val_accuracy: 0.3542\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7773 - accuracy: 0.3438 - val_loss: 0.7609 - val_accuracy: 0.3438\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7667 - accuracy: 0.3472 - val_loss: 0.7517 - val_accuracy: 0.3542\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7570 - accuracy: 0.3420 - val_loss: 0.7435 - val_accuracy: 0.3438\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.7483 - accuracy: 0.3385 - val_loss: 0.7360 - val_accuracy: 0.3490\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7404 - accuracy: 0.3542 - val_loss: 0.7293 - val_accuracy: 0.3698\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.7333 - accuracy: 0.3524 - val_loss: 0.7232 - val_accuracy: 0.4062\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.7268 - accuracy: 0.3785 - val_loss: 0.7177 - val_accuracy: 0.4323\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.7208 - accuracy: 0.3872 - val_loss: 0.7126 - val_accuracy: 0.4896\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.7154 - accuracy: 0.4149 - val_loss: 0.7081 - val_accuracy: 0.4844\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7105 - accuracy: 0.4340 - val_loss: 0.7039 - val_accuracy: 0.4740\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7059 - accuracy: 0.4566 - val_loss: 0.7001 - val_accuracy: 0.4740\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7018 - accuracy: 0.4653 - val_loss: 0.6967 - val_accuracy: 0.4635\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6980 - accuracy: 0.4983 - val_loss: 0.6935 - val_accuracy: 0.4948\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6945 - accuracy: 0.5330 - val_loss: 0.6906 - val_accuracy: 0.5104\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6913 - accuracy: 0.5521 - val_loss: 0.6879 - val_accuracy: 0.5521\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6884 - accuracy: 0.5625 - val_loss: 0.6855 - val_accuracy: 0.5729\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6856 - accuracy: 0.5851 - val_loss: 0.6832 - val_accuracy: 0.5990\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.6831 - accuracy: 0.6042 - val_loss: 0.6811 - val_accuracy: 0.6094\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6807 - accuracy: 0.6181 - val_loss: 0.6791 - val_accuracy: 0.6198\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6785 - accuracy: 0.6285 - val_loss: 0.6773 - val_accuracy: 0.6354\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6765 - accuracy: 0.6354 - val_loss: 0.6756 - val_accuracy: 0.6250\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6745 - accuracy: 0.6389 - val_loss: 0.6740 - val_accuracy: 0.6354\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6727 - accuracy: 0.6441 - val_loss: 0.6725 - val_accuracy: 0.6354\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6710 - accuracy: 0.6441 - val_loss: 0.6711 - val_accuracy: 0.6406\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6694 - accuracy: 0.6458 - val_loss: 0.6697 - val_accuracy: 0.6406\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6679 - accuracy: 0.6458 - val_loss: 0.6684 - val_accuracy: 0.6406\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6664 - accuracy: 0.6458 - val_loss: 0.6672 - val_accuracy: 0.6406\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6650 - accuracy: 0.6476 - val_loss: 0.6660 - val_accuracy: 0.6406\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6637 - accuracy: 0.6476 - val_loss: 0.6649 - val_accuracy: 0.6406\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6625 - accuracy: 0.6493 - val_loss: 0.6638 - val_accuracy: 0.6406\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6612 - accuracy: 0.6510 - val_loss: 0.6628 - val_accuracy: 0.6406\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6601 - accuracy: 0.6528 - val_loss: 0.6618 - val_accuracy: 0.6406\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6589 - accuracy: 0.6528 - val_loss: 0.6608 - val_accuracy: 0.6406\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6579 - accuracy: 0.6528 - val_loss: 0.6599 - val_accuracy: 0.6406\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6568 - accuracy: 0.6528 - val_loss: 0.6590 - val_accuracy: 0.6406\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6558 - accuracy: 0.6528 - val_loss: 0.6581 - val_accuracy: 0.6406\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6549 - accuracy: 0.6545 - val_loss: 0.6572 - val_accuracy: 0.6406\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6539 - accuracy: 0.6562 - val_loss: 0.6564 - val_accuracy: 0.6406\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6530 - accuracy: 0.6562 - val_loss: 0.6555 - val_accuracy: 0.6406\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6521 - accuracy: 0.6545 - val_loss: 0.6547 - val_accuracy: 0.6406\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6512 - accuracy: 0.6545 - val_loss: 0.6539 - val_accuracy: 0.6406\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6503 - accuracy: 0.6545 - val_loss: 0.6531 - val_accuracy: 0.6406\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6495 - accuracy: 0.6545 - val_loss: 0.6523 - val_accuracy: 0.6406\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6486 - accuracy: 0.6545 - val_loss: 0.6516 - val_accuracy: 0.6406\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6478 - accuracy: 0.6545 - val_loss: 0.6508 - val_accuracy: 0.6406\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6470 - accuracy: 0.6545 - val_loss: 0.6501 - val_accuracy: 0.6406\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6462 - accuracy: 0.6545 - val_loss: 0.6493 - val_accuracy: 0.6406\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6454 - accuracy: 0.6545 - val_loss: 0.6486 - val_accuracy: 0.6406\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6446 - accuracy: 0.6545 - val_loss: 0.6479 - val_accuracy: 0.6406\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6439 - accuracy: 0.6545 - val_loss: 0.6472 - val_accuracy: 0.6406\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6431 - accuracy: 0.6545 - val_loss: 0.6464 - val_accuracy: 0.6406\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6424 - accuracy: 0.6545 - val_loss: 0.6457 - val_accuracy: 0.6406\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6416 - accuracy: 0.6545 - val_loss: 0.6450 - val_accuracy: 0.6406\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6409 - accuracy: 0.6545 - val_loss: 0.6443 - val_accuracy: 0.6406\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6402 - accuracy: 0.6545 - val_loss: 0.6437 - val_accuracy: 0.6406\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6395 - accuracy: 0.6545 - val_loss: 0.6430 - val_accuracy: 0.6406\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6388 - accuracy: 0.6545 - val_loss: 0.6423 - val_accuracy: 0.6406\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6381 - accuracy: 0.6545 - val_loss: 0.6416 - val_accuracy: 0.6406\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6374 - accuracy: 0.6545 - val_loss: 0.6409 - val_accuracy: 0.6406\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6367 - accuracy: 0.6545 - val_loss: 0.6403 - val_accuracy: 0.6406\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6360 - accuracy: 0.6545 - val_loss: 0.6396 - val_accuracy: 0.6406\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6354 - accuracy: 0.6545 - val_loss: 0.6389 - val_accuracy: 0.6406\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6347 - accuracy: 0.6545 - val_loss: 0.6383 - val_accuracy: 0.6406\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6340 - accuracy: 0.6545 - val_loss: 0.6376 - val_accuracy: 0.6406\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6334 - accuracy: 0.6545 - val_loss: 0.6370 - val_accuracy: 0.6406\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6327 - accuracy: 0.6545 - val_loss: 0.6363 - val_accuracy: 0.6406\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6321 - accuracy: 0.6545 - val_loss: 0.6357 - val_accuracy: 0.6406\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6314 - accuracy: 0.6545 - val_loss: 0.6350 - val_accuracy: 0.6406\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6308 - accuracy: 0.6545 - val_loss: 0.6344 - val_accuracy: 0.6406\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6301 - accuracy: 0.6545 - val_loss: 0.6338 - val_accuracy: 0.6406\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6295 - accuracy: 0.6545 - val_loss: 0.6331 - val_accuracy: 0.6406\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6289 - accuracy: 0.6545 - val_loss: 0.6325 - val_accuracy: 0.6406\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6283 - accuracy: 0.6545 - val_loss: 0.6319 - val_accuracy: 0.6406\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6276 - accuracy: 0.6545 - val_loss: 0.6313 - val_accuracy: 0.6406\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6270 - accuracy: 0.6545 - val_loss: 0.6306 - val_accuracy: 0.6406\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6264 - accuracy: 0.6545 - val_loss: 0.6300 - val_accuracy: 0.6406\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6258 - accuracy: 0.6545 - val_loss: 0.6294 - val_accuracy: 0.6406\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6252 - accuracy: 0.6545 - val_loss: 0.6288 - val_accuracy: 0.6406\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6246 - accuracy: 0.6545 - val_loss: 0.6282 - val_accuracy: 0.6406\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6240 - accuracy: 0.6545 - val_loss: 0.6276 - val_accuracy: 0.6406\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6234 - accuracy: 0.6545 - val_loss: 0.6270 - val_accuracy: 0.6406\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6228 - accuracy: 0.6545 - val_loss: 0.6264 - val_accuracy: 0.6406\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6222 - accuracy: 0.6545 - val_loss: 0.6258 - val_accuracy: 0.6406\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6216 - accuracy: 0.6545 - val_loss: 0.6252 - val_accuracy: 0.6406\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6210 - accuracy: 0.6545 - val_loss: 0.6246 - val_accuracy: 0.6406\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6204 - accuracy: 0.6545 - val_loss: 0.6240 - val_accuracy: 0.6406\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6198 - accuracy: 0.6545 - val_loss: 0.6234 - val_accuracy: 0.6406\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6193 - accuracy: 0.6545 - val_loss: 0.6228 - val_accuracy: 0.6406\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6187 - accuracy: 0.6545 - val_loss: 0.6222 - val_accuracy: 0.6406\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6181 - accuracy: 0.6545 - val_loss: 0.6216 - val_accuracy: 0.6406\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6176 - accuracy: 0.6545 - val_loss: 0.6210 - val_accuracy: 0.6406\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6170 - accuracy: 0.6545 - val_loss: 0.6205 - val_accuracy: 0.6406\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6164 - accuracy: 0.6545 - val_loss: 0.6199 - val_accuracy: 0.6406\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6159 - accuracy: 0.6545 - val_loss: 0.6193 - val_accuracy: 0.6406\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6153 - accuracy: 0.6545 - val_loss: 0.6187 - val_accuracy: 0.6406\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6147 - accuracy: 0.6545 - val_loss: 0.6182 - val_accuracy: 0.6406\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6142 - accuracy: 0.6545 - val_loss: 0.6176 - val_accuracy: 0.6406\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6136 - accuracy: 0.6545 - val_loss: 0.6170 - val_accuracy: 0.6406\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6131 - accuracy: 0.6545 - val_loss: 0.6165 - val_accuracy: 0.6406\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6125 - accuracy: 0.6545 - val_loss: 0.6159 - val_accuracy: 0.6406\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6120 - accuracy: 0.6545 - val_loss: 0.6153 - val_accuracy: 0.6406\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6114 - accuracy: 0.6545 - val_loss: 0.6148 - val_accuracy: 0.6406\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6109 - accuracy: 0.6545 - val_loss: 0.6142 - val_accuracy: 0.6406\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6103 - accuracy: 0.6545 - val_loss: 0.6137 - val_accuracy: 0.6406\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6098 - accuracy: 0.6545 - val_loss: 0.6131 - val_accuracy: 0.6406\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6093 - accuracy: 0.6545 - val_loss: 0.6126 - val_accuracy: 0.6406\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6087 - accuracy: 0.6545 - val_loss: 0.6120 - val_accuracy: 0.6406\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6545 - val_loss: 0.6115 - val_accuracy: 0.6406\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6077 - accuracy: 0.6545 - val_loss: 0.6109 - val_accuracy: 0.6406\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6072 - accuracy: 0.6545 - val_loss: 0.6104 - val_accuracy: 0.6406\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6066 - accuracy: 0.6545 - val_loss: 0.6099 - val_accuracy: 0.6406\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6061 - accuracy: 0.6545 - val_loss: 0.6093 - val_accuracy: 0.6406\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6056 - accuracy: 0.6562 - val_loss: 0.6088 - val_accuracy: 0.6406\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6051 - accuracy: 0.6562 - val_loss: 0.6083 - val_accuracy: 0.6406\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6046 - accuracy: 0.6562 - val_loss: 0.6077 - val_accuracy: 0.6406\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6041 - accuracy: 0.6562 - val_loss: 0.6072 - val_accuracy: 0.6406\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6035 - accuracy: 0.6562 - val_loss: 0.6067 - val_accuracy: 0.6406\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6030 - accuracy: 0.6562 - val_loss: 0.6062 - val_accuracy: 0.6406\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6025 - accuracy: 0.6562 - val_loss: 0.6056 - val_accuracy: 0.6406\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6020 - accuracy: 0.6580 - val_loss: 0.6051 - val_accuracy: 0.6406\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6015 - accuracy: 0.6580 - val_loss: 0.6046 - val_accuracy: 0.6406\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6010 - accuracy: 0.6580 - val_loss: 0.6041 - val_accuracy: 0.6406\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6005 - accuracy: 0.6580 - val_loss: 0.6036 - val_accuracy: 0.6406\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6000 - accuracy: 0.6580 - val_loss: 0.6030 - val_accuracy: 0.6406\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5995 - accuracy: 0.6597 - val_loss: 0.6025 - val_accuracy: 0.6406\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5990 - accuracy: 0.6615 - val_loss: 0.6020 - val_accuracy: 0.6406\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5985 - accuracy: 0.6615 - val_loss: 0.6015 - val_accuracy: 0.6406\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5980 - accuracy: 0.6615 - val_loss: 0.6010 - val_accuracy: 0.6406\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5975 - accuracy: 0.6615 - val_loss: 0.6005 - val_accuracy: 0.6406\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5970 - accuracy: 0.6615 - val_loss: 0.6000 - val_accuracy: 0.6406\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5965 - accuracy: 0.6615 - val_loss: 0.5995 - val_accuracy: 0.6406\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5960 - accuracy: 0.6632 - val_loss: 0.5990 - val_accuracy: 0.6510\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5956 - accuracy: 0.6615 - val_loss: 0.5985 - val_accuracy: 0.6510\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5951 - accuracy: 0.6632 - val_loss: 0.5980 - val_accuracy: 0.6510\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5946 - accuracy: 0.6632 - val_loss: 0.5975 - val_accuracy: 0.6510\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5941 - accuracy: 0.6632 - val_loss: 0.5970 - val_accuracy: 0.6510\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5937 - accuracy: 0.6632 - val_loss: 0.5966 - val_accuracy: 0.6510\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5932 - accuracy: 0.6632 - val_loss: 0.5961 - val_accuracy: 0.6562\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5927 - accuracy: 0.6649 - val_loss: 0.5956 - val_accuracy: 0.6510\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5922 - accuracy: 0.6649 - val_loss: 0.5951 - val_accuracy: 0.6510\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5918 - accuracy: 0.6632 - val_loss: 0.5946 - val_accuracy: 0.6510\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5913 - accuracy: 0.6649 - val_loss: 0.5941 - val_accuracy: 0.6510\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5908 - accuracy: 0.6649 - val_loss: 0.5937 - val_accuracy: 0.6510\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5904 - accuracy: 0.6649 - val_loss: 0.5932 - val_accuracy: 0.6562\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5899 - accuracy: 0.6649 - val_loss: 0.5927 - val_accuracy: 0.6562\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5894 - accuracy: 0.6649 - val_loss: 0.5922 - val_accuracy: 0.6562\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5890 - accuracy: 0.6649 - val_loss: 0.5918 - val_accuracy: 0.6562\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5885 - accuracy: 0.6649 - val_loss: 0.5913 - val_accuracy: 0.6667\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5880 - accuracy: 0.6701 - val_loss: 0.5908 - val_accuracy: 0.6667\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5876 - accuracy: 0.6684 - val_loss: 0.5904 - val_accuracy: 0.6667\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5871 - accuracy: 0.6701 - val_loss: 0.5899 - val_accuracy: 0.6667\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5867 - accuracy: 0.6684 - val_loss: 0.5894 - val_accuracy: 0.6667\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5862 - accuracy: 0.6719 - val_loss: 0.5890 - val_accuracy: 0.6667\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5858 - accuracy: 0.6736 - val_loss: 0.5885 - val_accuracy: 0.6667\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5853 - accuracy: 0.6753 - val_loss: 0.5881 - val_accuracy: 0.6719\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5849 - accuracy: 0.6771 - val_loss: 0.5876 - val_accuracy: 0.6719\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5844 - accuracy: 0.6771 - val_loss: 0.5871 - val_accuracy: 0.6719\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5840 - accuracy: 0.6771 - val_loss: 0.5867 - val_accuracy: 0.6719\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5835 - accuracy: 0.6788 - val_loss: 0.5862 - val_accuracy: 0.6719\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5831 - accuracy: 0.6806 - val_loss: 0.5858 - val_accuracy: 0.6771\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5826 - accuracy: 0.6823 - val_loss: 0.5853 - val_accuracy: 0.6771\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5822 - accuracy: 0.6892 - val_loss: 0.5849 - val_accuracy: 0.6771\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5818 - accuracy: 0.6892 - val_loss: 0.5844 - val_accuracy: 0.6771\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5813 - accuracy: 0.6892 - val_loss: 0.5840 - val_accuracy: 0.6771\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.6892 - val_loss: 0.5836 - val_accuracy: 0.6823\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5805 - accuracy: 0.6892 - val_loss: 0.5831 - val_accuracy: 0.6823\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5801 - accuracy: 0.6875 - val_loss: 0.5827 - val_accuracy: 0.6875\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5796 - accuracy: 0.6944 - val_loss: 0.5822 - val_accuracy: 0.6875\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5792 - accuracy: 0.6962 - val_loss: 0.5818 - val_accuracy: 0.6875\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5788 - accuracy: 0.6979 - val_loss: 0.5814 - val_accuracy: 0.6875\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5783 - accuracy: 0.6979 - val_loss: 0.5809 - val_accuracy: 0.6875\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5779 - accuracy: 0.6979 - val_loss: 0.5805 - val_accuracy: 0.6927\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5775 - accuracy: 0.6979 - val_loss: 0.5801 - val_accuracy: 0.6927\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5771 - accuracy: 0.6997 - val_loss: 0.5796 - val_accuracy: 0.6927\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5766 - accuracy: 0.6997 - val_loss: 0.5792 - val_accuracy: 0.6927\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5762 - accuracy: 0.6997 - val_loss: 0.5788 - val_accuracy: 0.6927\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5758 - accuracy: 0.7014 - val_loss: 0.5784 - val_accuracy: 0.6979\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5754 - accuracy: 0.6997 - val_loss: 0.5779 - val_accuracy: 0.6979\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5750 - accuracy: 0.6997 - val_loss: 0.5775 - val_accuracy: 0.6979\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5745 - accuracy: 0.6997 - val_loss: 0.5771 - val_accuracy: 0.6979\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5741 - accuracy: 0.6997 - val_loss: 0.5767 - val_accuracy: 0.6927\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5737 - accuracy: 0.6997 - val_loss: 0.5763 - val_accuracy: 0.6927\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5733 - accuracy: 0.7014 - val_loss: 0.5759 - val_accuracy: 0.6927\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5729 - accuracy: 0.7049 - val_loss: 0.5754 - val_accuracy: 0.6927\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.7049 - val_loss: 0.5750 - val_accuracy: 0.6927\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5720 - accuracy: 0.7049 - val_loss: 0.5746 - val_accuracy: 0.6979\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5716 - accuracy: 0.7049 - val_loss: 0.5742 - val_accuracy: 0.6979\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5712 - accuracy: 0.7031 - val_loss: 0.5738 - val_accuracy: 0.6979\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5708 - accuracy: 0.7031 - val_loss: 0.5734 - val_accuracy: 0.6979\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5704 - accuracy: 0.7049 - val_loss: 0.5730 - val_accuracy: 0.6979\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5700 - accuracy: 0.7066 - val_loss: 0.5726 - val_accuracy: 0.6979\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.7049 - val_loss: 0.5722 - val_accuracy: 0.6979\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5692 - accuracy: 0.7083 - val_loss: 0.5718 - val_accuracy: 0.6979\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(sgd(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "y_pred_class_nn_1 = model_1.predict(X_test_norm)\n",
    "classes_x=np.argmax(y_pred_class_nn_1, axis=1)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "classes_x[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37665266],\n",
       "       [0.48621768],\n",
       "       [0.30372685],\n",
       "       [0.30689144],\n",
       "       [0.29309344],\n",
       "       [0.44678077],\n",
       "       [0.2778268 ],\n",
       "       [0.33805436],\n",
       "       [0.5270391 ],\n",
       "       [0.33645624]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.641\n",
      "roc-auc is 0.810\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,classes_x)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x163e3a87940>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD5CAYAAAAp8/5SAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAqiElEQVR4nO3deXxU9b3/8dcnC6FVUZa4FFCgP1xQ9giOCgSpiugF9wvaAqJSuVXELmqtVX4o16X2au1VEXctlR+2SvHiUkWC3jIiQREFRRBRgqIsirhASPL5/XFOwiRkmayTzLyfjwePOXOWme+chPecfM73fI+5OyIikrzSEt0AERFpXAp6EZEkp6AXEUlyCnoRkSSnoBcRSXIKehGRJJcRz0pmNhz4E5AOPOjut1ZYfhjwMJANbAN+6u4F4bJxwPXhqje7+2PVvVeHDh28S5cutfkMIiIpb9myZVvcPbuyZVZTP3ozSwc+AE4GCoClwBh3XxWzzlPA/7j7Y2Z2EnCRu//MzNoB+UAO4MAyoL+7f1nV++Xk5Hh+fn6tPqCISKozs2XunlPZsnhKNwOAte6+zt0LgdnAqArr9ABeCacXxiw/FXjJ3beF4f4SMLy2H0BEROounqDvCGyIeV4Qzov1NnB2OH0WsJ+ZtY9zWxERaUQNdTL218AQM3sLGAJsBIrj3djMJppZvpnlb968uYGaJCIiEN/J2I1A55jnncJ5Zdz9U8IjejPbFzjH3b8ys41AboVt8yq+gbvPBGZCUKOPv/kiUh+7d++moKCAnTt3JropEqfWrVvTqVMnMjMz494mnqBfCnQ3s64EAT8auCB2BTPrAGxz9xLgtwQ9cABeBP7TzNqGz08Jl4tIM1BQUMB+++1Hly5dMLNEN0dq4O5s3bqVgoICunbtGvd2NZZu3L0IuJwgtN8D5rj7SjObZmYjw9VygdVm9gFwEDA93HYbcBPBl8VSYFo4T0SagZ07d9K+fXuFfAthZrRv377Wf4HF1Y/e3Z8Dnqsw74aY6b8Bf6ti24fZc4TfuKJRyMuD3FyIRJrkLUVaOoV8y1KXn1dcQd8i/POfcPrpUFICWVmwYIHCXkSEZBoC4V//gqKiIOgLC4MjexFp1rZu3UqfPn3o06cPBx98MB07dix7XlhYWO22+fn5TJ48uVbv16VLF7Zs2VKfJrdIyXNEP3w4TJsGZtCqVVC+EZFmrX379ixfvhyAqVOnsu+++/LrX/+6bHlRUREZGZXHVE5ODjk5lV4IKhUkzxF9JALdusFRR6lsI9KYolG45ZbgsRGMHz+eyy67jIEDB3L11VfzxhtvEIlE6Nu3L8cffzyrV68GIC8vjzPOOAMIviQmTJhAbm4u3bp14+677477/davX89JJ51Er169GDZsGJ988gkATz31FMcccwy9e/dm8ODBAKxcuZIBAwbQp08fevXqxZo1axr40zeO5DmiBzjySNi0SSEvUhdTpkB4dF2l7dthxYqgRJqWBr16wf77V71+nz5w1121bkpBQQGLFy8mPT2dr7/+mtdee42MjAxefvllrrvuOv7+97/vtc3777/PwoUL2bFjB0cccQSTJk2Kq6/5FVdcwbhx4xg3bhwPP/wwkydPZu7cuUybNo0XX3yRjh078tVXXwEwY8YMrrzySi688EIKCwspLo77utCESq6gP/RQeOONRLdCJHlt3x6EPASP27dXH/R1dN5555Genh6+5XbGjRvHmjVrMDN2795d6Tann346WVlZZGVlceCBB/L555/TqVOnGt8rGo3y9NNPA/Czn/2Mq6++GoATTjiB8ePHc/7553P22cEIL5FIhOnTp1NQUMDZZ59N9+7dG+LjNrrkC/otW+Dbb2GffRLdGpGWJZ4j72gUhg0LOjy0agWzZjXKX9D7xPz//f3vf8/QoUN55plnWL9+PblVnH/Lysoqm05PT6eoqKhebZgxYwZLlixh/vz59O/fn2XLlnHBBRcwcOBA5s+fz4gRI7j//vs56aST6vU+TSF5avQQBD3Ahg3VrycidROJBOfAbrqpyc6Fbd++nY4dg7EQH3300QZ//eOPP57Zs2cDMGvWLAYNGgTAhx9+yMCBA5k2bRrZ2dls2LCBdevW0a1bNyZPnsyoUaNYsWJFg7enMSTfET3AJ58E9XoRaXiRSJOeB7v66qsZN24cN998M6effnq9X69Xr16kpQXHuOeffz5//vOfueiii/jDH/5AdnY2jzzyCAC/+c1vWLNmDe7OsGHD6N27N7fddhtPPPEEmZmZHHzwwVx33XX1bk9TqPHGI02tXjce+fhj6NIFHngALrmkQdslkozee+89jjrqqEQ3Q2qpsp9bfW880nL86EdBT4Cwe5SIiCRb0GdmBmGvoBcRKZNcQQ/Qti289lqjXcwhItLSJFfQR6OwahWsWxd0AVPYi4gkWdDn5e25mEMDm4mIAMkW9Lm5UDoAUmamBjYTESHZgj4SgdtvD6b/67805o1IMzd06FBefPHFcvPuuusuJk2aVOU2ubm5lHbBHjFiRNk4NLGmTp3KHXfcUe17z507l1WrVpU9v+GGG3j55Zdr0frKxQ621lwkV9BDcPMRgB/+MLHtEJEajRkzpuyq1FKzZ89mzJgxcW3/3HPPccABB9TpvSsG/bRp0/jJT35Sp9dq7pIq6KNRuGV2V6JE4KOPEt0ckaTUkKMUn3vuucyfP7/sJiPr16/n008/ZdCgQUyaNImcnByOPvpobrzxxkq3j72RyPTp0zn88MM58cQTy4YyBnjggQc49thj6d27N+eccw7fffcdixcvZt68efzmN7+hT58+fPjhh4wfP56//S24I+qCBQvo27cvPXv2ZMKECezatavs/W688Ub69etHz549ef/99+P+rE8++SQ9e/bkmGOO4ZprrgGguLiY8ePHc8wxx9CzZ0/uvPNOAO6++2569OhBr169GD16dC336t6SZgiE+fNh5EiADLJsAQve+AMq3IjELxGjFLdr144BAwbw/PPPM2rUKGbPns3555+PmTF9+nTatWtHcXExw4YNY8WKFfTq1avS11m2bBmzZ89m+fLlFBUV0a9fP/r37w/A2WefzaWXXgrA9ddfz0MPPcQVV1zByJEjOeOMMzj33HPLvdbOnTsZP348CxYs4PDDD2fs2LHcd999TJkyBYAOHTrw5ptvcu+993LHHXfw4IMPVr/TgE8//ZRrrrmGZcuW0bZtW0455RTmzp1L586d2bhxI++++y5AWRnq1ltv5aOPPiIrK6vS0lRtJc0R/bJlwS9fSQkUeiZ57x2U6CaJJJ3KRimur9jyTWzZZs6cOfTr14++ffuycuXKcmWWil577TXOOussfvjDH9KmTRtGBkd9ALz77rsMGjSInj17MmvWLFauXFlte1avXk3Xrl05/PDDARg3bhyvvvpq2fLSIYv79+/P+vXr4/qMS5cuJTc3l+zsbDIyMrjwwgt59dVX6datG+vWreOKK67ghRdeoE2bNkAwHs+FF17IX/7ylyrvsFUbSXNEf/LJcOON4Z0E04rJ/fY54OeJbpZIi5GoUYpHjRrFVVddxZtvvsl3331H//79+eijj7jjjjtYunQpbdu2Zfz48ezcubNOrz9+/Hjmzp1L7969efTRR8mrZ7fr0uGQG2Io5LZt2/L222/z4osvMmPGDObMmcPDDz/M/PnzefXVV3n22WeZPn0677zzTr0CP64jejMbbmarzWytmV1byfJDzWyhmb1lZivMbEQ4v4uZfW9my8N/M+rc0hpEIsGfkYcdBgvGPUFky7MQ1tVEpGE0xijF++67L0OHDmXChAllR/Nff/01++yzD/vvvz+ff/45zz//fLWvMXjwYObOncv333/Pjh07ePbZZ8uW7dixg0MOOYTdu3cza9assvn77bcfO3bs2Ou1jjjiCNavX8/atWsBeOKJJxgyZEi9PuOAAQNYtGgRW7Zsobi4mCeffJIhQ4awZcsWSkpKOOecc7j55pt58803KSkpYcOGDQwdOpTbbruN7du3880339Tr/Wv8ijCzdOAe4GSgAFhqZvPcPfbvqOuBOe5+n5n1AJ4DuoTLPnT3PvVqZZz69IFXXoHIkFbwsAdj3rSQO8CItBSNMUrxmDFjOOuss8pKOL1796Zv374ceeSRdO7cmRNOOKHa7fv168e///u/07t3bw488ECOPfbYsmU33XQTAwcOJDs7m4EDB5aF++jRo7n00ku5++67y07CArRu3ZpHHnmE8847j6KiIo499lguu+yyWn2eBQsWlLu71VNPPcWtt97K0KFDcXdOP/10Ro0axdtvv81FF11ESVgPu+WWWyguLuanP/0p27dvx92ZPHlynXsWlXH3av8BEeDFmOe/BX5bYZ37gWti1l8cTncB3q3pPWL/9e/f3+tq6lR3M/fvX3rNHdwvush98eI6v55Islu1alWimyB1UNnPDcj3KnI1ntJNRyD2lk0F4bxYU4GfmlkBwdH8FTHLuoYlnUVmNqgW30G11q0buMPHH4Qlm0cf1Zg3IpLyGqrXzRjgUXfvBIwAnjCzNOAz4FB37wv8EvirmbWpuLGZTTSzfDPL37x5c50b0a1b8LhuSfga7hrzRkRSXjxBvxHoHPO8Uzgv1sXAHAB3jwKtgQ7uvsvdt4bzlwEfAodXfAN3n+nuOe6ek52dXftPEfrxj4PHddkDgu43EHQN0Jg3IlXyZnaXOaleXX5e8QT9UqC7mXU1s1bAaGBehXU+AYYBmNlRBEG/2cyyw5O5mFk3oDuwrtatjNNBB8EPfgAflnSDE04IZjTRDYxFWqLWrVuzdetWhX0L4e5s3bqV1q1b12q7GnvduHuRmV0OvAikAw+7+0ozm0ZQ/J8H/Ap4wMyuAhwY7+5uZoOBaWa2GygBLnP3bbX7aPEzC8o369YBAwdCfn7wKCKV6tSpEwUFBdSnZCpNq3Xr1uV69MQjuW4ODpx4IqxdC8+MfYbIH84Oulh27lzzhiIiLVjK3Bw8GoUlS+Dzz2HY3SOJclyQ+iIiKSypgj4vD4qLg+nCojTyyIU1axLZJBGRhEuasW4g6FzTqlUw8kFGBuSmLYa1xYlulohIQiXVEX0kAn/9azA9ZYoR+T+bdUQvIikvqYIeYNQoyMoKSzjt28PixboyVkRSWtIFfXp6cOHUmiXb4PXX4YsvNAyCiKS0pAt6gMMPhw/eL4k5M6thEEQkdSVt0H/4VTuKM8OrxzIyNAyCiKSspAz67t2hcHcan9w3P5hx2WUaBkFEUlZSBn14q0emvZZLdL9ToI63IBMRSQZJGfRffx08PvaYMezbfxBdkpQfU0QkLkmZgCtWBI/uUOiZ5K2peJ8UEZHUkZRBP3QopIWfrFVGCbnf/g9sa7RBM0VEmrWkDPpIBE47DfbdFxb85xIivA6rVye6WSIiCZGUQQ9Bb8pvvoEjcn8UzLjjDl00JSIpKWmD/qijgsf33tgRTDzzjK6QFZGUlLRB36NH8Ljq5fD2trpRuIikqKQN+sMOC+4f+16rPsEAOKAbhYtISkraoE9LC+4g+D9v/ojoyFuCmc88oytkRSTlJNWNR2JFo/Dhh8G4ZsM+/iULeJrIPvskulkiIk0uaY/o8/KgpCSYLiwObyv47ruJbJKISEIk7RF9bi5kZgbnXzMyIDdrKbzzdaKbJSLS5OI6ojez4Wa22szWmtm1lSw/1MwWmtlbZrbCzEbELPttuN1qMzu1IRtfnUgEZs8OpidPNiI//gKee07dK0Uk5dQY9GaWDtwDnAb0AMaYWY8Kq10PzHH3vsBo4N5w2x7h86OB4cC94es1iTPPhP33hx1rN8GqVbB+vfrSi0jKieeIfgCw1t3XuXshMBsYVWEdB9qE0/sDn4bTo4DZ7r7L3T8C1oav1yTMoFcvWLGsKKZgr770IpJa4gn6jsCGmOcF4bxYU4GfmlkB8BxwRS22bVS9e8M7Ww6mJDMrmJGerr70IpJSGqrXzRjgUXfvBIwAnjCzuF/bzCaaWb6Z5W/evLmBmhTo1Qt2fJfBxw++FMwYO1Z96UUkpcQTxhuBzjHPO4XzYl0MzAFw9yjQGugQ57a4+0x3z3H3nOzs7PhbH4devYLHG/55ItFO58HWrQ36+iIizV08Qb8U6G5mXc2sFcHJ1XkV1vkEGAZgZkcRBP3mcL3RZpZlZl2B7sAbDdX4eHz7bfA4axYM++wJnYcVkZRTY9C7exFwOfAi8B5B75qVZjbNzEaGq/0KuNTM3gaeBMZ7YCXBkf4q4AXgF+5e3BgfpCpLlpR+DigsySBv0xHw5ZdN2QQRkYQyd090G8rJycnx/Pz8Bnu9aBQGDQqGQvhBVjELdp1I5JJjYMIE1epFJGmY2TJ3z6lsWdIOgVAqEoFJk4Lpp65dFtxt6qGH1J9eRFJG0gc9wDnnBI/pH38UTGhsehFJISkR9H37Bo/LWkVi7hquselFJDWkRNDvvz907w7LNh8KEycGMzU2vYikiJQIegjuOPXKKxDtMSGYYZbYBomINJGUCPpoFBYtgu3b4aSrc4gSgTeatDu/iEjCpETQ5+UF3SsBCguNvOzzFPQikjJSIuhzcyErHNMsLQ1yf7wBFi6ExYsT2i4RkaaQEkEficCCBfCjH0Gvbt8QWfbf8M036ksvIikhJYIegrA/+2xYvb4VxUXh1cDqSy8iKSBlgh7guOPg28JWXJX2J6IcF/S8UV96EUlyKRX0rVoFj/9dMolh9grRA0epL72IJL2UCvo1a4JHd6OQVuR9djhs25bYRomINLKUCvqhQ4M7CUI4AgJ5cNVVOiErIkktpYI+EoErwrvZ/uW6VcFIlk88od43IpLUUiroAcaPDx6/fXd9MKGRLEUkyaVc0PfsCW3bwqKdAyAjI5ipkSxFJImlXNCnpcHRR8Mz/zqI6BV/DWbedJN634hI0kq5oI9Gg/vIbtsGJ913LtGMQfDZZ4lulohIo0m5oK90gLMnn9TJWBFJWikX9LEDnBlO7hdz4NNP1fNGRJJWygV96QBnvXtDm6zvGVgShvuuXep5IyJJKa6gN7PhZrbazNaa2bWVLL/TzJaH/z4ws69ilhXHLJvXgG2vs0gEpkyBL7//IVPS7ta4NyKS1DJqWsHM0oF7gJOBAmCpmc1z91Wl67j7VTHrXwH0jXmJ7929T4O1uIG0axc8/nfJJB60i1iwz1lEjjsusY0SEWkE8RzRDwDWuvs6dy8EZgOjqll/DPBkQzSuMa1cGTy6G4WWRd7XfWHyZNXpRSTpxBP0HYENMc8Lwnl7MbPDgK7AKzGzW5tZvpm9bmZnVrHdxHCd/M2bN8fX8nrKzY25XirDg3Fv7rlHJ2VFJOk09MnY0cDf3L04Zt5h7p4DXADcZWY/rriRu8909xx3z8nOzm7gJlUuEoE//zmY/t2Q/w3GvdFwCCKShOIJ+o1A55jnncJ5lRlNhbKNu28MH9cBeZSv3yfUpZfCfvvB39b3J5p+YjAzM1MnZUUkqcQT9EuB7mbW1cxaEYT5Xr1nzOxIoC0QjZnX1syywukOwAnAqorbJsobb8B338HyNfsyLH1h0PtmyhQNhyAiSaXGoHf3IuBy4EXgPWCOu680s2lmNjJm1dHAbHf3mHlHAflm9jawELg1trdOouXlBdUagF1F6eTtNxKeflo1ehFJKlY+lxMvJyfH8/Pzm+S9otHg3Ov330NGegmvMoRI8f/CD34QXFWlI3sRaSHMbFl4PnQvKXdlbKzSq2SPPhr2z/qeASWvBwt0layIJJGUDnoIwv7662Hrd/swKW1GUKcHnZAVkaSR8kEPUNqj88HiCQxLW0iUCBx5ZGIbJSLSQBT0BL1vAByjkCzySgbBJZfopKyIJAUFPUGVplWrYDo93cllUdD7RlfJikgSUNAT1OlffjkYp77Tvtv3LNBVsiKSBBT0oYyM4M5T6748gGEs0NDFIpI0FPShvDwoKQEwdllr8tqdA23awMKFKt+ISIumoA/F3mLQMYac2Ta4g/jvf69avYi0aAr6UOnFU2efHQyL8NiKPkH5pqREtXoRadEU9DEiEfjFL4Lpmfn9ytfq27dPbONEROpIQV/BkiVBroNRaK3JIxeKioJRLVW+EZEWSEFfQWytHpxPODQ4qlf5RkRaKAV9BZEIvPIKdOsGxZ7GA1walnAi6mopIi2Sgr4SkQiceiqAUUwGhbQir/WpwTeAyjci0sIo6Kvws59BWrh3LM1o/+3HcMMN6mopIi2Ogr4KkQj88pfBdHFJGlP4E9GSAarVi0iLo6CvRrt2wWMwqmVm0AMH1NVSRFoUBX01yvXAsbSgB07xsepqKSItioK+GpFIMNRN164VeuDs7KvyjYi0GAr6GkQicNZZwXTQAyeTPB8M69bpqF5EWgQFfRzOPRcyMix4YkZ7tsBDD6kHjoi0CHEFvZkNN7PVZrbWzK6tZPmdZrY8/PeBmX0Vs2ycma0J/41rwLY3mUgE/vjHYLrY04MeOD4Qdu6Exx9PbONERGpQY9CbWTpwD3Aa0AMYY2Y9Ytdx96vcvY+79wH+DDwdbtsOuBEYCAwAbjSztg36CZrIt9+W9qs3vieLqdwYhP0jj+ioXkSatXiO6AcAa919nbsXArOBUdWsPwZ4Mpw+FXjJ3be5+5fAS8Dw+jQ4UcqPgZPGy5wcnJjd1Q+mTlXYi0izFU/QdwQ2xDwvCOftxcwOA7oCr9RmWzObaGb5Zpa/efPmeNrd5ErHqx8yJHheQjo7yeJxfhbccFb1ehFpphr6ZOxo4G/uXlybjdx9prvnuHtOdnZ2Azep4UQicMste07MOmk8wkW6YlZEmrV4gn4j0DnmeadwXmVGs6dsU9ttW4RIBC65pPRZcMXsVG4kWjJQV8yKSLMUT9AvBbqbWVcza0UQ5vMqrmRmRwJtgdj6xYvAKWbWNjwJe0o4r0UbOxZ+8INg2kvr9f4S0Sv+qvKNiDQ7NQa9uxcBlxME9HvAHHdfaWbTzGxkzKqjgdnu7jHbbgNuIviyWApMC+e1aKX1+sGDg+dl9frCf4ff/U5hLyLNisXkcrOQk5Pj+fn5iW5GXKJRGDKohN3FQc0+i10sZCiRjHy45x6YODHBLRSRVGFmy9w9p7JlujK2HiIRuPjS0l1o7KIVNzCVaFEOXH65juxFpFlQ0NdTUK83DKe0f/1gFjFz9zj1rxeRZkFBX0+l9fqTTzEIw76ITH7BPUT/uUP960Uk4RT0DSASCQ7eg/71DhhFZPJ7/i/R7/toPBwRSSgFfQOJRILzr5mZpWEPC/hJUMa5vwQmTdKRvYgkhIK+AU2cCIsWwSmnxB7ZZ/Affg+TZvQimvtbhb2INDkFfQMrK+OkQ2nYF5PODH7O4MJ/MvPaDxPbQBFJOQr6RhCJwD33ppGZ7hgl4dzgJO1/vDqaST3yiM58J6FtFJHUoaBvJBMnwqLX0vj5ZWmkWwnlju7fG8zgnx/BzJ8uSnQzRSQFKOgbUSQC990H9/5mPZns3vvoftYJTDp6kY7uRaRRKeibwMTbfsyi+1fz86NeI50iyh3drxpE7s+7K/BFpNEo6JtIZGJP7ls1hHsvXLzX0X0hWcxYNUjlHBFpFAr6JjbxL0PKju6z2FVpOeesrm8x6axN6okpIg1Co1cmUHTmOzx+1zYeeO94iskALFwS/Ewy04u5+NIMxo4N6v0iIlXR6JXN1N7lnGJK6/dg7C5OZ8YMZ/CgEmbOTHBjRaTFUtA3A3vKOf9LJoUEYV/6l5ZRVGxM+nkJI49arZKOiNSaSjfNTPSauTz+h8/Z5Nk8y79VWtLJSCvhjJHpHHwwKuuICFB96UZB3xxFo/D448y8v4TL/c8UkY6Txp7Ah7I6fqZx8cUKfJFUp6BvqWbOJPofT/B48QU8xAR20ypmYfmj/PQ051e/TuOAAyA3V6EvkmoU9C1ZNAp5eURXtuHxv2awybOZz+nVhL6RkQG//CUKfZEUoqBPFmFJJzrzHR4vuZBNHFShjl/aYwcU+iKppd5Bb2bDgT8B6cCD7n5rJeucD0wlSJi33f2CcH4xUHpt/yfuPrK691LQx2HmzODm40VFzPSLuZx7KCINJz1cYe/QNzMyM2HECHQSVyQJ1SvozSwd+AA4GSgAlgJj3H1VzDrdgTnASe7+pZkd6O5fhMu+cfd9422sgj5OYUmHr74i+sfF5BUP4iv2405+VWPoA6SnG2ecAYccotAXSQb1DfoIMNXdTw2f/xbA3W+JWed24AN3f7CS7RX0jS0s6fDQQ0R39yePXL6iTbnQN0qq7Lmj0Bdp+aoL+ow4tu8IbIh5XgAMrLDO4eEb/YugvDPV3V8Il7U2s3ygCLjV3efWou0Sj0gk+Dd2LJHHHyey6X2YP58zd88jj1zas4W36Fdlz53iYvjHP4LQf+AB49RT4dBDoW9f2LpVtX2Rli6eoI/3dboDuUAn4FUz6+nuXwGHuftGM+sGvGJm77h7ufvpmdlEYCLAoYce2kBNSkGlgQ8Qje4J/eefh90PM7bkcR5nLJs4qMqeO8XF8NxzXm6eTuiKtGzxBP1GoHPM807hvFgFwBJ33w18ZGYfEAT/UnffCODu68wsD+gLlAt6d58JzISgdFOHzyEVVQh98vKIfPUVkTuvhKIioj6wxtAvVVTk3H67Ql+kpYqnRp9BcDJ2GEHALwUucPeVMesMJzhBO87MOgBvAX2AEuA7d98Vzo8Co2JP5FakGn0jizmJy513xhH6UP6E7p4Tu+np8KtfwddfB2upvi+SOA3RvXIEcBdB/f1hd59uZtOAfHefZ2YG/BEYDhQD0919tpkdD9xPEPhpwF3u/lB176Wgb0LVhD5AG76KoxfPHhkZcMklqu2LJIIumJKaVRL6uBPluEp78QSqDn1QmUekKSnopXbqFPqlVOYRSQQFvdRdDaFf2nVzEwfxPCPYTQYlcZZ5zjhDV+mKNBQFvTSMKkK/bHEdyzzp6XDyydCli+r7InWloJeGV1Xom9WyzFO50vq+Sj0i8VHQS+MqDf327YPD8TjKPDUNtVxRZiacfrpKPSJVUdBL04ujzBN/3/3y0tPhoovg2GPhrbeCeQp/SXUKekmsOEMfquq7X6rqUo+O+CXVKeil+Ygt87z1FmzaBPPnw+7de1aJu9RT9RH/aadBp046uSupQ0EvzVvpMMuVhH7ZKjGlnr27cZbSyV1JXQp6aTlKQx+gTZtqu3HW5+Su+vFLslHQS8tVQzfOstXqeXL3pJOgWzfo10+lHmmZFPSSHGroxlm2WgOc3E1PD0o9bdvueTuFvzRnCnpJXg16chfiGaRNdX5pjhT0klpqeXI3/jH4y38JxNb51btHEk1BL6krzpO7VZV6jOK4h2U221Py0VG/NDUFvUipWpZ6ttKhzuP1gC7kkqajoBepTnVH/RUGaau+zg819e4ZMgS6d1fvHml4CnqR2mji3j2XXw4HHaTePVI/CnqR+qphvB5Q7x5JLAW9SEOKo85ftmqdeveUV/HGLBqxUyqjoBdpbE3Su6f8vNgTvereKQp6kabWaL17vIrpgMo+qaveQW9mw4E/AenAg+5+ayXrnA9MJfjte9vdLwjnjwOuD1e72d0fq+69FPSStBq0d0+p6o/6MzKCo/5DDtFRf7KrV9CbWTrwAXAyUAAsBca4+6qYdboDc4CT3P1LMzvQ3b8ws3ZAPpBD8Bu4DOjv7l9W9X4KekkZdejd05c369y9E4Lvk8zMYLx+hX9yqS7oM+LYfgCw1t3XhS82GxgFrIpZ51LgntIAd/cvwvmnAi+5+7Zw25eA4cCTdfkgIkklEtk7Xc88s3zJB4i0aUPkzitr2b0z9gBuT6nH3SgshH/8o/zbquST3OIJ+o7AhpjnBcDACuscDmBm/yIo70x19xeq2LZjnVsrkuwqC3/Y+wtg0yYi8+cT2f36nlWYV2PZxyjBMSrW+YuK4Pbb9/wl8MAD6umTTOIJ+nhfpzuQC3QCXjWznvFubGYTgYkAhx56aAM1SSSJVPYFUKHmH7nzTiJFS2os+zzEhAoln71LPcXF8MILey978EEN5NYSxRP0G4HOMc87hfNiFQBL3H038JGZfUAQ/BsJwj9227yKb+DuM4GZENTo42y7SGqrGP5xHPVjxlh/vBYln/I1/6IimDu3fDNU9mn+4jkZm0FwMnYYQXAvBS5w95Ux6wwnOEE7zsw6AG8BfdhzArZfuOqbBCdjt1X1fjoZK9KAYo/6S2swDz1Uh/H6Y1Xf1TM9Hc49F4YOheXL97y1jv4bV0N0rxwB3EVQf3/Y3aeb2TQg393nmZkBfyQ40VoMTHf32eG2E4Drwpea7u6PVPdeCnqRRlZZ+Ffo598wPX3Uz78p6YIpEalZPa/uLa+68IfYo//TToNOnXTSt74U9CJSe3W8TePzjGA3GZTsFf5Q+RdA+fAHXehVFwp6EWkYcZZ98hhKezbzVnh6Lr5hnKv/AkhPhyuvhA4dyl1moKP/kIJeRBpXAk76ltLRf0BBLyJNr1FP+tZ89D9lCnz77Z63T/YvAAW9iDQfDTqkc6mqjv7LL6/Y6yeZvgAU9CLSfFU86Qt7fQFUHNK5PvfujafbZ0v8AlDQi0jLU1mvn+efD8o+JSV7Vou7yyfU5gugdKTPESNaxpAPCnoRSQ61PPqPr9cP1PwFALHlnyuvbH71fwW9iCS3RvkCKA3++Ov/U6bAN98Ec5v6C0BBLyKpqQ4XfUF1I31CfEf/0NRfAAp6EZFScXT7BMCMqA+sR/2/5r8Arrwy+A5qiAvAFPQiIjWp+AVQye0dG6b+X/0XQFYWLFxY+7Cv760ERUSSXxx394q89RYRvoI27SDm9o4V7+4FNY31Hxv2Vm5ZYaGTl2cNWtZR0IuIVKeRvwCMonJfBK18F7nt1wBx36SvRgp6EZG6aKAvgK1klxsAbixPENn6bzRk0KtGLyLSFCrrAlrZAHB1LNKrRi8ikmhV/QUAQVeb0hPBjTDusoJeRCTRqvsSaABpjfbKIiLSLCjoRUSSnIJeRCTJKehFRJKcgl5EJMkp6EVEklyzu2DKzDYDH9fjJToAWxqoOQ1J7aqd5touaL5tU7tqp7m2C+rWtsPcPbuyBc0u6OvLzPKrujoskdSu2mmu7YLm2za1q3aaa7ug4dum0o2ISJJT0IuIJLlkDPqZiW5AFdSu2mmu7YLm2za1q3aaa7uggduWdDV6EREpLxmP6EVEJEbSBL2ZDTez1Wa21syuTWA7OpvZQjNbZWYrzezKcP5UM9toZsvDfyMS1L71ZvZO2Ib8cF47M3vJzNaEj22buE1HxOyX5Wb2tZlNScQ+M7OHzewLM3s3Zl6l+8cCd4e/cyvMrF8Tt+sPZvZ++N7PmNkB4fwuZvZ9zH6b0VjtqqZtVf7szOy34T5bbWanNnG7/l9Mm9ab2fJwfpPts2oyovF+z9y9xf8D0oEPgW5AK+BtoEeC2nII0C+c3g/4AOgBTAV+3Qz21XqgQ4V5twPXhtPXArcl+Ge5CTgsEfsMGAz0A96taf8AI4DnCW76eRywpInbdQqQEU7fFtOuLrHrJWifVfqzC/8vvA1kAV3D/7fpTdWuCsv/CNzQ1PusmoxotN+zZDmiHwCsdfd17l4IzAZGJaIh7v6Zu78ZTu8A3gM6JqIttTAKeCycfgw4M3FNYRjwobvX56K5OnP3V4FtFWZXtX9GAY974HXgADM7pKna5e7/dPei8OnrQKfGeO+aVLHPqjIKmO3uu9z9I2Atwf/fJm2XmRlwPvBkY7x3darJiEb7PUuWoO8IbIh5XkAzCFcz6wL0BZaEsy4P//R6uKnLIzEc+KeZLTOzieG8g9z9s3B6E3BQYpoGwGjK/+drDvusqv3TnH7vJhAc9ZXqamZvmdkiMxuUoDZV9rNrLvtsEPC5u6+Jmdfk+6xCRjTa71myBH2zY2b7An8Hprj718B9wI+BPsBnBH82JsKJ7t4POA34hZkNjl3owd+KCemKZWatgJHAU+Gs5rLPyiRy/1TFzH4HFAGzwlmfAYe6e1/gl8BfzaxNEzer2f3sKhhD+QOKJt9nlWREmYb+PUuWoN8IdI553imclxBmlknwA5zl7k8DuPvn7l7s7iXAAzTSn6s1cfeN4eMXwDNhOz4v/VMwfPwiEW0j+PJ5090/D9vYLPYZVe+fhP/emdl44AzgwjAcCMsiW8PpZQR18MObsl3V/Oyawz7LAM4G/l/pvKbeZ5VlBI34e5YsQb8U6G5mXcOjwtHAvEQ0JKz9PQS85+7/FTM/tqZ2FvBuxW2boG37mNl+pdMEJ/PeJdhX48LVxgH/aOq2hcodZTWHfRaqav/MA8aGvSKOA7bH/Ond6MxsOHA1MNLdv4uZn21m6eF0N6A7sK6p2hW+b1U/u3nAaDPLMrOuYdveaMq2AT8B3nf3gtIZTbnPqsoIGvP3rCnOMjfFP4Iz0x8QfBP/LoHtOJHgT64VwPLw3wjgCeCdcP484JAEtK0bQY+Ht4GVpfsJaA8sANYALwPtEtC2fYCtwP4x85p8nxF80XwG7CaohV5c1f4h6AVxT/g79w6Q08TtWktQuy39PZsRrntO+PNdDrwJ/FsC9lmVPzvgd+E+Ww2c1pTtCuc/ClxWYd0m22fVZESj/Z7pylgRkSSXLKUbERGpgoJeRCTJKehFRJKcgl5EJMkp6EVEkpyCXkQkySnoRUSSnIJeRCTJ/X8lR2PqcBOV3QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5688 - accuracy: 0.7066 - val_loss: 0.5714 - val_accuracy: 0.7031\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.7066 - val_loss: 0.5710 - val_accuracy: 0.7031\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5681 - accuracy: 0.7066 - val_loss: 0.5706 - val_accuracy: 0.7031\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5677 - accuracy: 0.7066 - val_loss: 0.5702 - val_accuracy: 0.7031\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5673 - accuracy: 0.7066 - val_loss: 0.5698 - val_accuracy: 0.7083\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5669 - accuracy: 0.7101 - val_loss: 0.5694 - val_accuracy: 0.7083\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5665 - accuracy: 0.7083 - val_loss: 0.5690 - val_accuracy: 0.7083\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5661 - accuracy: 0.7101 - val_loss: 0.5686 - val_accuracy: 0.7083\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5657 - accuracy: 0.7101 - val_loss: 0.5682 - val_accuracy: 0.7083\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5653 - accuracy: 0.7135 - val_loss: 0.5679 - val_accuracy: 0.7083\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5649 - accuracy: 0.7135 - val_loss: 0.5675 - val_accuracy: 0.7083\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5645 - accuracy: 0.7170 - val_loss: 0.5671 - val_accuracy: 0.7083\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5641 - accuracy: 0.7170 - val_loss: 0.5667 - val_accuracy: 0.7135\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5638 - accuracy: 0.7170 - val_loss: 0.5663 - val_accuracy: 0.7083\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5633 - accuracy: 0.7153 - val_loss: 0.5659 - val_accuracy: 0.7083\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5630 - accuracy: 0.7170 - val_loss: 0.5656 - val_accuracy: 0.7083\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5626 - accuracy: 0.7170 - val_loss: 0.5652 - val_accuracy: 0.7083\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5622 - accuracy: 0.7188 - val_loss: 0.5648 - val_accuracy: 0.7135\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5618 - accuracy: 0.7188 - val_loss: 0.5644 - val_accuracy: 0.7135\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5615 - accuracy: 0.7188 - val_loss: 0.5641 - val_accuracy: 0.7135\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5611 - accuracy: 0.7205 - val_loss: 0.5637 - val_accuracy: 0.7135\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5607 - accuracy: 0.7188 - val_loss: 0.5633 - val_accuracy: 0.7135\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5604 - accuracy: 0.7153 - val_loss: 0.5629 - val_accuracy: 0.7135\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5600 - accuracy: 0.7153 - val_loss: 0.5626 - val_accuracy: 0.7135\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5596 - accuracy: 0.7170 - val_loss: 0.5622 - val_accuracy: 0.7135\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5592 - accuracy: 0.7170 - val_loss: 0.5618 - val_accuracy: 0.7188\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5589 - accuracy: 0.7170 - val_loss: 0.5615 - val_accuracy: 0.7240\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.7170 - val_loss: 0.5611 - val_accuracy: 0.7240\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5582 - accuracy: 0.7188 - val_loss: 0.5608 - val_accuracy: 0.7240\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5578 - accuracy: 0.7170 - val_loss: 0.5604 - val_accuracy: 0.7240\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5574 - accuracy: 0.7170 - val_loss: 0.5600 - val_accuracy: 0.7292\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5570 - accuracy: 0.7205 - val_loss: 0.5597 - val_accuracy: 0.7292\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5567 - accuracy: 0.7205 - val_loss: 0.5593 - val_accuracy: 0.7344\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5563 - accuracy: 0.7222 - val_loss: 0.5590 - val_accuracy: 0.7344\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5559 - accuracy: 0.7222 - val_loss: 0.5586 - val_accuracy: 0.7344\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5556 - accuracy: 0.7222 - val_loss: 0.5583 - val_accuracy: 0.7344\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.7188 - val_loss: 0.5579 - val_accuracy: 0.7344\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5549 - accuracy: 0.7188 - val_loss: 0.5576 - val_accuracy: 0.7344\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5545 - accuracy: 0.7205 - val_loss: 0.5572 - val_accuracy: 0.7344\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5542 - accuracy: 0.7205 - val_loss: 0.5569 - val_accuracy: 0.7344\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5538 - accuracy: 0.7222 - val_loss: 0.5565 - val_accuracy: 0.7292\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5535 - accuracy: 0.7222 - val_loss: 0.5562 - val_accuracy: 0.7292\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.7240 - val_loss: 0.5558 - val_accuracy: 0.7292\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5528 - accuracy: 0.7257 - val_loss: 0.5555 - val_accuracy: 0.7292\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5524 - accuracy: 0.7257 - val_loss: 0.5551 - val_accuracy: 0.7292\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.7257 - val_loss: 0.5548 - val_accuracy: 0.7292\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.7274 - val_loss: 0.5545 - val_accuracy: 0.7292\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5514 - accuracy: 0.7292 - val_loss: 0.5541 - val_accuracy: 0.7292\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5510 - accuracy: 0.7292 - val_loss: 0.5538 - val_accuracy: 0.7344\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5507 - accuracy: 0.7309 - val_loss: 0.5535 - val_accuracy: 0.7396\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5504 - accuracy: 0.7309 - val_loss: 0.5531 - val_accuracy: 0.7396\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5500 - accuracy: 0.7292 - val_loss: 0.5528 - val_accuracy: 0.7396\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.7292 - val_loss: 0.5525 - val_accuracy: 0.7396\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5493 - accuracy: 0.7292 - val_loss: 0.5521 - val_accuracy: 0.7396\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5490 - accuracy: 0.7292 - val_loss: 0.5518 - val_accuracy: 0.7396\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5486 - accuracy: 0.7274 - val_loss: 0.5515 - val_accuracy: 0.7396\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5483 - accuracy: 0.7274 - val_loss: 0.5511 - val_accuracy: 0.7396\n",
      "Epoch 58/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5480 - accuracy: 0.7309 - val_loss: 0.5508 - val_accuracy: 0.7396\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5476 - accuracy: 0.7309 - val_loss: 0.5505 - val_accuracy: 0.7396\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5473 - accuracy: 0.7309 - val_loss: 0.5502 - val_accuracy: 0.7396\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5470 - accuracy: 0.7309 - val_loss: 0.5499 - val_accuracy: 0.7396\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5466 - accuracy: 0.7309 - val_loss: 0.5495 - val_accuracy: 0.7396\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5463 - accuracy: 0.7292 - val_loss: 0.5492 - val_accuracy: 0.7396\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5460 - accuracy: 0.7292 - val_loss: 0.5489 - val_accuracy: 0.7396\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5456 - accuracy: 0.7292 - val_loss: 0.5486 - val_accuracy: 0.7448\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.7292 - val_loss: 0.5483 - val_accuracy: 0.7448\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5450 - accuracy: 0.7292 - val_loss: 0.5480 - val_accuracy: 0.7500\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5447 - accuracy: 0.7292 - val_loss: 0.5476 - val_accuracy: 0.7500\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5444 - accuracy: 0.7257 - val_loss: 0.5473 - val_accuracy: 0.7500\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5440 - accuracy: 0.7257 - val_loss: 0.5470 - val_accuracy: 0.7500\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5437 - accuracy: 0.7257 - val_loss: 0.5467 - val_accuracy: 0.7500\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5434 - accuracy: 0.7274 - val_loss: 0.5464 - val_accuracy: 0.7500\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.7274 - val_loss: 0.5461 - val_accuracy: 0.7500\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5427 - accuracy: 0.7292 - val_loss: 0.5458 - val_accuracy: 0.7500\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5424 - accuracy: 0.7292 - val_loss: 0.5455 - val_accuracy: 0.7500\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5421 - accuracy: 0.7292 - val_loss: 0.5452 - val_accuracy: 0.7500\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5418 - accuracy: 0.7292 - val_loss: 0.5449 - val_accuracy: 0.7448\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5415 - accuracy: 0.7292 - val_loss: 0.5446 - val_accuracy: 0.7448\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5411 - accuracy: 0.7309 - val_loss: 0.5443 - val_accuracy: 0.7448\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5408 - accuracy: 0.7309 - val_loss: 0.5440 - val_accuracy: 0.7448\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.7292 - val_loss: 0.5437 - val_accuracy: 0.7448\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5402 - accuracy: 0.7292 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.7274 - val_loss: 0.5431 - val_accuracy: 0.7500\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5396 - accuracy: 0.7274 - val_loss: 0.5428 - val_accuracy: 0.7500\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5393 - accuracy: 0.7274 - val_loss: 0.5425 - val_accuracy: 0.7500\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.7274 - val_loss: 0.5422 - val_accuracy: 0.7500\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5387 - accuracy: 0.7309 - val_loss: 0.5419 - val_accuracy: 0.7500\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5384 - accuracy: 0.7309 - val_loss: 0.5416 - val_accuracy: 0.7500\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5381 - accuracy: 0.7292 - val_loss: 0.5413 - val_accuracy: 0.7448\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.5378 - accuracy: 0.7309 - val_loss: 0.5411 - val_accuracy: 0.7448\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5375 - accuracy: 0.7326 - val_loss: 0.5408 - val_accuracy: 0.7448\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5372 - accuracy: 0.7344 - val_loss: 0.5405 - val_accuracy: 0.7448\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7344 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.7378 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.7361 - val_loss: 0.5396 - val_accuracy: 0.7500\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7344 - val_loss: 0.5394 - val_accuracy: 0.7500\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.7344 - val_loss: 0.5391 - val_accuracy: 0.7552\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.7361 - val_loss: 0.5388 - val_accuracy: 0.7552\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.7361 - val_loss: 0.5385 - val_accuracy: 0.7552\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5348 - accuracy: 0.7361 - val_loss: 0.5382 - val_accuracy: 0.7552\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7361 - val_loss: 0.5380 - val_accuracy: 0.7552\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.7344 - val_loss: 0.5377 - val_accuracy: 0.7552\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5339 - accuracy: 0.7326 - val_loss: 0.5374 - val_accuracy: 0.7604\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5336 - accuracy: 0.7326 - val_loss: 0.5372 - val_accuracy: 0.7604\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5333 - accuracy: 0.7326 - val_loss: 0.5369 - val_accuracy: 0.7604\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5330 - accuracy: 0.7326 - val_loss: 0.5366 - val_accuracy: 0.7604\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.7326 - val_loss: 0.5363 - val_accuracy: 0.7604\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5325 - accuracy: 0.7344 - val_loss: 0.5361 - val_accuracy: 0.7604\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5322 - accuracy: 0.7344 - val_loss: 0.5358 - val_accuracy: 0.7604\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5319 - accuracy: 0.7344 - val_loss: 0.5356 - val_accuracy: 0.7604\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7361 - val_loss: 0.5353 - val_accuracy: 0.7604\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5313 - accuracy: 0.7361 - val_loss: 0.5350 - val_accuracy: 0.7604\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5311 - accuracy: 0.7361 - val_loss: 0.5348 - val_accuracy: 0.7656\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5308 - accuracy: 0.7361 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
      "Epoch 115/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7361 - val_loss: 0.5342 - val_accuracy: 0.7708\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5302 - accuracy: 0.7361 - val_loss: 0.5340 - val_accuracy: 0.7708\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5300 - accuracy: 0.7361 - val_loss: 0.5337 - val_accuracy: 0.7708\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5297 - accuracy: 0.7361 - val_loss: 0.5335 - val_accuracy: 0.7708\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5294 - accuracy: 0.7361 - val_loss: 0.5332 - val_accuracy: 0.7708\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.7361 - val_loss: 0.5330 - val_accuracy: 0.7708\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.7361 - val_loss: 0.5327 - val_accuracy: 0.7708\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.7344 - val_loss: 0.5325 - val_accuracy: 0.7708\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5283 - accuracy: 0.7344 - val_loss: 0.5322 - val_accuracy: 0.7760\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5280 - accuracy: 0.7344 - val_loss: 0.5320 - val_accuracy: 0.7760\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5277 - accuracy: 0.7361 - val_loss: 0.5317 - val_accuracy: 0.7708\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5275 - accuracy: 0.7361 - val_loss: 0.5315 - val_accuracy: 0.7708\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.7361 - val_loss: 0.5312 - val_accuracy: 0.7708\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5269 - accuracy: 0.7344 - val_loss: 0.5310 - val_accuracy: 0.7708\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.7361 - val_loss: 0.5307 - val_accuracy: 0.7708\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.7378 - val_loss: 0.5305 - val_accuracy: 0.7708\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5262 - accuracy: 0.7361 - val_loss: 0.5302 - val_accuracy: 0.7708\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5259 - accuracy: 0.7378 - val_loss: 0.5300 - val_accuracy: 0.7708\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7378 - val_loss: 0.5298 - val_accuracy: 0.7708\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.7378 - val_loss: 0.5295 - val_accuracy: 0.7708\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5251 - accuracy: 0.7378 - val_loss: 0.5293 - val_accuracy: 0.7708\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5248 - accuracy: 0.7361 - val_loss: 0.5290 - val_accuracy: 0.7760\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7344 - val_loss: 0.5288 - val_accuracy: 0.7760\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5243 - accuracy: 0.7344 - val_loss: 0.5286 - val_accuracy: 0.7760\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7361 - val_loss: 0.5283 - val_accuracy: 0.7760\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7361 - val_loss: 0.5281 - val_accuracy: 0.7760\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7361 - val_loss: 0.5279 - val_accuracy: 0.7760\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7361 - val_loss: 0.5276 - val_accuracy: 0.7760\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.7361 - val_loss: 0.5274 - val_accuracy: 0.7760\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.7344 - val_loss: 0.5272 - val_accuracy: 0.7812\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.7344 - val_loss: 0.5269 - val_accuracy: 0.7812\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.7326 - val_loss: 0.5267 - val_accuracy: 0.7812\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7326 - val_loss: 0.5265 - val_accuracy: 0.7812\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.7326 - val_loss: 0.5263 - val_accuracy: 0.7812\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7344 - val_loss: 0.5260 - val_accuracy: 0.7812\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5213 - accuracy: 0.7361 - val_loss: 0.5258 - val_accuracy: 0.7812\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.5210 - accuracy: 0.7361 - val_loss: 0.5256 - val_accuracy: 0.7812\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5208 - accuracy: 0.7361 - val_loss: 0.5254 - val_accuracy: 0.7812\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.7361 - val_loss: 0.5251 - val_accuracy: 0.7812\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5203 - accuracy: 0.7361 - val_loss: 0.5249 - val_accuracy: 0.7865\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.7378 - val_loss: 0.5247 - val_accuracy: 0.7865\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5198 - accuracy: 0.7378 - val_loss: 0.5245 - val_accuracy: 0.7865\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5196 - accuracy: 0.7378 - val_loss: 0.5243 - val_accuracy: 0.7865\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5193 - accuracy: 0.7378 - val_loss: 0.5241 - val_accuracy: 0.7865\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5191 - accuracy: 0.7396 - val_loss: 0.5238 - val_accuracy: 0.7865\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5189 - accuracy: 0.7396 - val_loss: 0.5236 - val_accuracy: 0.7865\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5186 - accuracy: 0.7413 - val_loss: 0.5234 - val_accuracy: 0.7865\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5184 - accuracy: 0.7413 - val_loss: 0.5232 - val_accuracy: 0.7865\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5181 - accuracy: 0.7413 - val_loss: 0.5230 - val_accuracy: 0.7865\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5179 - accuracy: 0.7413 - val_loss: 0.5228 - val_accuracy: 0.7865\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5177 - accuracy: 0.7413 - val_loss: 0.5226 - val_accuracy: 0.7865\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5174 - accuracy: 0.7413 - val_loss: 0.5224 - val_accuracy: 0.7865\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5172 - accuracy: 0.7413 - val_loss: 0.5222 - val_accuracy: 0.7865\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5170 - accuracy: 0.7431 - val_loss: 0.5220 - val_accuracy: 0.7865\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5167 - accuracy: 0.7413 - val_loss: 0.5217 - val_accuracy: 0.7865\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.7431 - val_loss: 0.5215 - val_accuracy: 0.7865\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5163 - accuracy: 0.7465 - val_loss: 0.5213 - val_accuracy: 0.7865\n",
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5161 - accuracy: 0.7431 - val_loss: 0.5211 - val_accuracy: 0.7865\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5158 - accuracy: 0.7500 - val_loss: 0.5209 - val_accuracy: 0.7865\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5156 - accuracy: 0.7483 - val_loss: 0.5207 - val_accuracy: 0.7865\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5154 - accuracy: 0.7500 - val_loss: 0.5205 - val_accuracy: 0.7865\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5151 - accuracy: 0.7517 - val_loss: 0.5203 - val_accuracy: 0.7865\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5149 - accuracy: 0.7500 - val_loss: 0.5201 - val_accuracy: 0.7865\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5147 - accuracy: 0.7517 - val_loss: 0.5199 - val_accuracy: 0.7865\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.7517 - val_loss: 0.5197 - val_accuracy: 0.7865\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.5143 - accuracy: 0.7535 - val_loss: 0.5195 - val_accuracy: 0.7865\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5140 - accuracy: 0.7535 - val_loss: 0.5193 - val_accuracy: 0.7865\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5138 - accuracy: 0.7535 - val_loss: 0.5192 - val_accuracy: 0.7865\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5136 - accuracy: 0.7535 - val_loss: 0.5190 - val_accuracy: 0.7865\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5134 - accuracy: 0.7535 - val_loss: 0.5188 - val_accuracy: 0.7865\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5131 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7865\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5129 - accuracy: 0.7535 - val_loss: 0.5184 - val_accuracy: 0.7865\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5127 - accuracy: 0.7552 - val_loss: 0.5182 - val_accuracy: 0.7865\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5125 - accuracy: 0.7552 - val_loss: 0.5180 - val_accuracy: 0.7865\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5123 - accuracy: 0.7552 - val_loss: 0.5178 - val_accuracy: 0.7865\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5121 - accuracy: 0.7552 - val_loss: 0.5176 - val_accuracy: 0.7865\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5118 - accuracy: 0.7552 - val_loss: 0.5174 - val_accuracy: 0.7865\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5116 - accuracy: 0.7552 - val_loss: 0.5173 - val_accuracy: 0.7865\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.7552 - val_loss: 0.5171 - val_accuracy: 0.7865\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5112 - accuracy: 0.7587 - val_loss: 0.5169 - val_accuracy: 0.7865\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5110 - accuracy: 0.7587 - val_loss: 0.5167 - val_accuracy: 0.7865\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5108 - accuracy: 0.7587 - val_loss: 0.5165 - val_accuracy: 0.7865\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5106 - accuracy: 0.7587 - val_loss: 0.5163 - val_accuracy: 0.7865\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5104 - accuracy: 0.7569 - val_loss: 0.5162 - val_accuracy: 0.7865\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5102 - accuracy: 0.7587 - val_loss: 0.5160 - val_accuracy: 0.7865\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5100 - accuracy: 0.7587 - val_loss: 0.5158 - val_accuracy: 0.7865\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5097 - accuracy: 0.7587 - val_loss: 0.5156 - val_accuracy: 0.7865\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5095 - accuracy: 0.7604 - val_loss: 0.5155 - val_accuracy: 0.7865\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5093 - accuracy: 0.7604 - val_loss: 0.5153 - val_accuracy: 0.7865\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5091 - accuracy: 0.7604 - val_loss: 0.5151 - val_accuracy: 0.7865\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5089 - accuracy: 0.7587 - val_loss: 0.5149 - val_accuracy: 0.7865\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5087 - accuracy: 0.7587 - val_loss: 0.5148 - val_accuracy: 0.7865\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5085 - accuracy: 0.7587 - val_loss: 0.5146 - val_accuracy: 0.7865\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5083 - accuracy: 0.7587 - val_loss: 0.5144 - val_accuracy: 0.7865\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5081 - accuracy: 0.7604 - val_loss: 0.5142 - val_accuracy: 0.7865\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5079 - accuracy: 0.7587 - val_loss: 0.5141 - val_accuracy: 0.7865\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5077 - accuracy: 0.7604 - val_loss: 0.5139 - val_accuracy: 0.7917\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5075 - accuracy: 0.7622 - val_loss: 0.5137 - val_accuracy: 0.7917\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5073 - accuracy: 0.7604 - val_loss: 0.5136 - val_accuracy: 0.7917\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5072 - accuracy: 0.7604 - val_loss: 0.5134 - val_accuracy: 0.7917\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5069 - accuracy: 0.7604 - val_loss: 0.5132 - val_accuracy: 0.7917\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5068 - accuracy: 0.7604 - val_loss: 0.5131 - val_accuracy: 0.7812\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5065 - accuracy: 0.7604 - val_loss: 0.5129 - val_accuracy: 0.7812\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5064 - accuracy: 0.7604 - val_loss: 0.5127 - val_accuracy: 0.7812\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5062 - accuracy: 0.7604 - val_loss: 0.5126 - val_accuracy: 0.7812\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5060 - accuracy: 0.7622 - val_loss: 0.5124 - val_accuracy: 0.7812\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5058 - accuracy: 0.7604 - val_loss: 0.5122 - val_accuracy: 0.7812\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5056 - accuracy: 0.7604 - val_loss: 0.5121 - val_accuracy: 0.7812\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5054 - accuracy: 0.7604 - val_loss: 0.5119 - val_accuracy: 0.7812\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5052 - accuracy: 0.7604 - val_loss: 0.5118 - val_accuracy: 0.7812\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5050 - accuracy: 0.7604 - val_loss: 0.5116 - val_accuracy: 0.7865\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5048 - accuracy: 0.7604 - val_loss: 0.5114 - val_accuracy: 0.7865\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5047 - accuracy: 0.7604 - val_loss: 0.5113 - val_accuracy: 0.7865\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5045 - accuracy: 0.7622 - val_loss: 0.5111 - val_accuracy: 0.7865\n",
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5043 - accuracy: 0.7622 - val_loss: 0.5110 - val_accuracy: 0.7865\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5041 - accuracy: 0.7622 - val_loss: 0.5108 - val_accuracy: 0.7865\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5039 - accuracy: 0.7622 - val_loss: 0.5107 - val_accuracy: 0.7865\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5037 - accuracy: 0.7622 - val_loss: 0.5105 - val_accuracy: 0.7865\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5035 - accuracy: 0.7622 - val_loss: 0.5104 - val_accuracy: 0.7865\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5033 - accuracy: 0.7622 - val_loss: 0.5102 - val_accuracy: 0.7865\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.7622 - val_loss: 0.5100 - val_accuracy: 0.7865\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5030 - accuracy: 0.7622 - val_loss: 0.5099 - val_accuracy: 0.7865\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.5028 - accuracy: 0.7622 - val_loss: 0.5097 - val_accuracy: 0.7865\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5026 - accuracy: 0.7622 - val_loss: 0.5096 - val_accuracy: 0.7865\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.5024 - accuracy: 0.7622 - val_loss: 0.5095 - val_accuracy: 0.7865\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5023 - accuracy: 0.7622 - val_loss: 0.5093 - val_accuracy: 0.7865\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5021 - accuracy: 0.7622 - val_loss: 0.5092 - val_accuracy: 0.7865\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5019 - accuracy: 0.7639 - val_loss: 0.5090 - val_accuracy: 0.7865\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5017 - accuracy: 0.7639 - val_loss: 0.5089 - val_accuracy: 0.7865\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 0.5015 - accuracy: 0.7639 - val_loss: 0.5087 - val_accuracy: 0.7917\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.5014 - accuracy: 0.7639 - val_loss: 0.5086 - val_accuracy: 0.7917\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.5012 - accuracy: 0.7639 - val_loss: 0.5084 - val_accuracy: 0.7917\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.5010 - accuracy: 0.7639 - val_loss: 0.5083 - val_accuracy: 0.7917\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5009 - accuracy: 0.7639 - val_loss: 0.5081 - val_accuracy: 0.7917\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.5007 - accuracy: 0.7639 - val_loss: 0.5080 - val_accuracy: 0.7917\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.5005 - accuracy: 0.7639 - val_loss: 0.5079 - val_accuracy: 0.7917\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.5003 - accuracy: 0.7639 - val_loss: 0.5077 - val_accuracy: 0.7917\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 0.5002 - accuracy: 0.7639 - val_loss: 0.5076 - val_accuracy: 0.7917\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.7639 - val_loss: 0.5074 - val_accuracy: 0.7917\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4999 - accuracy: 0.7639 - val_loss: 0.5073 - val_accuracy: 0.7917\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4997 - accuracy: 0.7639 - val_loss: 0.5072 - val_accuracy: 0.7917\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4995 - accuracy: 0.7639 - val_loss: 0.5070 - val_accuracy: 0.7917\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4993 - accuracy: 0.7639 - val_loss: 0.5069 - val_accuracy: 0.7917\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4992 - accuracy: 0.7622 - val_loss: 0.5068 - val_accuracy: 0.7917\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4990 - accuracy: 0.7622 - val_loss: 0.5066 - val_accuracy: 0.7969\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4988 - accuracy: 0.7622 - val_loss: 0.5065 - val_accuracy: 0.7969\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4987 - accuracy: 0.7622 - val_loss: 0.5064 - val_accuracy: 0.7969\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4985 - accuracy: 0.7639 - val_loss: 0.5062 - val_accuracy: 0.7969\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4983 - accuracy: 0.7622 - val_loss: 0.5061 - val_accuracy: 0.7969\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4982 - accuracy: 0.7656 - val_loss: 0.5060 - val_accuracy: 0.7969\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4980 - accuracy: 0.7639 - val_loss: 0.5058 - val_accuracy: 0.7969\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4978 - accuracy: 0.7656 - val_loss: 0.5057 - val_accuracy: 0.7969\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4977 - accuracy: 0.7656 - val_loss: 0.5056 - val_accuracy: 0.7969\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.7656 - val_loss: 0.5054 - val_accuracy: 0.7969\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4974 - accuracy: 0.7656 - val_loss: 0.5053 - val_accuracy: 0.7969\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4972 - accuracy: 0.7656 - val_loss: 0.5052 - val_accuracy: 0.7969\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4971 - accuracy: 0.7656 - val_loss: 0.5051 - val_accuracy: 0.7969\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4969 - accuracy: 0.7656 - val_loss: 0.5049 - val_accuracy: 0.7969\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4967 - accuracy: 0.7656 - val_loss: 0.5048 - val_accuracy: 0.7969\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4966 - accuracy: 0.7656 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4964 - accuracy: 0.7656 - val_loss: 0.5045 - val_accuracy: 0.7917\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4963 - accuracy: 0.7656 - val_loss: 0.5044 - val_accuracy: 0.7917\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4961 - accuracy: 0.7656 - val_loss: 0.5043 - val_accuracy: 0.7917\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.7656 - val_loss: 0.5042 - val_accuracy: 0.7917\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4958 - accuracy: 0.7656 - val_loss: 0.5041 - val_accuracy: 0.7917\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4957 - accuracy: 0.7656 - val_loss: 0.5039 - val_accuracy: 0.7917\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4955 - accuracy: 0.7656 - val_loss: 0.5038 - val_accuracy: 0.7917\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4953 - accuracy: 0.7656 - val_loss: 0.5037 - val_accuracy: 0.7917\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4952 - accuracy: 0.7656 - val_loss: 0.5036 - val_accuracy: 0.7917\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.7656 - val_loss: 0.5034 - val_accuracy: 0.7917\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4949 - accuracy: 0.7656 - val_loss: 0.5033 - val_accuracy: 0.7917\n",
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.7656 - val_loss: 0.5032 - val_accuracy: 0.7917\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4946 - accuracy: 0.7656 - val_loss: 0.5031 - val_accuracy: 0.7917\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.7656 - val_loss: 0.5030 - val_accuracy: 0.7917\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.7656 - val_loss: 0.5029 - val_accuracy: 0.7917\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4942 - accuracy: 0.7656 - val_loss: 0.5027 - val_accuracy: 0.7917\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.7656 - val_loss: 0.5026 - val_accuracy: 0.7917\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.7656 - val_loss: 0.5025 - val_accuracy: 0.7917\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4937 - accuracy: 0.7656 - val_loss: 0.5024 - val_accuracy: 0.7917\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4936 - accuracy: 0.7656 - val_loss: 0.5023 - val_accuracy: 0.7865\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4934 - accuracy: 0.7656 - val_loss: 0.5022 - val_accuracy: 0.7865\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.7656 - val_loss: 0.5021 - val_accuracy: 0.7865\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.7656 - val_loss: 0.5020 - val_accuracy: 0.7865\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.7656 - val_loss: 0.5018 - val_accuracy: 0.7865\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.7656 - val_loss: 0.5017 - val_accuracy: 0.7865\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.7656 - val_loss: 0.5016 - val_accuracy: 0.7865\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.7656 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4925 - accuracy: 0.7656 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7656 - val_loss: 0.5013 - val_accuracy: 0.7865\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4921 - accuracy: 0.7656 - val_loss: 0.5012 - val_accuracy: 0.7865\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4920 - accuracy: 0.7674 - val_loss: 0.5011 - val_accuracy: 0.7865\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4919 - accuracy: 0.7674 - val_loss: 0.5010 - val_accuracy: 0.7865\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4917 - accuracy: 0.7674 - val_loss: 0.5009 - val_accuracy: 0.7812\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.7674 - val_loss: 0.5008 - val_accuracy: 0.7812\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7674 - val_loss: 0.5007 - val_accuracy: 0.7812\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7674 - val_loss: 0.5005 - val_accuracy: 0.7812\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4912 - accuracy: 0.7674 - val_loss: 0.5004 - val_accuracy: 0.7812\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4911 - accuracy: 0.7674 - val_loss: 0.5003 - val_accuracy: 0.7812\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7674 - val_loss: 0.5002 - val_accuracy: 0.7812\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.7674 - val_loss: 0.5001 - val_accuracy: 0.7812\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.7674 - val_loss: 0.5000 - val_accuracy: 0.7812\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4905 - accuracy: 0.7674 - val_loss: 0.4999 - val_accuracy: 0.7812\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4904 - accuracy: 0.7691 - val_loss: 0.4998 - val_accuracy: 0.7812\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4903 - accuracy: 0.7691 - val_loss: 0.4997 - val_accuracy: 0.7812\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4901 - accuracy: 0.7691 - val_loss: 0.4996 - val_accuracy: 0.7812\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4900 - accuracy: 0.7691 - val_loss: 0.4995 - val_accuracy: 0.7812\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4899 - accuracy: 0.7691 - val_loss: 0.4994 - val_accuracy: 0.7812\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4897 - accuracy: 0.7691 - val_loss: 0.4993 - val_accuracy: 0.7812\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.7691 - val_loss: 0.4992 - val_accuracy: 0.7760\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4895 - accuracy: 0.7691 - val_loss: 0.4991 - val_accuracy: 0.7760\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4893 - accuracy: 0.7691 - val_loss: 0.4990 - val_accuracy: 0.7760\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4892 - accuracy: 0.7691 - val_loss: 0.4989 - val_accuracy: 0.7760\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.7708 - val_loss: 0.4988 - val_accuracy: 0.7760\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4890 - accuracy: 0.7674 - val_loss: 0.4987 - val_accuracy: 0.7760\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.7691 - val_loss: 0.4986 - val_accuracy: 0.7760\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4887 - accuracy: 0.7691 - val_loss: 0.4986 - val_accuracy: 0.7760\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7674 - val_loss: 0.4985 - val_accuracy: 0.7760\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4885 - accuracy: 0.7674 - val_loss: 0.4984 - val_accuracy: 0.7760\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4883 - accuracy: 0.7674 - val_loss: 0.4983 - val_accuracy: 0.7760\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4882 - accuracy: 0.7674 - val_loss: 0.4982 - val_accuracy: 0.7760\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.7674 - val_loss: 0.4981 - val_accuracy: 0.7760\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.7674 - val_loss: 0.4980 - val_accuracy: 0.7760\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4878 - accuracy: 0.7674 - val_loss: 0.4979 - val_accuracy: 0.7760\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.7674 - val_loss: 0.4978 - val_accuracy: 0.7708\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.7674 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7674 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4874 - accuracy: 0.7674 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4872 - accuracy: 0.7674 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4871 - accuracy: 0.7674 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.7674 - val_loss: 0.4973 - val_accuracy: 0.7708\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4869 - accuracy: 0.7691 - val_loss: 0.4972 - val_accuracy: 0.7708\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.7691 - val_loss: 0.4971 - val_accuracy: 0.7708\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7691 - val_loss: 0.4970 - val_accuracy: 0.7708\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4865 - accuracy: 0.7691 - val_loss: 0.4969 - val_accuracy: 0.7708\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4864 - accuracy: 0.7691 - val_loss: 0.4968 - val_accuracy: 0.7708\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4863 - accuracy: 0.7691 - val_loss: 0.4968 - val_accuracy: 0.7708\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.7691 - val_loss: 0.4967 - val_accuracy: 0.7708\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.7674 - val_loss: 0.4966 - val_accuracy: 0.7708\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.7674 - val_loss: 0.4965 - val_accuracy: 0.7708\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.7691 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7674 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4856 - accuracy: 0.7674 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7691 - val_loss: 0.4962 - val_accuracy: 0.7708\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4854 - accuracy: 0.7674 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4853 - accuracy: 0.7674 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4852 - accuracy: 0.7674 - val_loss: 0.4959 - val_accuracy: 0.7656\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4850 - accuracy: 0.7674 - val_loss: 0.4958 - val_accuracy: 0.7656\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.7674 - val_loss: 0.4958 - val_accuracy: 0.7656\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.7674 - val_loss: 0.4957 - val_accuracy: 0.7656\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.7674 - val_loss: 0.4956 - val_accuracy: 0.7656\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7674 - val_loss: 0.4955 - val_accuracy: 0.7656\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7674 - val_loss: 0.4955 - val_accuracy: 0.7656\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7674 - val_loss: 0.4954 - val_accuracy: 0.7656\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7674 - val_loss: 0.4953 - val_accuracy: 0.7656\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7674 - val_loss: 0.4952 - val_accuracy: 0.7656\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7674 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4839 - accuracy: 0.7691 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7691 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4837 - accuracy: 0.7691 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4836 - accuracy: 0.7691 - val_loss: 0.4948 - val_accuracy: 0.7656\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7691 - val_loss: 0.4948 - val_accuracy: 0.7656\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4834 - accuracy: 0.7691 - val_loss: 0.4947 - val_accuracy: 0.7656\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7691 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4832 - accuracy: 0.7691 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.7691 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4830 - accuracy: 0.7691 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4829 - accuracy: 0.7691 - val_loss: 0.4943 - val_accuracy: 0.7656\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.7691 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.7691 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.7691 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.7691 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 0.7691 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4823 - accuracy: 0.7691 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7691 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4821 - accuracy: 0.7691 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4820 - accuracy: 0.7691 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.7691 - val_loss: 0.4936 - val_accuracy: 0.7656\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7691 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.7674 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.7691 - val_loss: 0.4934 - val_accuracy: 0.7656\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.7691 - val_loss: 0.4933 - val_accuracy: 0.7656\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.7691 - val_loss: 0.4933 - val_accuracy: 0.7656\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.7674 - val_loss: 0.4932 - val_accuracy: 0.7656\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.7691 - val_loss: 0.4931 - val_accuracy: 0.7656\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.7674 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4810 - accuracy: 0.7674 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4809 - accuracy: 0.7674 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.7674 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4807 - accuracy: 0.7674 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.7674 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.7674 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.7674 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7674 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.7674 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7674 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7691 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7691 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4799 - accuracy: 0.7674 - val_loss: 0.4922 - val_accuracy: 0.7708\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4798 - accuracy: 0.7674 - val_loss: 0.4922 - val_accuracy: 0.7708\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7674 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.7708 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7708 - val_loss: 0.4920 - val_accuracy: 0.7708\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.7708 - val_loss: 0.4919 - val_accuracy: 0.7708\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.7708 - val_loss: 0.4919 - val_accuracy: 0.7708\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.7708 - val_loss: 0.4918 - val_accuracy: 0.7760\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7708 - val_loss: 0.4918 - val_accuracy: 0.7760\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4791 - accuracy: 0.7708 - val_loss: 0.4917 - val_accuracy: 0.7760\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4790 - accuracy: 0.7708 - val_loss: 0.4917 - val_accuracy: 0.7760\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7708 - val_loss: 0.4916 - val_accuracy: 0.7760\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7760\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7760\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.7708 - val_loss: 0.4914 - val_accuracy: 0.7760\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.7708 - val_loss: 0.4914 - val_accuracy: 0.7760\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.7708 - val_loss: 0.4913 - val_accuracy: 0.7760\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4784 - accuracy: 0.7708 - val_loss: 0.4912 - val_accuracy: 0.7760\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4783 - accuracy: 0.7726 - val_loss: 0.4912 - val_accuracy: 0.7760\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4782 - accuracy: 0.7708 - val_loss: 0.4911 - val_accuracy: 0.7760\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7708 - val_loss: 0.4911 - val_accuracy: 0.7760\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7708 - val_loss: 0.4910 - val_accuracy: 0.7760\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7708 - val_loss: 0.4910 - val_accuracy: 0.7760\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4779 - accuracy: 0.7708 - val_loss: 0.4909 - val_accuracy: 0.7760\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4778 - accuracy: 0.7708 - val_loss: 0.4909 - val_accuracy: 0.7760\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4777 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7760\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4777 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7760\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4776 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7760\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7708 - val_loss: 0.4907 - val_accuracy: 0.7760\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.7726 - val_loss: 0.4906 - val_accuracy: 0.7760\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.7726 - val_loss: 0.4905 - val_accuracy: 0.7760\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.7726 - val_loss: 0.4905 - val_accuracy: 0.7760\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7726 - val_loss: 0.4904 - val_accuracy: 0.7760\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.7726 - val_loss: 0.4904 - val_accuracy: 0.7760\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7726 - val_loss: 0.4903 - val_accuracy: 0.7760\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.7726 - val_loss: 0.4903 - val_accuracy: 0.7760\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4768 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7760\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4768 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7760\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7760\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7760\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7760\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7760\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7726 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.7726 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4762 - accuracy: 0.7726 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4761 - accuracy: 0.7726 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.7726 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.7726 - val_loss: 0.4897 - val_accuracy: 0.7760\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.7726 - val_loss: 0.4897 - val_accuracy: 0.7760\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.7726 - val_loss: 0.4896 - val_accuracy: 0.7760\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.7726 - val_loss: 0.4896 - val_accuracy: 0.7760\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.7726 - val_loss: 0.4895 - val_accuracy: 0.7760\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7726 - val_loss: 0.4895 - val_accuracy: 0.7760\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7726 - val_loss: 0.4894 - val_accuracy: 0.7760\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7726 - val_loss: 0.4894 - val_accuracy: 0.7760\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.7726 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.7726 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7726 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7726 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.7726 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7726 - val_loss: 0.4891 - val_accuracy: 0.7760\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7726 - val_loss: 0.4891 - val_accuracy: 0.7760\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7726 - val_loss: 0.4890 - val_accuracy: 0.7760\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.7726 - val_loss: 0.4890 - val_accuracy: 0.7760\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.7726 - val_loss: 0.4889 - val_accuracy: 0.7760\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7726 - val_loss: 0.4889 - val_accuracy: 0.7760\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7760\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.7760 - val_loss: 0.4888 - val_accuracy: 0.7760\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7760\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7760\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7760\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7760\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7760\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7760\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7743 - val_loss: 0.4885 - val_accuracy: 0.7760\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4740 - accuracy: 0.7743 - val_loss: 0.4885 - val_accuracy: 0.7760\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7743 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7726 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7760 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.7726 - val_loss: 0.4883 - val_accuracy: 0.7760\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.7743 - val_loss: 0.4883 - val_accuracy: 0.7760\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7726 - val_loss: 0.4882 - val_accuracy: 0.7760\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.7726 - val_loss: 0.4882 - val_accuracy: 0.7760\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7726 - val_loss: 0.4882 - val_accuracy: 0.7760\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.7743 - val_loss: 0.4881 - val_accuracy: 0.7760\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7726 - val_loss: 0.4881 - val_accuracy: 0.7760\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7743 - val_loss: 0.4880 - val_accuracy: 0.7760\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7760\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7760\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7760\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7760\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4729 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7760\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4729 - accuracy: 0.7778 - val_loss: 0.4878 - val_accuracy: 0.7760\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4728 - accuracy: 0.7760 - val_loss: 0.4878 - val_accuracy: 0.7760\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.7760 - val_loss: 0.4877 - val_accuracy: 0.7760\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7778 - val_loss: 0.4877 - val_accuracy: 0.7760\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7778 - val_loss: 0.4877 - val_accuracy: 0.7760\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4726 - accuracy: 0.7778 - val_loss: 0.4876 - val_accuracy: 0.7760\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7778 - val_loss: 0.4876 - val_accuracy: 0.7760\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.7778 - val_loss: 0.4876 - val_accuracy: 0.7760\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7760\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7760\n",
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7760\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7778 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7778 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7778 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7778 - val_loss: 0.4872 - val_accuracy: 0.7760\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7778 - val_loss: 0.4872 - val_accuracy: 0.7760\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4717 - accuracy: 0.7778 - val_loss: 0.4872 - val_accuracy: 0.7760\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4717 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7760\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7778 - val_loss: 0.4871 - val_accuracy: 0.7760\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.7778 - val_loss: 0.4871 - val_accuracy: 0.7760\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4715 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4714 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4713 - accuracy: 0.7778 - val_loss: 0.4869 - val_accuracy: 0.7760\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4713 - accuracy: 0.7778 - val_loss: 0.4869 - val_accuracy: 0.7760\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4712 - accuracy: 0.7778 - val_loss: 0.4869 - val_accuracy: 0.7760\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7778 - val_loss: 0.4868 - val_accuracy: 0.7760\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4711 - accuracy: 0.7778 - val_loss: 0.4868 - val_accuracy: 0.7760\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4710 - accuracy: 0.7778 - val_loss: 0.4868 - val_accuracy: 0.7760\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7778 - val_loss: 0.4867 - val_accuracy: 0.7760\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7778 - val_loss: 0.4867 - val_accuracy: 0.7760\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7778 - val_loss: 0.4867 - val_accuracy: 0.7760\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7778 - val_loss: 0.4867 - val_accuracy: 0.7760\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7778 - val_loss: 0.4866 - val_accuracy: 0.7760\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7778 - val_loss: 0.4866 - val_accuracy: 0.7760\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7778 - val_loss: 0.4866 - val_accuracy: 0.7760\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7760\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7760\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7760\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7760\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7760\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4703 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7760\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4703 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7760\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.7778 - val_loss: 0.4863 - val_accuracy: 0.7760\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7795 - val_loss: 0.4863 - val_accuracy: 0.7760\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7795 - val_loss: 0.4863 - val_accuracy: 0.7760\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7795 - val_loss: 0.4863 - val_accuracy: 0.7760\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7760\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.7778 - val_loss: 0.4862 - val_accuracy: 0.7760\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4699 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7760\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.4699 - accuracy: 0.7795 - val_loss: 0.4861 - val_accuracy: 0.7760\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.4698 - accuracy: 0.7795 - val_loss: 0.4861 - val_accuracy: 0.7760\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.4698 - accuracy: 0.7795 - val_loss: 0.4861 - val_accuracy: 0.7760\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4697 - accuracy: 0.7795 - val_loss: 0.4861 - val_accuracy: 0.7760\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4697 - accuracy: 0.7795 - val_loss: 0.4860 - val_accuracy: 0.7760\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4696 - accuracy: 0.7795 - val_loss: 0.4860 - val_accuracy: 0.7760\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4695 - accuracy: 0.7795 - val_loss: 0.4860 - val_accuracy: 0.7760\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4695 - accuracy: 0.7795 - val_loss: 0.4860 - val_accuracy: 0.7760\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4695 - accuracy: 0.7795 - val_loss: 0.4859 - val_accuracy: 0.7760\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4694 - accuracy: 0.7778 - val_loss: 0.4859 - val_accuracy: 0.7760\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4694 - accuracy: 0.7778 - val_loss: 0.4859 - val_accuracy: 0.7760\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 0.4693 - accuracy: 0.7778 - val_loss: 0.4859 - val_accuracy: 0.7760\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4692 - accuracy: 0.7778 - val_loss: 0.4858 - val_accuracy: 0.7760\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7778 - val_loss: 0.4858 - val_accuracy: 0.7760\n",
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4691 - accuracy: 0.7778 - val_loss: 0.4858 - val_accuracy: 0.7760\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7778 - val_loss: 0.4858 - val_accuracy: 0.7760\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4691 - accuracy: 0.7778 - val_loss: 0.4857 - val_accuracy: 0.7760\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4690 - accuracy: 0.7778 - val_loss: 0.4857 - val_accuracy: 0.7760\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4690 - accuracy: 0.7778 - val_loss: 0.4857 - val_accuracy: 0.7760\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4689 - accuracy: 0.7778 - val_loss: 0.4857 - val_accuracy: 0.7760\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4689 - accuracy: 0.7795 - val_loss: 0.4856 - val_accuracy: 0.7760\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7778 - val_loss: 0.4856 - val_accuracy: 0.7760\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4688 - accuracy: 0.7795 - val_loss: 0.4856 - val_accuracy: 0.7760\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7795 - val_loss: 0.4856 - val_accuracy: 0.7760\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4687 - accuracy: 0.7795 - val_loss: 0.4855 - val_accuracy: 0.7760\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.7795 - val_loss: 0.4855 - val_accuracy: 0.7760\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7795 - val_loss: 0.4855 - val_accuracy: 0.7760\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7778 - val_loss: 0.4855 - val_accuracy: 0.7760\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4685 - accuracy: 0.7795 - val_loss: 0.4855 - val_accuracy: 0.7760\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4685 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7760\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7795 - val_loss: 0.4854 - val_accuracy: 0.7760\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4684 - accuracy: 0.7795 - val_loss: 0.4854 - val_accuracy: 0.7760\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7795 - val_loss: 0.4854 - val_accuracy: 0.7760\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4683 - accuracy: 0.7795 - val_loss: 0.4853 - val_accuracy: 0.7760\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.7795 - val_loss: 0.4853 - val_accuracy: 0.7760\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.7795 - val_loss: 0.4853 - val_accuracy: 0.7760\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7795 - val_loss: 0.4853 - val_accuracy: 0.7760\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.7795 - val_loss: 0.4853 - val_accuracy: 0.7760\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4681 - accuracy: 0.7795 - val_loss: 0.4852 - val_accuracy: 0.7760\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7795 - val_loss: 0.4852 - val_accuracy: 0.7760\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7812 - val_loss: 0.4852 - val_accuracy: 0.7760\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.7812 - val_loss: 0.4852 - val_accuracy: 0.7760\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.7812 - val_loss: 0.4852 - val_accuracy: 0.7760\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7812 - val_loss: 0.4851 - val_accuracy: 0.7760\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7812 - val_loss: 0.4851 - val_accuracy: 0.7760\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7795 - val_loss: 0.4851 - val_accuracy: 0.7760\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7812 - val_loss: 0.4851 - val_accuracy: 0.7760\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7812 - val_loss: 0.4851 - val_accuracy: 0.7760\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4676 - accuracy: 0.7812 - val_loss: 0.4850 - val_accuracy: 0.7760\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4676 - accuracy: 0.7812 - val_loss: 0.4850 - val_accuracy: 0.7760\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7812 - val_loss: 0.4850 - val_accuracy: 0.7760\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7812 - val_loss: 0.4850 - val_accuracy: 0.7760\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7812 - val_loss: 0.4850 - val_accuracy: 0.7760\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7812 - val_loss: 0.4849 - val_accuracy: 0.7760\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7812 - val_loss: 0.4849 - val_accuracy: 0.7760\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7760\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7760\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7812 - val_loss: 0.4849 - val_accuracy: 0.7760\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4672 - accuracy: 0.7812 - val_loss: 0.4848 - val_accuracy: 0.7760\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7812 - val_loss: 0.4848 - val_accuracy: 0.7760\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7812 - val_loss: 0.4848 - val_accuracy: 0.7760\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7812 - val_loss: 0.4848 - val_accuracy: 0.7760\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7812 - val_loss: 0.4848 - val_accuracy: 0.7760\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7812 - val_loss: 0.4848 - val_accuracy: 0.7760\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7812 - val_loss: 0.4847 - val_accuracy: 0.7760\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7812 - val_loss: 0.4847 - val_accuracy: 0.7760\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4669 - accuracy: 0.7812 - val_loss: 0.4847 - val_accuracy: 0.7760\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7812 - val_loss: 0.4847 - val_accuracy: 0.7760\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7812 - val_loss: 0.4847 - val_accuracy: 0.7760\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7760\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7760\n",
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7760\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7760\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7760\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4665 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7708\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4665 - accuracy: 0.7812 - val_loss: 0.4845 - val_accuracy: 0.7708\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7812 - val_loss: 0.4845 - val_accuracy: 0.7708\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7812 - val_loss: 0.4845 - val_accuracy: 0.7708\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7812 - val_loss: 0.4845 - val_accuracy: 0.7708\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4664 - accuracy: 0.7812 - val_loss: 0.4845 - val_accuracy: 0.7708\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4663 - accuracy: 0.7812 - val_loss: 0.4845 - val_accuracy: 0.7708\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7812 - val_loss: 0.4844 - val_accuracy: 0.7708\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7812 - val_loss: 0.4844 - val_accuracy: 0.7708\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7812 - val_loss: 0.4844 - val_accuracy: 0.7708\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7812 - val_loss: 0.4844 - val_accuracy: 0.7708\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4661 - accuracy: 0.7812 - val_loss: 0.4844 - val_accuracy: 0.7708\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4661 - accuracy: 0.7812 - val_loss: 0.4844 - val_accuracy: 0.7708\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4661 - accuracy: 0.7812 - val_loss: 0.4844 - val_accuracy: 0.7708\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4660 - accuracy: 0.7795 - val_loss: 0.4843 - val_accuracy: 0.7708\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7812 - val_loss: 0.4843 - val_accuracy: 0.7708\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7812 - val_loss: 0.4843 - val_accuracy: 0.7708\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4659 - accuracy: 0.7795 - val_loss: 0.4843 - val_accuracy: 0.7708\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4659 - accuracy: 0.7795 - val_loss: 0.4843 - val_accuracy: 0.7708\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7795 - val_loss: 0.4843 - val_accuracy: 0.7708\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.4843 - val_accuracy: 0.7708\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7795 - val_loss: 0.4842 - val_accuracy: 0.7708\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7795 - val_loss: 0.4842 - val_accuracy: 0.7708\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4657 - accuracy: 0.7795 - val_loss: 0.4842 - val_accuracy: 0.7708\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7795 - val_loss: 0.4842 - val_accuracy: 0.7708\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.7795 - val_loss: 0.4842 - val_accuracy: 0.7708\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.7795 - val_loss: 0.4842 - val_accuracy: 0.7708\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7795 - val_loss: 0.4842 - val_accuracy: 0.7708\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4655 - accuracy: 0.7795 - val_loss: 0.4841 - val_accuracy: 0.7708\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.4841 - val_accuracy: 0.7708\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7795 - val_loss: 0.4841 - val_accuracy: 0.7708\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7795 - val_loss: 0.4841 - val_accuracy: 0.7708\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.4841 - val_accuracy: 0.7708\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.4841 - val_accuracy: 0.7708\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.4841 - val_accuracy: 0.7708\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.4840 - val_accuracy: 0.7708\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7795 - val_loss: 0.4840 - val_accuracy: 0.7708\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.7795 - val_loss: 0.4840 - val_accuracy: 0.7708\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7795 - val_loss: 0.4840 - val_accuracy: 0.7708\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7795 - val_loss: 0.4840 - val_accuracy: 0.7708\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7795 - val_loss: 0.4840 - val_accuracy: 0.7708\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7795 - val_loss: 0.4840 - val_accuracy: 0.7708\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4651 - accuracy: 0.7795 - val_loss: 0.4840 - val_accuracy: 0.7708\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7795 - val_loss: 0.4839 - val_accuracy: 0.7708\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7795 - val_loss: 0.4839 - val_accuracy: 0.7708\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7795 - val_loss: 0.4839 - val_accuracy: 0.7708\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7795 - val_loss: 0.4839 - val_accuracy: 0.7708\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7795 - val_loss: 0.4839 - val_accuracy: 0.7708\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7795 - val_loss: 0.4839 - val_accuracy: 0.7708\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7795 - val_loss: 0.4839 - val_accuracy: 0.7708\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7795 - val_loss: 0.4839 - val_accuracy: 0.7708\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4648 - accuracy: 0.7795 - val_loss: 0.4838 - val_accuracy: 0.7708\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7795 - val_loss: 0.4838 - val_accuracy: 0.7708\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7795 - val_loss: 0.4838 - val_accuracy: 0.7708\n",
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7795 - val_loss: 0.4838 - val_accuracy: 0.7708\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7795 - val_loss: 0.4838 - val_accuracy: 0.7708\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7795 - val_loss: 0.4838 - val_accuracy: 0.7708\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7795 - val_loss: 0.4838 - val_accuracy: 0.7708\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7795 - val_loss: 0.4838 - val_accuracy: 0.7708\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7795 - val_loss: 0.4838 - val_accuracy: 0.7708\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7795 - val_loss: 0.4837 - val_accuracy: 0.7708\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7812 - val_loss: 0.4837 - val_accuracy: 0.7708\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7795 - val_loss: 0.4837 - val_accuracy: 0.7708\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7795 - val_loss: 0.4837 - val_accuracy: 0.7708\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7812 - val_loss: 0.4837 - val_accuracy: 0.7708\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7812 - val_loss: 0.4837 - val_accuracy: 0.7708\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7812 - val_loss: 0.4837 - val_accuracy: 0.7708\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7812 - val_loss: 0.4837 - val_accuracy: 0.7708\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7812 - val_loss: 0.4837 - val_accuracy: 0.7708\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4642 - accuracy: 0.7812 - val_loss: 0.4837 - val_accuracy: 0.7708\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.7812 - val_loss: 0.4836 - val_accuracy: 0.7708\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7812 - val_loss: 0.4836 - val_accuracy: 0.7708\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7812 - val_loss: 0.4836 - val_accuracy: 0.7708\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7830 - val_loss: 0.4836 - val_accuracy: 0.7708\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7812 - val_loss: 0.4836 - val_accuracy: 0.7708\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7830 - val_loss: 0.4836 - val_accuracy: 0.7708\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7830 - val_loss: 0.4836 - val_accuracy: 0.7708\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7812 - val_loss: 0.4836 - val_accuracy: 0.7708\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7830 - val_loss: 0.4836 - val_accuracy: 0.7708\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4639 - accuracy: 0.7830 - val_loss: 0.4836 - val_accuracy: 0.7708\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7830 - val_loss: 0.4835 - val_accuracy: 0.7708\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4638 - accuracy: 0.7830 - val_loss: 0.4835 - val_accuracy: 0.7708\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4638 - accuracy: 0.7830 - val_loss: 0.4835 - val_accuracy: 0.7708\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7830 - val_loss: 0.4835 - val_accuracy: 0.7708\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7830 - val_loss: 0.4835 - val_accuracy: 0.7708\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7830 - val_loss: 0.4835 - val_accuracy: 0.7708\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4637 - accuracy: 0.7830 - val_loss: 0.4835 - val_accuracy: 0.7708\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4637 - accuracy: 0.7830 - val_loss: 0.4835 - val_accuracy: 0.7708\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7830 - val_loss: 0.4835 - val_accuracy: 0.7708\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7830 - val_loss: 0.4835 - val_accuracy: 0.7708\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7830 - val_loss: 0.4835 - val_accuracy: 0.7708\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7830 - val_loss: 0.4835 - val_accuracy: 0.7708\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4635 - accuracy: 0.7830 - val_loss: 0.4834 - val_accuracy: 0.7708\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7830 - val_loss: 0.4834 - val_accuracy: 0.7708\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4635 - accuracy: 0.7830 - val_loss: 0.4834 - val_accuracy: 0.7708\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4635 - accuracy: 0.7830 - val_loss: 0.4834 - val_accuracy: 0.7708\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4634 - accuracy: 0.7830 - val_loss: 0.4834 - val_accuracy: 0.7708\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7830 - val_loss: 0.4834 - val_accuracy: 0.7708\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7830 - val_loss: 0.4834 - val_accuracy: 0.7708\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4633 - accuracy: 0.7830 - val_loss: 0.4834 - val_accuracy: 0.7708\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7830 - val_loss: 0.4834 - val_accuracy: 0.7708\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7830 - val_loss: 0.4834 - val_accuracy: 0.7708\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7830 - val_loss: 0.4834 - val_accuracy: 0.7708\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7830 - val_loss: 0.4834 - val_accuracy: 0.7708\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7830 - val_loss: 0.4833 - val_accuracy: 0.7708\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7830 - val_loss: 0.4833 - val_accuracy: 0.7708\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7830 - val_loss: 0.4833 - val_accuracy: 0.7708\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7830 - val_loss: 0.4833 - val_accuracy: 0.7708\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.7830 - val_loss: 0.4833 - val_accuracy: 0.7708\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4631 - accuracy: 0.7830 - val_loss: 0.4833 - val_accuracy: 0.7708\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7830 - val_loss: 0.4833 - val_accuracy: 0.7708\n",
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7830 - val_loss: 0.4833 - val_accuracy: 0.7708\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7830 - val_loss: 0.4833 - val_accuracy: 0.7708\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7830 - val_loss: 0.4833 - val_accuracy: 0.7708\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7830 - val_loss: 0.4833 - val_accuracy: 0.7708\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4629 - accuracy: 0.7830 - val_loss: 0.4833 - val_accuracy: 0.7708\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7830 - val_loss: 0.4833 - val_accuracy: 0.7708\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4629 - accuracy: 0.7830 - val_loss: 0.4833 - val_accuracy: 0.7708\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7830 - val_loss: 0.4833 - val_accuracy: 0.7708\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7830 - val_loss: 0.4832 - val_accuracy: 0.7708\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7830 - val_loss: 0.4832 - val_accuracy: 0.7708\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7830 - val_loss: 0.4832 - val_accuracy: 0.7708\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7830 - val_loss: 0.4832 - val_accuracy: 0.7708\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7830 - val_loss: 0.4832 - val_accuracy: 0.7708\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7830 - val_loss: 0.4832 - val_accuracy: 0.7708\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7830 - val_loss: 0.4832 - val_accuracy: 0.7708\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4627 - accuracy: 0.7830 - val_loss: 0.4832 - val_accuracy: 0.7708\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7830 - val_loss: 0.4832 - val_accuracy: 0.7708\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7830 - val_loss: 0.4832 - val_accuracy: 0.7708\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7830 - val_loss: 0.4832 - val_accuracy: 0.7708\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7830 - val_loss: 0.4832 - val_accuracy: 0.7708\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7830 - val_loss: 0.4832 - val_accuracy: 0.7708\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7830 - val_loss: 0.4832 - val_accuracy: 0.7708\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7830 - val_loss: 0.4832 - val_accuracy: 0.7708\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7830 - val_loss: 0.4832 - val_accuracy: 0.7708\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4624 - accuracy: 0.7830 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7830 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7830 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7830 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7830 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4623 - accuracy: 0.7830 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4623 - accuracy: 0.7830 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7830 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4623 - accuracy: 0.7830 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7830 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7830 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7830 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7830 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7830 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7830 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7830 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7830 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4621 - accuracy: 0.7830 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7830 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7830 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7830 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7830 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7830 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7830 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7830 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7830 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4619 - accuracy: 0.7830 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7812 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7830 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7830 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7830 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7812 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7812 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4617 - accuracy: 0.7812 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7812 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7812 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7812 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7812 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7812 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4615 - accuracy: 0.7812 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4614 - accuracy: 0.7812 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4599 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4598 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4594 - accuracy: 0.7760 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4594 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4593 - accuracy: 0.7760 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4593 - accuracy: 0.7760 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7760 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4829 - val_accuracy: 0.7656\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4829 - val_accuracy: 0.7656\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4829 - val_accuracy: 0.7656\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4829 - val_accuracy: 0.7656\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.4829 - val_accuracy: 0.7656\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.4829 - val_accuracy: 0.7656\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.4829 - val_accuracy: 0.7656\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.4829 - val_accuracy: 0.7656\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.4829 - val_accuracy: 0.7656\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.4829 - val_accuracy: 0.7656\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.4829 - val_accuracy: 0.7656\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.4829 - val_accuracy: 0.7656\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7778 - val_loss: 0.4829 - val_accuracy: 0.7656\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.7778 - val_loss: 0.4829 - val_accuracy: 0.7656\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7778 - val_loss: 0.4829 - val_accuracy: 0.7656\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7778 - val_loss: 0.4829 - val_accuracy: 0.7656\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x163e3525900>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "For this exercise, do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/1500\n",
      "576/576 [==============================] - 0s 295us/step - loss: 0.6739 - accuracy: 0.5747 - val_loss: 0.6753 - val_accuracy: 0.5885\n",
      "Epoch 2/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.6717 - accuracy: 0.5868 - val_loss: 0.6734 - val_accuracy: 0.6042\n",
      "Epoch 3/1500\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.6696 - accuracy: 0.5990 - val_loss: 0.6715 - val_accuracy: 0.6146\n",
      "Epoch 4/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.6675 - accuracy: 0.6146 - val_loss: 0.6697 - val_accuracy: 0.6354\n",
      "Epoch 5/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.6655 - accuracy: 0.6215 - val_loss: 0.6679 - val_accuracy: 0.6458\n",
      "Epoch 6/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.6634 - accuracy: 0.6424 - val_loss: 0.6661 - val_accuracy: 0.6250\n",
      "Epoch 7/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6614 - accuracy: 0.6476 - val_loss: 0.6643 - val_accuracy: 0.6198\n",
      "Epoch 8/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6594 - accuracy: 0.6580 - val_loss: 0.6626 - val_accuracy: 0.6042\n",
      "Epoch 9/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6575 - accuracy: 0.6649 - val_loss: 0.6610 - val_accuracy: 0.6094\n",
      "Epoch 10/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.6556 - accuracy: 0.6615 - val_loss: 0.6594 - val_accuracy: 0.6250\n",
      "Epoch 11/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6538 - accuracy: 0.6667 - val_loss: 0.6579 - val_accuracy: 0.6458\n",
      "Epoch 12/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6520 - accuracy: 0.6615 - val_loss: 0.6564 - val_accuracy: 0.6667\n",
      "Epoch 13/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6503 - accuracy: 0.6632 - val_loss: 0.6549 - val_accuracy: 0.6562\n",
      "Epoch 14/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.6486 - accuracy: 0.6736 - val_loss: 0.6534 - val_accuracy: 0.6562\n",
      "Epoch 15/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6470 - accuracy: 0.6806 - val_loss: 0.6520 - val_accuracy: 0.6667\n",
      "Epoch 16/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.6454 - accuracy: 0.6806 - val_loss: 0.6506 - val_accuracy: 0.6771\n",
      "Epoch 17/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.6438 - accuracy: 0.6910 - val_loss: 0.6493 - val_accuracy: 0.6823\n",
      "Epoch 18/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6423 - accuracy: 0.6840 - val_loss: 0.6480 - val_accuracy: 0.6667\n",
      "Epoch 19/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6409 - accuracy: 0.6806 - val_loss: 0.6467 - val_accuracy: 0.6615\n",
      "Epoch 20/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6394 - accuracy: 0.6771 - val_loss: 0.6454 - val_accuracy: 0.6719\n",
      "Epoch 21/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6380 - accuracy: 0.6875 - val_loss: 0.6442 - val_accuracy: 0.6719\n",
      "Epoch 22/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6366 - accuracy: 0.6840 - val_loss: 0.6430 - val_accuracy: 0.6875\n",
      "Epoch 23/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6352 - accuracy: 0.6858 - val_loss: 0.6418 - val_accuracy: 0.6927\n",
      "Epoch 24/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6339 - accuracy: 0.6840 - val_loss: 0.6407 - val_accuracy: 0.6927\n",
      "Epoch 25/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6327 - accuracy: 0.6840 - val_loss: 0.6396 - val_accuracy: 0.6979\n",
      "Epoch 26/1500\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.6314 - accuracy: 0.6823 - val_loss: 0.6385 - val_accuracy: 0.7031\n",
      "Epoch 27/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.6301 - accuracy: 0.6840 - val_loss: 0.6374 - val_accuracy: 0.7031\n",
      "Epoch 28/1500\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.6289 - accuracy: 0.6823 - val_loss: 0.6364 - val_accuracy: 0.7031\n",
      "Epoch 29/1500\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.6277 - accuracy: 0.6858 - val_loss: 0.6353 - val_accuracy: 0.6927\n",
      "Epoch 30/1500\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.6265 - accuracy: 0.6858 - val_loss: 0.6343 - val_accuracy: 0.6927\n",
      "Epoch 31/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.6253 - accuracy: 0.6840 - val_loss: 0.6333 - val_accuracy: 0.6927\n",
      "Epoch 32/1500\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.6242 - accuracy: 0.6840 - val_loss: 0.6324 - val_accuracy: 0.6927\n",
      "Epoch 33/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.6231 - accuracy: 0.6840 - val_loss: 0.6314 - val_accuracy: 0.6875\n",
      "Epoch 34/1500\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.6220 - accuracy: 0.6806 - val_loss: 0.6305 - val_accuracy: 0.6823\n",
      "Epoch 35/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.6209 - accuracy: 0.6840 - val_loss: 0.6296 - val_accuracy: 0.6823\n",
      "Epoch 36/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.6198 - accuracy: 0.6858 - val_loss: 0.6286 - val_accuracy: 0.6823\n",
      "Epoch 37/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.6188 - accuracy: 0.6840 - val_loss: 0.6277 - val_accuracy: 0.6771\n",
      "Epoch 38/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.6177 - accuracy: 0.6840 - val_loss: 0.6269 - val_accuracy: 0.6771\n",
      "Epoch 39/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.6167 - accuracy: 0.6840 - val_loss: 0.6260 - val_accuracy: 0.6823\n",
      "Epoch 40/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.6156 - accuracy: 0.6840 - val_loss: 0.6251 - val_accuracy: 0.6823\n",
      "Epoch 41/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6146 - accuracy: 0.6840 - val_loss: 0.6243 - val_accuracy: 0.6823\n",
      "Epoch 42/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6136 - accuracy: 0.6858 - val_loss: 0.6235 - val_accuracy: 0.6823\n",
      "Epoch 43/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6126 - accuracy: 0.6875 - val_loss: 0.6226 - val_accuracy: 0.6823\n",
      "Epoch 44/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6115 - accuracy: 0.6892 - val_loss: 0.6218 - val_accuracy: 0.6823\n",
      "Epoch 45/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6105 - accuracy: 0.6892 - val_loss: 0.6210 - val_accuracy: 0.6823\n",
      "Epoch 46/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6095 - accuracy: 0.6892 - val_loss: 0.6201 - val_accuracy: 0.6771\n",
      "Epoch 47/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.6085 - accuracy: 0.6892 - val_loss: 0.6193 - val_accuracy: 0.6771\n",
      "Epoch 48/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.6076 - accuracy: 0.6910 - val_loss: 0.6186 - val_accuracy: 0.6771\n",
      "Epoch 49/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6066 - accuracy: 0.6910 - val_loss: 0.6178 - val_accuracy: 0.6719\n",
      "Epoch 50/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6057 - accuracy: 0.6910 - val_loss: 0.6170 - val_accuracy: 0.6719\n",
      "Epoch 51/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.6047 - accuracy: 0.6892 - val_loss: 0.6163 - val_accuracy: 0.6719\n",
      "Epoch 52/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.6038 - accuracy: 0.6892 - val_loss: 0.6156 - val_accuracy: 0.6719\n",
      "Epoch 53/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6028 - accuracy: 0.6892 - val_loss: 0.6148 - val_accuracy: 0.6719\n",
      "Epoch 54/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6019 - accuracy: 0.6892 - val_loss: 0.6141 - val_accuracy: 0.6667\n",
      "Epoch 55/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6010 - accuracy: 0.6910 - val_loss: 0.6134 - val_accuracy: 0.6667\n",
      "Epoch 56/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6001 - accuracy: 0.6892 - val_loss: 0.6127 - val_accuracy: 0.6719\n",
      "Epoch 57/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5992 - accuracy: 0.6910 - val_loss: 0.6120 - val_accuracy: 0.6719\n",
      "Epoch 58/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5983 - accuracy: 0.6910 - val_loss: 0.6113 - val_accuracy: 0.6719\n",
      "Epoch 59/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5974 - accuracy: 0.6927 - val_loss: 0.6106 - val_accuracy: 0.6719\n",
      "Epoch 60/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5966 - accuracy: 0.6927 - val_loss: 0.6099 - val_accuracy: 0.6719\n",
      "Epoch 61/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5957 - accuracy: 0.6927 - val_loss: 0.6092 - val_accuracy: 0.6667\n",
      "Epoch 62/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5948 - accuracy: 0.6927 - val_loss: 0.6086 - val_accuracy: 0.6667\n",
      "Epoch 63/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5940 - accuracy: 0.6927 - val_loss: 0.6079 - val_accuracy: 0.6667\n",
      "Epoch 64/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5931 - accuracy: 0.6927 - val_loss: 0.6072 - val_accuracy: 0.6667\n",
      "Epoch 65/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5922 - accuracy: 0.6927 - val_loss: 0.6066 - val_accuracy: 0.6667\n",
      "Epoch 66/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5913 - accuracy: 0.6910 - val_loss: 0.6059 - val_accuracy: 0.6667\n",
      "Epoch 67/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5904 - accuracy: 0.6927 - val_loss: 0.6053 - val_accuracy: 0.6667\n",
      "Epoch 68/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5895 - accuracy: 0.6927 - val_loss: 0.6047 - val_accuracy: 0.6719\n",
      "Epoch 69/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5886 - accuracy: 0.6927 - val_loss: 0.6040 - val_accuracy: 0.6719\n",
      "Epoch 70/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5877 - accuracy: 0.6910 - val_loss: 0.6034 - val_accuracy: 0.6719\n",
      "Epoch 71/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5868 - accuracy: 0.6910 - val_loss: 0.6027 - val_accuracy: 0.6719\n",
      "Epoch 72/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5859 - accuracy: 0.6910 - val_loss: 0.6021 - val_accuracy: 0.6719\n",
      "Epoch 73/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5849 - accuracy: 0.6910 - val_loss: 0.6014 - val_accuracy: 0.6719\n",
      "Epoch 74/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5840 - accuracy: 0.6910 - val_loss: 0.6008 - val_accuracy: 0.6719\n",
      "Epoch 75/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5831 - accuracy: 0.6892 - val_loss: 0.6001 - val_accuracy: 0.6719\n",
      "Epoch 76/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5822 - accuracy: 0.6910 - val_loss: 0.5994 - val_accuracy: 0.6719\n",
      "Epoch 77/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5813 - accuracy: 0.6910 - val_loss: 0.5988 - val_accuracy: 0.6719\n",
      "Epoch 78/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5804 - accuracy: 0.6910 - val_loss: 0.5981 - val_accuracy: 0.6719\n",
      "Epoch 79/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5795 - accuracy: 0.6910 - val_loss: 0.5975 - val_accuracy: 0.6719\n",
      "Epoch 80/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5787 - accuracy: 0.6910 - val_loss: 0.5969 - val_accuracy: 0.6719\n",
      "Epoch 81/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5778 - accuracy: 0.6927 - val_loss: 0.5963 - val_accuracy: 0.6719\n",
      "Epoch 82/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5769 - accuracy: 0.6927 - val_loss: 0.5956 - val_accuracy: 0.6719\n",
      "Epoch 83/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5760 - accuracy: 0.6927 - val_loss: 0.5950 - val_accuracy: 0.6667\n",
      "Epoch 84/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5752 - accuracy: 0.6927 - val_loss: 0.5944 - val_accuracy: 0.6667\n",
      "Epoch 85/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5743 - accuracy: 0.6944 - val_loss: 0.5937 - val_accuracy: 0.6667\n",
      "Epoch 86/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5734 - accuracy: 0.6944 - val_loss: 0.5931 - val_accuracy: 0.6667\n",
      "Epoch 87/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5725 - accuracy: 0.6962 - val_loss: 0.5925 - val_accuracy: 0.6667\n",
      "Epoch 88/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5716 - accuracy: 0.6962 - val_loss: 0.5918 - val_accuracy: 0.6667\n",
      "Epoch 89/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5708 - accuracy: 0.6962 - val_loss: 0.5912 - val_accuracy: 0.6667\n",
      "Epoch 90/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5699 - accuracy: 0.6997 - val_loss: 0.5906 - val_accuracy: 0.6667\n",
      "Epoch 91/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5690 - accuracy: 0.7014 - val_loss: 0.5899 - val_accuracy: 0.6667\n",
      "Epoch 92/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5681 - accuracy: 0.7031 - val_loss: 0.5893 - val_accuracy: 0.6667\n",
      "Epoch 93/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5673 - accuracy: 0.7031 - val_loss: 0.5886 - val_accuracy: 0.6667\n",
      "Epoch 94/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5664 - accuracy: 0.7031 - val_loss: 0.5880 - val_accuracy: 0.6667\n",
      "Epoch 95/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5655 - accuracy: 0.7031 - val_loss: 0.5874 - val_accuracy: 0.6667\n",
      "Epoch 96/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5647 - accuracy: 0.7014 - val_loss: 0.5867 - val_accuracy: 0.6667\n",
      "Epoch 97/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5638 - accuracy: 0.7014 - val_loss: 0.5861 - val_accuracy: 0.6667\n",
      "Epoch 98/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5629 - accuracy: 0.7014 - val_loss: 0.5855 - val_accuracy: 0.6667\n",
      "Epoch 99/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5621 - accuracy: 0.7031 - val_loss: 0.5849 - val_accuracy: 0.6667\n",
      "Epoch 100/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5612 - accuracy: 0.7031 - val_loss: 0.5842 - val_accuracy: 0.6667\n",
      "Epoch 101/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5604 - accuracy: 0.7031 - val_loss: 0.5836 - val_accuracy: 0.6667\n",
      "Epoch 102/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5595 - accuracy: 0.7031 - val_loss: 0.5830 - val_accuracy: 0.6667\n",
      "Epoch 103/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5587 - accuracy: 0.7031 - val_loss: 0.5824 - val_accuracy: 0.6667\n",
      "Epoch 104/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5578 - accuracy: 0.7031 - val_loss: 0.5818 - val_accuracy: 0.6667\n",
      "Epoch 105/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5569 - accuracy: 0.7031 - val_loss: 0.5811 - val_accuracy: 0.6667\n",
      "Epoch 106/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5560 - accuracy: 0.7031 - val_loss: 0.5805 - val_accuracy: 0.6667\n",
      "Epoch 107/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5552 - accuracy: 0.7049 - val_loss: 0.5799 - val_accuracy: 0.6719\n",
      "Epoch 108/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5543 - accuracy: 0.7049 - val_loss: 0.5793 - val_accuracy: 0.6771\n",
      "Epoch 109/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5534 - accuracy: 0.7049 - val_loss: 0.5787 - val_accuracy: 0.6771\n",
      "Epoch 110/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5525 - accuracy: 0.7049 - val_loss: 0.5781 - val_accuracy: 0.6771\n",
      "Epoch 111/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5516 - accuracy: 0.7066 - val_loss: 0.5775 - val_accuracy: 0.6771\n",
      "Epoch 112/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5508 - accuracy: 0.7083 - val_loss: 0.5769 - val_accuracy: 0.6771\n",
      "Epoch 113/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5499 - accuracy: 0.7083 - val_loss: 0.5764 - val_accuracy: 0.6771\n",
      "Epoch 114/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5490 - accuracy: 0.7101 - val_loss: 0.5758 - val_accuracy: 0.6771\n",
      "Epoch 115/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5482 - accuracy: 0.7101 - val_loss: 0.5752 - val_accuracy: 0.6771\n",
      "Epoch 116/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5473 - accuracy: 0.7101 - val_loss: 0.5747 - val_accuracy: 0.6875\n",
      "Epoch 117/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5465 - accuracy: 0.7101 - val_loss: 0.5741 - val_accuracy: 0.6927\n",
      "Epoch 118/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5456 - accuracy: 0.7101 - val_loss: 0.5736 - val_accuracy: 0.6927\n",
      "Epoch 119/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5448 - accuracy: 0.7101 - val_loss: 0.5730 - val_accuracy: 0.6927\n",
      "Epoch 120/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5439 - accuracy: 0.7101 - val_loss: 0.5725 - val_accuracy: 0.6875\n",
      "Epoch 121/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5431 - accuracy: 0.7118 - val_loss: 0.5719 - val_accuracy: 0.6875\n",
      "Epoch 122/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5422 - accuracy: 0.7118 - val_loss: 0.5713 - val_accuracy: 0.6875\n",
      "Epoch 123/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5413 - accuracy: 0.7135 - val_loss: 0.5708 - val_accuracy: 0.6875\n",
      "Epoch 124/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5404 - accuracy: 0.7135 - val_loss: 0.5702 - val_accuracy: 0.6875\n",
      "Epoch 125/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5396 - accuracy: 0.7170 - val_loss: 0.5697 - val_accuracy: 0.6875\n",
      "Epoch 126/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5387 - accuracy: 0.7170 - val_loss: 0.5691 - val_accuracy: 0.6927\n",
      "Epoch 127/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5379 - accuracy: 0.7188 - val_loss: 0.5686 - val_accuracy: 0.6927\n",
      "Epoch 128/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5370 - accuracy: 0.7188 - val_loss: 0.5680 - val_accuracy: 0.6927\n",
      "Epoch 129/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5361 - accuracy: 0.7188 - val_loss: 0.5675 - val_accuracy: 0.6927\n",
      "Epoch 130/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5352 - accuracy: 0.7188 - val_loss: 0.5669 - val_accuracy: 0.6927\n",
      "Epoch 131/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5343 - accuracy: 0.7205 - val_loss: 0.5664 - val_accuracy: 0.6875\n",
      "Epoch 132/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5334 - accuracy: 0.7188 - val_loss: 0.5659 - val_accuracy: 0.6875\n",
      "Epoch 133/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5325 - accuracy: 0.7257 - val_loss: 0.5653 - val_accuracy: 0.6875\n",
      "Epoch 134/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5316 - accuracy: 0.7240 - val_loss: 0.5648 - val_accuracy: 0.6875\n",
      "Epoch 135/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5306 - accuracy: 0.7240 - val_loss: 0.5642 - val_accuracy: 0.6927\n",
      "Epoch 136/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5297 - accuracy: 0.7257 - val_loss: 0.5637 - val_accuracy: 0.6927\n",
      "Epoch 137/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5288 - accuracy: 0.7274 - val_loss: 0.5632 - val_accuracy: 0.6927\n",
      "Epoch 138/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5279 - accuracy: 0.7274 - val_loss: 0.5626 - val_accuracy: 0.6927\n",
      "Epoch 139/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5269 - accuracy: 0.7274 - val_loss: 0.5621 - val_accuracy: 0.6927\n",
      "Epoch 140/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5260 - accuracy: 0.7292 - val_loss: 0.5616 - val_accuracy: 0.6927\n",
      "Epoch 141/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5251 - accuracy: 0.7292 - val_loss: 0.5611 - val_accuracy: 0.6979\n",
      "Epoch 142/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5242 - accuracy: 0.7309 - val_loss: 0.5606 - val_accuracy: 0.6979\n",
      "Epoch 143/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5233 - accuracy: 0.7326 - val_loss: 0.5601 - val_accuracy: 0.6979\n",
      "Epoch 144/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5225 - accuracy: 0.7344 - val_loss: 0.5597 - val_accuracy: 0.6927\n",
      "Epoch 145/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5216 - accuracy: 0.7344 - val_loss: 0.5592 - val_accuracy: 0.6927\n",
      "Epoch 146/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5207 - accuracy: 0.7361 - val_loss: 0.5587 - val_accuracy: 0.6927\n",
      "Epoch 147/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5199 - accuracy: 0.7378 - val_loss: 0.5582 - val_accuracy: 0.6927\n",
      "Epoch 148/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5190 - accuracy: 0.7396 - val_loss: 0.5577 - val_accuracy: 0.6979\n",
      "Epoch 149/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5181 - accuracy: 0.7396 - val_loss: 0.5572 - val_accuracy: 0.6927\n",
      "Epoch 150/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5172 - accuracy: 0.7431 - val_loss: 0.5567 - val_accuracy: 0.7031\n",
      "Epoch 151/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5162 - accuracy: 0.7431 - val_loss: 0.5562 - val_accuracy: 0.7083\n",
      "Epoch 152/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5153 - accuracy: 0.7465 - val_loss: 0.5558 - val_accuracy: 0.7135\n",
      "Epoch 153/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5144 - accuracy: 0.7500 - val_loss: 0.5553 - val_accuracy: 0.7135\n",
      "Epoch 154/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5135 - accuracy: 0.7465 - val_loss: 0.5549 - val_accuracy: 0.7135\n",
      "Epoch 155/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5127 - accuracy: 0.7465 - val_loss: 0.5544 - val_accuracy: 0.7135\n",
      "Epoch 156/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5117 - accuracy: 0.7483 - val_loss: 0.5540 - val_accuracy: 0.7135\n",
      "Epoch 157/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5109 - accuracy: 0.7465 - val_loss: 0.5536 - val_accuracy: 0.7135\n",
      "Epoch 158/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5100 - accuracy: 0.7517 - val_loss: 0.5531 - val_accuracy: 0.7135\n",
      "Epoch 159/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5091 - accuracy: 0.7500 - val_loss: 0.5527 - val_accuracy: 0.7135\n",
      "Epoch 160/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5082 - accuracy: 0.7500 - val_loss: 0.5523 - val_accuracy: 0.7135\n",
      "Epoch 161/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5074 - accuracy: 0.7517 - val_loss: 0.5519 - val_accuracy: 0.7135\n",
      "Epoch 162/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5065 - accuracy: 0.7517 - val_loss: 0.5515 - val_accuracy: 0.7135\n",
      "Epoch 163/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5057 - accuracy: 0.7500 - val_loss: 0.5510 - val_accuracy: 0.7188\n",
      "Epoch 164/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5049 - accuracy: 0.7500 - val_loss: 0.5506 - val_accuracy: 0.7240\n",
      "Epoch 165/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5040 - accuracy: 0.7500 - val_loss: 0.5503 - val_accuracy: 0.7292\n",
      "Epoch 166/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5033 - accuracy: 0.7500 - val_loss: 0.5499 - val_accuracy: 0.7344\n",
      "Epoch 167/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5025 - accuracy: 0.7517 - val_loss: 0.5495 - val_accuracy: 0.7344\n",
      "Epoch 168/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5017 - accuracy: 0.7517 - val_loss: 0.5491 - val_accuracy: 0.7344\n",
      "Epoch 169/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5009 - accuracy: 0.7517 - val_loss: 0.5487 - val_accuracy: 0.7344\n",
      "Epoch 170/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5002 - accuracy: 0.7552 - val_loss: 0.5483 - val_accuracy: 0.7344\n",
      "Epoch 171/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4994 - accuracy: 0.7535 - val_loss: 0.5479 - val_accuracy: 0.7344\n",
      "Epoch 172/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4987 - accuracy: 0.7535 - val_loss: 0.5475 - val_accuracy: 0.7344\n",
      "Epoch 173/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4981 - accuracy: 0.7535 - val_loss: 0.5471 - val_accuracy: 0.7396\n",
      "Epoch 174/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4974 - accuracy: 0.7500 - val_loss: 0.5468 - val_accuracy: 0.7396\n",
      "Epoch 175/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4968 - accuracy: 0.7500 - val_loss: 0.5464 - val_accuracy: 0.7396\n",
      "Epoch 176/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4961 - accuracy: 0.7500 - val_loss: 0.5460 - val_accuracy: 0.7396\n",
      "Epoch 177/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4954 - accuracy: 0.7500 - val_loss: 0.5456 - val_accuracy: 0.7396\n",
      "Epoch 178/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4947 - accuracy: 0.7500 - val_loss: 0.5452 - val_accuracy: 0.7396\n",
      "Epoch 179/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4940 - accuracy: 0.7517 - val_loss: 0.5449 - val_accuracy: 0.7344\n",
      "Epoch 180/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4934 - accuracy: 0.7500 - val_loss: 0.5445 - val_accuracy: 0.7344\n",
      "Epoch 181/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4927 - accuracy: 0.7517 - val_loss: 0.5441 - val_accuracy: 0.7344\n",
      "Epoch 182/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4921 - accuracy: 0.7535 - val_loss: 0.5438 - val_accuracy: 0.7292\n",
      "Epoch 183/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4914 - accuracy: 0.7517 - val_loss: 0.5434 - val_accuracy: 0.7292\n",
      "Epoch 184/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4908 - accuracy: 0.7517 - val_loss: 0.5431 - val_accuracy: 0.7292\n",
      "Epoch 185/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4901 - accuracy: 0.7517 - val_loss: 0.5427 - val_accuracy: 0.7292\n",
      "Epoch 186/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4895 - accuracy: 0.7517 - val_loss: 0.5424 - val_accuracy: 0.7292\n",
      "Epoch 187/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4889 - accuracy: 0.7500 - val_loss: 0.5421 - val_accuracy: 0.7292\n",
      "Epoch 188/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4882 - accuracy: 0.7483 - val_loss: 0.5417 - val_accuracy: 0.7292\n",
      "Epoch 189/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4876 - accuracy: 0.7500 - val_loss: 0.5414 - val_accuracy: 0.7292\n",
      "Epoch 190/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4870 - accuracy: 0.7483 - val_loss: 0.5411 - val_accuracy: 0.7292\n",
      "Epoch 191/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4864 - accuracy: 0.7483 - val_loss: 0.5408 - val_accuracy: 0.7292\n",
      "Epoch 192/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4859 - accuracy: 0.7483 - val_loss: 0.5405 - val_accuracy: 0.7240\n",
      "Epoch 193/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4853 - accuracy: 0.7483 - val_loss: 0.5402 - val_accuracy: 0.7240\n",
      "Epoch 194/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4847 - accuracy: 0.7465 - val_loss: 0.5400 - val_accuracy: 0.7240\n",
      "Epoch 195/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4841 - accuracy: 0.7465 - val_loss: 0.5397 - val_accuracy: 0.7240\n",
      "Epoch 196/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4836 - accuracy: 0.7465 - val_loss: 0.5394 - val_accuracy: 0.7240\n",
      "Epoch 197/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4830 - accuracy: 0.7465 - val_loss: 0.5391 - val_accuracy: 0.7240\n",
      "Epoch 198/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4824 - accuracy: 0.7483 - val_loss: 0.5388 - val_accuracy: 0.7240\n",
      "Epoch 199/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4818 - accuracy: 0.7483 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 200/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4812 - accuracy: 0.7483 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
      "Epoch 201/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4806 - accuracy: 0.7483 - val_loss: 0.5378 - val_accuracy: 0.7188\n",
      "Epoch 202/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4800 - accuracy: 0.7483 - val_loss: 0.5374 - val_accuracy: 0.7188\n",
      "Epoch 203/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4795 - accuracy: 0.7500 - val_loss: 0.5371 - val_accuracy: 0.7135\n",
      "Epoch 204/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4789 - accuracy: 0.7500 - val_loss: 0.5368 - val_accuracy: 0.7135\n",
      "Epoch 205/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4784 - accuracy: 0.7500 - val_loss: 0.5365 - val_accuracy: 0.7135\n",
      "Epoch 206/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4778 - accuracy: 0.7500 - val_loss: 0.5361 - val_accuracy: 0.7135\n",
      "Epoch 207/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4773 - accuracy: 0.7500 - val_loss: 0.5358 - val_accuracy: 0.7083\n",
      "Epoch 208/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4767 - accuracy: 0.7500 - val_loss: 0.5355 - val_accuracy: 0.7083\n",
      "Epoch 209/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4762 - accuracy: 0.7517 - val_loss: 0.5352 - val_accuracy: 0.7083\n",
      "Epoch 210/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4757 - accuracy: 0.7535 - val_loss: 0.5349 - val_accuracy: 0.7083\n",
      "Epoch 211/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4752 - accuracy: 0.7535 - val_loss: 0.5346 - val_accuracy: 0.7083\n",
      "Epoch 212/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4746 - accuracy: 0.7517 - val_loss: 0.5343 - val_accuracy: 0.7083\n",
      "Epoch 213/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4741 - accuracy: 0.7517 - val_loss: 0.5340 - val_accuracy: 0.7083\n",
      "Epoch 214/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4736 - accuracy: 0.7517 - val_loss: 0.5337 - val_accuracy: 0.7083\n",
      "Epoch 215/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4731 - accuracy: 0.7517 - val_loss: 0.5334 - val_accuracy: 0.7083\n",
      "Epoch 216/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4726 - accuracy: 0.7552 - val_loss: 0.5331 - val_accuracy: 0.7083\n",
      "Epoch 217/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4721 - accuracy: 0.7552 - val_loss: 0.5329 - val_accuracy: 0.7083\n",
      "Epoch 218/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4716 - accuracy: 0.7552 - val_loss: 0.5326 - val_accuracy: 0.7083\n",
      "Epoch 219/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4712 - accuracy: 0.7569 - val_loss: 0.5323 - val_accuracy: 0.7083\n",
      "Epoch 220/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4707 - accuracy: 0.7569 - val_loss: 0.5321 - val_accuracy: 0.7083\n",
      "Epoch 221/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4703 - accuracy: 0.7587 - val_loss: 0.5318 - val_accuracy: 0.7135\n",
      "Epoch 222/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4698 - accuracy: 0.7587 - val_loss: 0.5316 - val_accuracy: 0.7135\n",
      "Epoch 223/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4694 - accuracy: 0.7604 - val_loss: 0.5314 - val_accuracy: 0.7135\n",
      "Epoch 224/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4689 - accuracy: 0.7622 - val_loss: 0.5312 - val_accuracy: 0.7135\n",
      "Epoch 225/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4685 - accuracy: 0.7622 - val_loss: 0.5309 - val_accuracy: 0.7135\n",
      "Epoch 226/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4681 - accuracy: 0.7622 - val_loss: 0.5307 - val_accuracy: 0.7135\n",
      "Epoch 227/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4678 - accuracy: 0.7622 - val_loss: 0.5305 - val_accuracy: 0.7135\n",
      "Epoch 228/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4674 - accuracy: 0.7622 - val_loss: 0.5303 - val_accuracy: 0.7135\n",
      "Epoch 229/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4670 - accuracy: 0.7622 - val_loss: 0.5301 - val_accuracy: 0.7135\n",
      "Epoch 230/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4666 - accuracy: 0.7604 - val_loss: 0.5299 - val_accuracy: 0.7135\n",
      "Epoch 231/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4663 - accuracy: 0.7622 - val_loss: 0.5297 - val_accuracy: 0.7188\n",
      "Epoch 232/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4659 - accuracy: 0.7604 - val_loss: 0.5295 - val_accuracy: 0.7188\n",
      "Epoch 233/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4655 - accuracy: 0.7604 - val_loss: 0.5293 - val_accuracy: 0.7188\n",
      "Epoch 234/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4652 - accuracy: 0.7604 - val_loss: 0.5291 - val_accuracy: 0.7240\n",
      "Epoch 235/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4649 - accuracy: 0.7604 - val_loss: 0.5290 - val_accuracy: 0.7240\n",
      "Epoch 236/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4646 - accuracy: 0.7604 - val_loss: 0.5288 - val_accuracy: 0.7240\n",
      "Epoch 237/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4642 - accuracy: 0.7604 - val_loss: 0.5286 - val_accuracy: 0.7240\n",
      "Epoch 238/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4639 - accuracy: 0.7587 - val_loss: 0.5285 - val_accuracy: 0.7188\n",
      "Epoch 239/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4636 - accuracy: 0.7587 - val_loss: 0.5283 - val_accuracy: 0.7188\n",
      "Epoch 240/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4633 - accuracy: 0.7604 - val_loss: 0.5281 - val_accuracy: 0.7188\n",
      "Epoch 241/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4630 - accuracy: 0.7587 - val_loss: 0.5280 - val_accuracy: 0.7188\n",
      "Epoch 242/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4627 - accuracy: 0.7569 - val_loss: 0.5279 - val_accuracy: 0.7188\n",
      "Epoch 243/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4624 - accuracy: 0.7569 - val_loss: 0.5277 - val_accuracy: 0.7188\n",
      "Epoch 244/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4621 - accuracy: 0.7587 - val_loss: 0.5276 - val_accuracy: 0.7188\n",
      "Epoch 245/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4619 - accuracy: 0.7587 - val_loss: 0.5275 - val_accuracy: 0.7188\n",
      "Epoch 246/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4616 - accuracy: 0.7587 - val_loss: 0.5273 - val_accuracy: 0.7188\n",
      "Epoch 247/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4614 - accuracy: 0.7587 - val_loss: 0.5272 - val_accuracy: 0.7188\n",
      "Epoch 248/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4611 - accuracy: 0.7587 - val_loss: 0.5271 - val_accuracy: 0.7188\n",
      "Epoch 249/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4608 - accuracy: 0.7569 - val_loss: 0.5270 - val_accuracy: 0.7188\n",
      "Epoch 250/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4606 - accuracy: 0.7587 - val_loss: 0.5269 - val_accuracy: 0.7188\n",
      "Epoch 251/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4603 - accuracy: 0.7587 - val_loss: 0.5267 - val_accuracy: 0.7188\n",
      "Epoch 252/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4601 - accuracy: 0.7587 - val_loss: 0.5266 - val_accuracy: 0.7188\n",
      "Epoch 253/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4598 - accuracy: 0.7587 - val_loss: 0.5265 - val_accuracy: 0.7188\n",
      "Epoch 254/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4596 - accuracy: 0.7622 - val_loss: 0.5264 - val_accuracy: 0.7188\n",
      "Epoch 255/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4593 - accuracy: 0.7604 - val_loss: 0.5263 - val_accuracy: 0.7188\n",
      "Epoch 256/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4591 - accuracy: 0.7622 - val_loss: 0.5262 - val_accuracy: 0.7188\n",
      "Epoch 257/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4589 - accuracy: 0.7622 - val_loss: 0.5261 - val_accuracy: 0.7188\n",
      "Epoch 258/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4586 - accuracy: 0.7622 - val_loss: 0.5260 - val_accuracy: 0.7188\n",
      "Epoch 259/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4583 - accuracy: 0.7622 - val_loss: 0.5260 - val_accuracy: 0.7188\n",
      "Epoch 260/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4581 - accuracy: 0.7604 - val_loss: 0.5259 - val_accuracy: 0.7188\n",
      "Epoch 261/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4579 - accuracy: 0.7604 - val_loss: 0.5258 - val_accuracy: 0.7188\n",
      "Epoch 262/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4576 - accuracy: 0.7587 - val_loss: 0.5257 - val_accuracy: 0.7188\n",
      "Epoch 263/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4574 - accuracy: 0.7587 - val_loss: 0.5257 - val_accuracy: 0.7188\n",
      "Epoch 264/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4572 - accuracy: 0.7604 - val_loss: 0.5256 - val_accuracy: 0.7188\n",
      "Epoch 265/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4569 - accuracy: 0.7587 - val_loss: 0.5255 - val_accuracy: 0.7188\n",
      "Epoch 266/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4567 - accuracy: 0.7569 - val_loss: 0.5255 - val_accuracy: 0.7188\n",
      "Epoch 267/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4565 - accuracy: 0.7587 - val_loss: 0.5254 - val_accuracy: 0.7240\n",
      "Epoch 268/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4562 - accuracy: 0.7569 - val_loss: 0.5253 - val_accuracy: 0.7240\n",
      "Epoch 269/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4560 - accuracy: 0.7587 - val_loss: 0.5253 - val_accuracy: 0.7240\n",
      "Epoch 270/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4558 - accuracy: 0.7622 - val_loss: 0.5252 - val_accuracy: 0.7188\n",
      "Epoch 271/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4556 - accuracy: 0.7604 - val_loss: 0.5251 - val_accuracy: 0.7188\n",
      "Epoch 272/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4553 - accuracy: 0.7604 - val_loss: 0.5250 - val_accuracy: 0.7135\n",
      "Epoch 273/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4551 - accuracy: 0.7622 - val_loss: 0.5249 - val_accuracy: 0.7135\n",
      "Epoch 274/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4549 - accuracy: 0.7622 - val_loss: 0.5248 - val_accuracy: 0.7135\n",
      "Epoch 275/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4547 - accuracy: 0.7639 - val_loss: 0.5247 - val_accuracy: 0.7135\n",
      "Epoch 276/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4545 - accuracy: 0.7656 - val_loss: 0.5246 - val_accuracy: 0.7135\n",
      "Epoch 277/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4542 - accuracy: 0.7639 - val_loss: 0.5245 - val_accuracy: 0.7135\n",
      "Epoch 278/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4540 - accuracy: 0.7639 - val_loss: 0.5244 - val_accuracy: 0.7135\n",
      "Epoch 279/1500\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4538 - accuracy: 0.7639 - val_loss: 0.5244 - val_accuracy: 0.7135\n",
      "Epoch 280/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4536 - accuracy: 0.7622 - val_loss: 0.5243 - val_accuracy: 0.7240\n",
      "Epoch 281/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4534 - accuracy: 0.7604 - val_loss: 0.5242 - val_accuracy: 0.7240\n",
      "Epoch 282/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4532 - accuracy: 0.7604 - val_loss: 0.5241 - val_accuracy: 0.7240\n",
      "Epoch 283/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4530 - accuracy: 0.7639 - val_loss: 0.5241 - val_accuracy: 0.7292\n",
      "Epoch 284/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4528 - accuracy: 0.7622 - val_loss: 0.5240 - val_accuracy: 0.7292\n",
      "Epoch 285/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4526 - accuracy: 0.7604 - val_loss: 0.5239 - val_accuracy: 0.7292\n",
      "Epoch 286/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4524 - accuracy: 0.7639 - val_loss: 0.5238 - val_accuracy: 0.7240\n",
      "Epoch 287/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4522 - accuracy: 0.7622 - val_loss: 0.5238 - val_accuracy: 0.7240\n",
      "Epoch 288/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4520 - accuracy: 0.7604 - val_loss: 0.5237 - val_accuracy: 0.7240\n",
      "Epoch 289/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4518 - accuracy: 0.7622 - val_loss: 0.5236 - val_accuracy: 0.7240\n",
      "Epoch 290/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4516 - accuracy: 0.7604 - val_loss: 0.5236 - val_accuracy: 0.7240\n",
      "Epoch 291/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4515 - accuracy: 0.7604 - val_loss: 0.5235 - val_accuracy: 0.7240\n",
      "Epoch 292/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4513 - accuracy: 0.7622 - val_loss: 0.5234 - val_accuracy: 0.7240\n",
      "Epoch 293/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4511 - accuracy: 0.7604 - val_loss: 0.5233 - val_accuracy: 0.7240\n",
      "Epoch 294/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4509 - accuracy: 0.7656 - val_loss: 0.5233 - val_accuracy: 0.7240\n",
      "Epoch 295/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4507 - accuracy: 0.7604 - val_loss: 0.5232 - val_accuracy: 0.7240\n",
      "Epoch 296/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4506 - accuracy: 0.7639 - val_loss: 0.5231 - val_accuracy: 0.7240\n",
      "Epoch 297/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4504 - accuracy: 0.7604 - val_loss: 0.5230 - val_accuracy: 0.7240\n",
      "Epoch 298/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4502 - accuracy: 0.7587 - val_loss: 0.5229 - val_accuracy: 0.7240\n",
      "Epoch 299/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4501 - accuracy: 0.7604 - val_loss: 0.5228 - val_accuracy: 0.7240\n",
      "Epoch 300/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4499 - accuracy: 0.7587 - val_loss: 0.5227 - val_accuracy: 0.7240\n",
      "Epoch 301/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4497 - accuracy: 0.7604 - val_loss: 0.5227 - val_accuracy: 0.7240\n",
      "Epoch 302/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4496 - accuracy: 0.7639 - val_loss: 0.5226 - val_accuracy: 0.7240\n",
      "Epoch 303/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4494 - accuracy: 0.7639 - val_loss: 0.5225 - val_accuracy: 0.7240\n",
      "Epoch 304/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4492 - accuracy: 0.7639 - val_loss: 0.5224 - val_accuracy: 0.7240\n",
      "Epoch 305/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4491 - accuracy: 0.7656 - val_loss: 0.5224 - val_accuracy: 0.7240\n",
      "Epoch 306/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4489 - accuracy: 0.7691 - val_loss: 0.5223 - val_accuracy: 0.7240\n",
      "Epoch 307/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4488 - accuracy: 0.7674 - val_loss: 0.5222 - val_accuracy: 0.7240\n",
      "Epoch 308/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4486 - accuracy: 0.7674 - val_loss: 0.5222 - val_accuracy: 0.7240\n",
      "Epoch 309/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4484 - accuracy: 0.7708 - val_loss: 0.5221 - val_accuracy: 0.7240\n",
      "Epoch 310/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4483 - accuracy: 0.7708 - val_loss: 0.5221 - val_accuracy: 0.7240\n",
      "Epoch 311/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4482 - accuracy: 0.7708 - val_loss: 0.5220 - val_accuracy: 0.7240\n",
      "Epoch 312/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4480 - accuracy: 0.7708 - val_loss: 0.5220 - val_accuracy: 0.7240\n",
      "Epoch 313/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4479 - accuracy: 0.7691 - val_loss: 0.5219 - val_accuracy: 0.7240\n",
      "Epoch 314/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4477 - accuracy: 0.7708 - val_loss: 0.5219 - val_accuracy: 0.7240\n",
      "Epoch 315/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4476 - accuracy: 0.7708 - val_loss: 0.5218 - val_accuracy: 0.7240\n",
      "Epoch 316/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4475 - accuracy: 0.7708 - val_loss: 0.5218 - val_accuracy: 0.7240\n",
      "Epoch 317/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4474 - accuracy: 0.7708 - val_loss: 0.5217 - val_accuracy: 0.7240\n",
      "Epoch 318/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4472 - accuracy: 0.7708 - val_loss: 0.5217 - val_accuracy: 0.7240\n",
      "Epoch 319/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4470 - accuracy: 0.7708 - val_loss: 0.5216 - val_accuracy: 0.7240\n",
      "Epoch 320/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4469 - accuracy: 0.7726 - val_loss: 0.5216 - val_accuracy: 0.7240\n",
      "Epoch 321/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4468 - accuracy: 0.7743 - val_loss: 0.5215 - val_accuracy: 0.7240\n",
      "Epoch 322/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4466 - accuracy: 0.7743 - val_loss: 0.5215 - val_accuracy: 0.7240\n",
      "Epoch 323/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4465 - accuracy: 0.7743 - val_loss: 0.5214 - val_accuracy: 0.7240\n",
      "Epoch 324/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4463 - accuracy: 0.7743 - val_loss: 0.5214 - val_accuracy: 0.7240\n",
      "Epoch 325/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4462 - accuracy: 0.7743 - val_loss: 0.5213 - val_accuracy: 0.7240\n",
      "Epoch 326/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4460 - accuracy: 0.7743 - val_loss: 0.5213 - val_accuracy: 0.7240\n",
      "Epoch 327/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4459 - accuracy: 0.7760 - val_loss: 0.5212 - val_accuracy: 0.7240\n",
      "Epoch 328/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4458 - accuracy: 0.7760 - val_loss: 0.5212 - val_accuracy: 0.7240\n",
      "Epoch 329/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4457 - accuracy: 0.7760 - val_loss: 0.5212 - val_accuracy: 0.7240\n",
      "Epoch 330/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4456 - accuracy: 0.7760 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 331/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4454 - accuracy: 0.7760 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 332/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4453 - accuracy: 0.7760 - val_loss: 0.5210 - val_accuracy: 0.7240\n",
      "Epoch 333/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4452 - accuracy: 0.7760 - val_loss: 0.5210 - val_accuracy: 0.7292\n",
      "Epoch 334/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4451 - accuracy: 0.7760 - val_loss: 0.5209 - val_accuracy: 0.7292\n",
      "Epoch 335/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4449 - accuracy: 0.7760 - val_loss: 0.5209 - val_accuracy: 0.7292\n",
      "Epoch 336/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4448 - accuracy: 0.7760 - val_loss: 0.5209 - val_accuracy: 0.7292\n",
      "Epoch 337/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4447 - accuracy: 0.7760 - val_loss: 0.5208 - val_accuracy: 0.7292\n",
      "Epoch 338/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4446 - accuracy: 0.7760 - val_loss: 0.5208 - val_accuracy: 0.7292\n",
      "Epoch 339/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4445 - accuracy: 0.7760 - val_loss: 0.5208 - val_accuracy: 0.7292\n",
      "Epoch 340/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4444 - accuracy: 0.7760 - val_loss: 0.5207 - val_accuracy: 0.7344\n",
      "Epoch 341/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4443 - accuracy: 0.7760 - val_loss: 0.5207 - val_accuracy: 0.7344\n",
      "Epoch 342/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4441 - accuracy: 0.7760 - val_loss: 0.5207 - val_accuracy: 0.7344\n",
      "Epoch 343/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4440 - accuracy: 0.7760 - val_loss: 0.5206 - val_accuracy: 0.7344\n",
      "Epoch 344/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5430 - accuracy: 0.65 - 0s 35us/step - loss: 0.4439 - accuracy: 0.7743 - val_loss: 0.5206 - val_accuracy: 0.7344\n",
      "Epoch 345/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4439 - accuracy: 0.7743 - val_loss: 0.5206 - val_accuracy: 0.7344\n",
      "Epoch 346/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4437 - accuracy: 0.7743 - val_loss: 0.5205 - val_accuracy: 0.7344\n",
      "Epoch 347/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4436 - accuracy: 0.7743 - val_loss: 0.5205 - val_accuracy: 0.7344\n",
      "Epoch 348/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4435 - accuracy: 0.7743 - val_loss: 0.5205 - val_accuracy: 0.7344\n",
      "Epoch 349/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4434 - accuracy: 0.7743 - val_loss: 0.5204 - val_accuracy: 0.7344\n",
      "Epoch 350/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4433 - accuracy: 0.7743 - val_loss: 0.5204 - val_accuracy: 0.7344\n",
      "Epoch 351/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4433 - accuracy: 0.7743 - val_loss: 0.5204 - val_accuracy: 0.7344\n",
      "Epoch 352/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4431 - accuracy: 0.7760 - val_loss: 0.5203 - val_accuracy: 0.7344\n",
      "Epoch 353/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4430 - accuracy: 0.7760 - val_loss: 0.5203 - val_accuracy: 0.7344\n",
      "Epoch 354/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4429 - accuracy: 0.7743 - val_loss: 0.5203 - val_accuracy: 0.7344\n",
      "Epoch 355/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4428 - accuracy: 0.7760 - val_loss: 0.5202 - val_accuracy: 0.7344\n",
      "Epoch 356/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4427 - accuracy: 0.7760 - val_loss: 0.5202 - val_accuracy: 0.7344\n",
      "Epoch 357/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4426 - accuracy: 0.7760 - val_loss: 0.5202 - val_accuracy: 0.7344\n",
      "Epoch 358/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4425 - accuracy: 0.7743 - val_loss: 0.5202 - val_accuracy: 0.7344\n",
      "Epoch 359/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4424 - accuracy: 0.7760 - val_loss: 0.5201 - val_accuracy: 0.7344\n",
      "Epoch 360/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4423 - accuracy: 0.7760 - val_loss: 0.5201 - val_accuracy: 0.7344\n",
      "Epoch 361/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4422 - accuracy: 0.7760 - val_loss: 0.5201 - val_accuracy: 0.7344\n",
      "Epoch 362/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4421 - accuracy: 0.7743 - val_loss: 0.5201 - val_accuracy: 0.7344\n",
      "Epoch 363/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4420 - accuracy: 0.7760 - val_loss: 0.5200 - val_accuracy: 0.7344\n",
      "Epoch 364/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4419 - accuracy: 0.7778 - val_loss: 0.5200 - val_accuracy: 0.7344\n",
      "Epoch 365/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4418 - accuracy: 0.7795 - val_loss: 0.5200 - val_accuracy: 0.7344\n",
      "Epoch 366/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4417 - accuracy: 0.7778 - val_loss: 0.5200 - val_accuracy: 0.7344\n",
      "Epoch 367/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4416 - accuracy: 0.7778 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
      "Epoch 368/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4414 - accuracy: 0.7778 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 369/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4414 - accuracy: 0.7760 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 370/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4413 - accuracy: 0.7778 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 371/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4412 - accuracy: 0.7778 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 372/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4411 - accuracy: 0.7778 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 373/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4410 - accuracy: 0.7795 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 374/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4409 - accuracy: 0.7778 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 375/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4408 - accuracy: 0.7778 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 376/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4407 - accuracy: 0.7795 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 377/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4406 - accuracy: 0.7760 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 378/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4405 - accuracy: 0.7795 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 379/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4404 - accuracy: 0.7795 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 380/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4403 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 381/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4402 - accuracy: 0.7795 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 382/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4135 - accuracy: 0.75 - 0s 35us/step - loss: 0.4401 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 383/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3684 - accuracy: 0.81 - 0s 33us/step - loss: 0.4400 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 384/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4399 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 385/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4398 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 386/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4397 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 387/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4396 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 388/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4395 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 389/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4394 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 390/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4394 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 391/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4392 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 392/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4392 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 393/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4391 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 394/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4389 - accuracy: 0.7830 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 395/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4389 - accuracy: 0.7830 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 396/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4388 - accuracy: 0.7830 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 397/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4387 - accuracy: 0.7830 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 398/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4386 - accuracy: 0.7830 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 399/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4385 - accuracy: 0.7830 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 400/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4384 - accuracy: 0.7830 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 401/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4383 - accuracy: 0.7830 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 402/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4382 - accuracy: 0.7830 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
      "Epoch 403/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4381 - accuracy: 0.7830 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
      "Epoch 404/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4380 - accuracy: 0.7830 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
      "Epoch 405/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4380 - accuracy: 0.7830 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
      "Epoch 406/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4379 - accuracy: 0.7830 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
      "Epoch 407/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4378 - accuracy: 0.7830 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
      "Epoch 408/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4377 - accuracy: 0.7830 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
      "Epoch 409/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4376 - accuracy: 0.7830 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
      "Epoch 410/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4375 - accuracy: 0.7830 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
      "Epoch 411/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4375 - accuracy: 0.7812 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
      "Epoch 412/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4374 - accuracy: 0.7830 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
      "Epoch 413/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4373 - accuracy: 0.7830 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
      "Epoch 414/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4372 - accuracy: 0.7830 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 415/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4372 - accuracy: 0.7812 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 416/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4370 - accuracy: 0.7830 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 417/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4369 - accuracy: 0.7830 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 418/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4369 - accuracy: 0.7812 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 419/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4368 - accuracy: 0.7812 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 420/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4367 - accuracy: 0.7830 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 421/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4367 - accuracy: 0.7830 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 422/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4366 - accuracy: 0.7830 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 423/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4366 - accuracy: 0.7830 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 424/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4364 - accuracy: 0.7830 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 425/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4364 - accuracy: 0.7812 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 426/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4363 - accuracy: 0.7812 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 427/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4362 - accuracy: 0.7812 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 428/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4361 - accuracy: 0.7812 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 429/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3969 - accuracy: 0.81 - 0s 35us/step - loss: 0.4361 - accuracy: 0.7812 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 430/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4361 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 431/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3619 - accuracy: 0.81 - 0s 35us/step - loss: 0.4360 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 432/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4359 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 433/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4358 - accuracy: 0.7795 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 434/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4358 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 435/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.2474 - accuracy: 0.90 - 0s 33us/step - loss: 0.4357 - accuracy: 0.7795 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 436/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4356 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 437/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4356 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 438/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4355 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 439/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4354 - accuracy: 0.7830 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
      "Epoch 440/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4354 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
      "Epoch 441/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4353 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
      "Epoch 442/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4353 - accuracy: 0.7830 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 443/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4352 - accuracy: 0.7830 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 444/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4351 - accuracy: 0.7830 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 445/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4350 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 446/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4350 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 447/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4349 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 448/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4348 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 449/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4348 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 450/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4347 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 451/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4347 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 452/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4346 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 453/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4346 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 454/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4321 - accuracy: 0.78 - 0s 33us/step - loss: 0.4345 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 455/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3891 - accuracy: 0.81 - 0s 35us/step - loss: 0.4344 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 456/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4343 - accuracy: 0.7795 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 457/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5922 - accuracy: 0.68 - 0s 35us/step - loss: 0.4343 - accuracy: 0.7812 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 458/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4342 - accuracy: 0.7795 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 459/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4342 - accuracy: 0.7795 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 460/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4341 - accuracy: 0.7795 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 461/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4341 - accuracy: 0.7795 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 462/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4340 - accuracy: 0.7795 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 463/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4339 - accuracy: 0.7795 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 464/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4339 - accuracy: 0.7795 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 465/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4338 - accuracy: 0.7795 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 466/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4337 - accuracy: 0.7795 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 467/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4337 - accuracy: 0.7795 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 468/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4336 - accuracy: 0.7795 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 469/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4336 - accuracy: 0.7795 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 470/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4335 - accuracy: 0.7795 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 471/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4334 - accuracy: 0.7795 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 472/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4334 - accuracy: 0.7795 - val_loss: 0.5189 - val_accuracy: 0.7396\n",
      "Epoch 473/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4333 - accuracy: 0.7795 - val_loss: 0.5189 - val_accuracy: 0.7396\n",
      "Epoch 474/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4333 - accuracy: 0.7795 - val_loss: 0.5189 - val_accuracy: 0.7396\n",
      "Epoch 475/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4332 - accuracy: 0.7778 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
      "Epoch 476/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4979 - accuracy: 0.75 - 0s 33us/step - loss: 0.4332 - accuracy: 0.7795 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
      "Epoch 477/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4331 - accuracy: 0.7795 - val_loss: 0.5188 - val_accuracy: 0.7448\n",
      "Epoch 478/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5426 - accuracy: 0.75 - 0s 35us/step - loss: 0.4330 - accuracy: 0.7795 - val_loss: 0.5188 - val_accuracy: 0.7448\n",
      "Epoch 479/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4330 - accuracy: 0.7795 - val_loss: 0.5188 - val_accuracy: 0.7448\n",
      "Epoch 480/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4329 - accuracy: 0.7795 - val_loss: 0.5188 - val_accuracy: 0.7396\n",
      "Epoch 481/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4329 - accuracy: 0.7795 - val_loss: 0.5188 - val_accuracy: 0.7396\n",
      "Epoch 482/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4328 - accuracy: 0.7795 - val_loss: 0.5188 - val_accuracy: 0.7396\n",
      "Epoch 483/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4328 - accuracy: 0.7795 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 484/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4327 - accuracy: 0.7795 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 485/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4326 - accuracy: 0.7795 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 486/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4326 - accuracy: 0.7795 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 487/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4325 - accuracy: 0.7795 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 488/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4325 - accuracy: 0.7778 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 489/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4324 - accuracy: 0.7795 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 490/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4324 - accuracy: 0.7795 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 491/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4323 - accuracy: 0.7812 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 492/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4322 - accuracy: 0.7778 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 493/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4322 - accuracy: 0.7812 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 494/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4321 - accuracy: 0.7795 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 495/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4321 - accuracy: 0.7795 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
      "Epoch 496/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4320 - accuracy: 0.7795 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
      "Epoch 497/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4320 - accuracy: 0.7812 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
      "Epoch 498/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4319 - accuracy: 0.7795 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
      "Epoch 499/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4319 - accuracy: 0.7812 - val_loss: 0.5185 - val_accuracy: 0.7448\n",
      "Epoch 500/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4318 - accuracy: 0.7812 - val_loss: 0.5185 - val_accuracy: 0.7448\n",
      "Epoch 501/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4318 - accuracy: 0.7795 - val_loss: 0.5184 - val_accuracy: 0.7448\n",
      "Epoch 502/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4317 - accuracy: 0.7778 - val_loss: 0.5184 - val_accuracy: 0.7448\n",
      "Epoch 503/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4316 - accuracy: 0.7795 - val_loss: 0.5184 - val_accuracy: 0.7448\n",
      "Epoch 504/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4316 - accuracy: 0.7795 - val_loss: 0.5184 - val_accuracy: 0.7448\n",
      "Epoch 505/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4315 - accuracy: 0.7795 - val_loss: 0.5184 - val_accuracy: 0.7448\n",
      "Epoch 506/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4315 - accuracy: 0.7795 - val_loss: 0.5184 - val_accuracy: 0.7448\n",
      "Epoch 507/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4314 - accuracy: 0.7778 - val_loss: 0.5184 - val_accuracy: 0.7448\n",
      "Epoch 508/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4314 - accuracy: 0.7795 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 509/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4314 - accuracy: 0.7795 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 510/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4313 - accuracy: 0.7795 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 511/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4313 - accuracy: 0.7795 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 512/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4312 - accuracy: 0.7812 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 513/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4312 - accuracy: 0.7795 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 514/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4311 - accuracy: 0.7812 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 515/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4311 - accuracy: 0.7812 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 516/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4310 - accuracy: 0.7830 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 517/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4310 - accuracy: 0.7795 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 518/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4309 - accuracy: 0.7830 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 519/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4309 - accuracy: 0.7812 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 520/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4308 - accuracy: 0.7830 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 521/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4308 - accuracy: 0.7812 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 522/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4307 - accuracy: 0.7830 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 523/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4307 - accuracy: 0.7830 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 524/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4306 - accuracy: 0.7830 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 525/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4305 - accuracy: 0.7830 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 526/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4306 - accuracy: 0.7830 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 527/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4305 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 528/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4304 - accuracy: 0.7830 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 529/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4304 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 530/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 531/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 532/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 533/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5386 - accuracy: 0.75 - 0s 36us/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 534/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 535/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 536/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4301 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 537/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 538/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 539/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 540/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4299 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 541/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 542/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 543/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 544/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4297 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 545/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4297 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 546/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4297 - accuracy: 0.7865 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 547/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4296 - accuracy: 0.7865 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 548/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4296 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 549/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4826 - accuracy: 0.75 - 0s 35us/step - loss: 0.4296 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 550/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4295 - accuracy: 0.7865 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 551/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4295 - accuracy: 0.7865 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 552/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4294 - accuracy: 0.7865 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 553/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4294 - accuracy: 0.7865 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 554/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4293 - accuracy: 0.7865 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 555/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4293 - accuracy: 0.7865 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 556/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4293 - accuracy: 0.7865 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 557/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4293 - accuracy: 0.7865 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 558/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4292 - accuracy: 0.7865 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 559/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4292 - accuracy: 0.7865 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 560/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4292 - accuracy: 0.7865 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 561/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4291 - accuracy: 0.7865 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 562/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3030 - accuracy: 0.90 - 0s 35us/step - loss: 0.4290 - accuracy: 0.7865 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 563/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4291 - accuracy: 0.7865 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 564/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4290 - accuracy: 0.7865 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 565/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 566/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 567/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4289 - accuracy: 0.7882 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 568/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4289 - accuracy: 0.7882 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 569/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4288 - accuracy: 0.7882 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 570/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4288 - accuracy: 0.7865 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 571/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4288 - accuracy: 0.7882 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 572/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4287 - accuracy: 0.7865 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 573/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4288 - accuracy: 0.7865 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 574/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4287 - accuracy: 0.7882 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 575/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4286 - accuracy: 0.7882 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 576/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4287 - accuracy: 0.7882 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 577/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4286 - accuracy: 0.7882 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 578/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4285 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 579/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4285 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 580/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 581/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 582/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 583/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 584/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 585/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4283 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
      "Epoch 586/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4283 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
      "Epoch 587/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
      "Epoch 588/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 589/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 590/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4281 - accuracy: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 591/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4281 - accuracy: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 592/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4281 - accuracy: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 593/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4281 - accuracy: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 594/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5345 - accuracy: 0.75 - 0s 35us/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 595/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 596/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 597/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4279 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 598/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4279 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 599/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4279 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 600/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4278 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 601/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4278 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 602/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4278 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 603/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4277 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 604/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4277 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 605/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4277 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 606/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4276 - accuracy: 0.7882 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
      "Epoch 607/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4276 - accuracy: 0.7882 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
      "Epoch 608/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4276 - accuracy: 0.7882 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
      "Epoch 609/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4275 - accuracy: 0.7882 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
      "Epoch 610/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4275 - accuracy: 0.7865 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 611/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4275 - accuracy: 0.7882 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 612/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5146 - accuracy: 0.75 - 0s 35us/step - loss: 0.4274 - accuracy: 0.7865 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 613/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4275 - accuracy: 0.7882 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 614/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4274 - accuracy: 0.7865 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 615/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4273 - accuracy: 0.7882 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 616/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4273 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 617/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4966 - accuracy: 0.75 - 0s 35us/step - loss: 0.4273 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 618/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4273 - accuracy: 0.7865 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 619/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4884 - accuracy: 0.71 - 0s 35us/step - loss: 0.4272 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 620/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4272 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 621/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4271 - accuracy: 0.7865 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
      "Epoch 622/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.5195 - val_accuracy: 0.7344\n",
      "Epoch 623/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.5195 - val_accuracy: 0.7292\n",
      "Epoch 624/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4270 - accuracy: 0.7865 - val_loss: 0.5195 - val_accuracy: 0.7292\n",
      "Epoch 625/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.5195 - val_accuracy: 0.7292\n",
      "Epoch 626/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4269 - accuracy: 0.7865 - val_loss: 0.5195 - val_accuracy: 0.7344\n",
      "Epoch 627/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4269 - accuracy: 0.7865 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 628/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4269 - accuracy: 0.7865 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 629/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4268 - accuracy: 0.7882 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 630/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4268 - accuracy: 0.7865 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 631/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4267 - accuracy: 0.7865 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 632/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4267 - accuracy: 0.7882 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 633/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4267 - accuracy: 0.7882 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 634/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4266 - accuracy: 0.7865 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 635/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4266 - accuracy: 0.7865 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 636/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4266 - accuracy: 0.7882 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 637/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4265 - accuracy: 0.7847 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 638/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4265 - accuracy: 0.7882 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 639/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4265 - accuracy: 0.7865 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 640/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4264 - accuracy: 0.7865 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 641/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4264 - accuracy: 0.7865 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 642/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4264 - accuracy: 0.7865 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 643/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4263 - accuracy: 0.7865 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 644/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4263 - accuracy: 0.7882 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 645/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4263 - accuracy: 0.7865 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 646/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4262 - accuracy: 0.7865 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 647/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4262 - accuracy: 0.7865 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 648/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4261 - accuracy: 0.7865 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 649/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4261 - accuracy: 0.7865 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
      "Epoch 650/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4261 - accuracy: 0.7865 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
      "Epoch 651/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4261 - accuracy: 0.7865 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
      "Epoch 652/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4260 - accuracy: 0.7865 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
      "Epoch 653/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4260 - accuracy: 0.7865 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
      "Epoch 654/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4259 - accuracy: 0.7865 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
      "Epoch 655/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4260 - accuracy: 0.7865 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
      "Epoch 656/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4259 - accuracy: 0.7865 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
      "Epoch 657/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4259 - accuracy: 0.7865 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
      "Epoch 658/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4258 - accuracy: 0.7865 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
      "Epoch 659/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4258 - accuracy: 0.7865 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
      "Epoch 660/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4257 - accuracy: 0.7865 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
      "Epoch 661/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4257 - accuracy: 0.7865 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
      "Epoch 662/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4257 - accuracy: 0.7865 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
      "Epoch 663/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4257 - accuracy: 0.7882 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
      "Epoch 664/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4256 - accuracy: 0.7847 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
      "Epoch 665/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4256 - accuracy: 0.7847 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
      "Epoch 666/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4256 - accuracy: 0.7865 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
      "Epoch 667/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4255 - accuracy: 0.7865 - val_loss: 0.5203 - val_accuracy: 0.7448\n",
      "Epoch 668/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4255 - accuracy: 0.7865 - val_loss: 0.5203 - val_accuracy: 0.7448\n",
      "Epoch 669/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4255 - accuracy: 0.7847 - val_loss: 0.5203 - val_accuracy: 0.7448\n",
      "Epoch 670/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4254 - accuracy: 0.7847 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 671/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4254 - accuracy: 0.7847 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 672/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4254 - accuracy: 0.7865 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 673/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4254 - accuracy: 0.7847 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 674/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4253 - accuracy: 0.7865 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 675/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4253 - accuracy: 0.7847 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 676/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4253 - accuracy: 0.7847 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 677/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4252 - accuracy: 0.7865 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 678/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4252 - accuracy: 0.7847 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 679/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4252 - accuracy: 0.7847 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 680/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4251 - accuracy: 0.7847 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 681/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4251 - accuracy: 0.7865 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 682/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4251 - accuracy: 0.7847 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 683/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4250 - accuracy: 0.7865 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 684/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4250 - accuracy: 0.7865 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 685/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4250 - accuracy: 0.7847 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 686/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4249 - accuracy: 0.7847 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 687/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4250 - accuracy: 0.7865 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 688/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4249 - accuracy: 0.7865 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 689/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4249 - accuracy: 0.7847 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
      "Epoch 690/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4249 - accuracy: 0.7847 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
      "Epoch 691/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4248 - accuracy: 0.7865 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
      "Epoch 692/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4248 - accuracy: 0.7865 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
      "Epoch 693/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4248 - accuracy: 0.7847 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
      "Epoch 694/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4247 - accuracy: 0.7865 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
      "Epoch 695/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4247 - accuracy: 0.7847 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
      "Epoch 696/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4247 - accuracy: 0.7847 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 697/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4246 - accuracy: 0.7847 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 698/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4246 - accuracy: 0.7847 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 699/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4246 - accuracy: 0.7847 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 700/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4246 - accuracy: 0.7847 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 701/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4246 - accuracy: 0.7865 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 702/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4245 - accuracy: 0.7847 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 703/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4044 - accuracy: 0.81 - 0s 35us/step - loss: 0.4245 - accuracy: 0.7847 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 704/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4244 - accuracy: 0.7847 - val_loss: 0.5212 - val_accuracy: 0.7500\n",
      "Epoch 705/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4245 - accuracy: 0.7847 - val_loss: 0.5212 - val_accuracy: 0.7500\n",
      "Epoch 706/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4244 - accuracy: 0.7847 - val_loss: 0.5212 - val_accuracy: 0.7500\n",
      "Epoch 707/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4244 - accuracy: 0.7847 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
      "Epoch 708/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4244 - accuracy: 0.7847 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
      "Epoch 709/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4243 - accuracy: 0.7865 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
      "Epoch 710/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4243 - accuracy: 0.7865 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
      "Epoch 711/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4242 - accuracy: 0.7847 - val_loss: 0.5214 - val_accuracy: 0.7500\n",
      "Epoch 712/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4242 - accuracy: 0.7847 - val_loss: 0.5214 - val_accuracy: 0.7500\n",
      "Epoch 713/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4242 - accuracy: 0.7847 - val_loss: 0.5214 - val_accuracy: 0.7500\n",
      "Epoch 714/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4242 - accuracy: 0.7865 - val_loss: 0.5214 - val_accuracy: 0.7500\n",
      "Epoch 715/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4242 - accuracy: 0.7847 - val_loss: 0.5215 - val_accuracy: 0.7500\n",
      "Epoch 716/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4242 - accuracy: 0.7847 - val_loss: 0.5215 - val_accuracy: 0.7500\n",
      "Epoch 717/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4241 - accuracy: 0.7847 - val_loss: 0.5215 - val_accuracy: 0.7500\n",
      "Epoch 718/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4241 - accuracy: 0.7847 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
      "Epoch 719/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4241 - accuracy: 0.7847 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
      "Epoch 720/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4240 - accuracy: 0.7865 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
      "Epoch 721/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4240 - accuracy: 0.7847 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
      "Epoch 722/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4240 - accuracy: 0.7865 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
      "Epoch 723/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4240 - accuracy: 0.7847 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
      "Epoch 724/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4239 - accuracy: 0.7847 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
      "Epoch 725/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4239 - accuracy: 0.7865 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
      "Epoch 726/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4239 - accuracy: 0.7865 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
      "Epoch 727/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4239 - accuracy: 0.7865 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
      "Epoch 728/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4238 - accuracy: 0.7847 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
      "Epoch 729/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4238 - accuracy: 0.7847 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
      "Epoch 730/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4238 - accuracy: 0.7847 - val_loss: 0.5219 - val_accuracy: 0.7500\n",
      "Epoch 731/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4238 - accuracy: 0.7865 - val_loss: 0.5219 - val_accuracy: 0.7500\n",
      "Epoch 732/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4237 - accuracy: 0.7830 - val_loss: 0.5219 - val_accuracy: 0.7500\n",
      "Epoch 733/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4237 - accuracy: 0.7847 - val_loss: 0.5220 - val_accuracy: 0.7500\n",
      "Epoch 734/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4236 - accuracy: 0.7830 - val_loss: 0.5220 - val_accuracy: 0.7500\n",
      "Epoch 735/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4236 - accuracy: 0.7847 - val_loss: 0.5220 - val_accuracy: 0.7500\n",
      "Epoch 736/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4236 - accuracy: 0.7847 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
      "Epoch 737/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4236 - accuracy: 0.7847 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
      "Epoch 738/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4236 - accuracy: 0.7847 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
      "Epoch 739/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4235 - accuracy: 0.7847 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
      "Epoch 740/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4235 - accuracy: 0.7830 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
      "Epoch 741/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4235 - accuracy: 0.7847 - val_loss: 0.5222 - val_accuracy: 0.7500\n",
      "Epoch 742/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4234 - accuracy: 0.7830 - val_loss: 0.5222 - val_accuracy: 0.7500\n",
      "Epoch 743/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4234 - accuracy: 0.7830 - val_loss: 0.5222 - val_accuracy: 0.7500\n",
      "Epoch 744/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4234 - accuracy: 0.7830 - val_loss: 0.5222 - val_accuracy: 0.7500\n",
      "Epoch 745/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4233 - accuracy: 0.7830 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 746/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4233 - accuracy: 0.7830 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 747/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4233 - accuracy: 0.7830 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 748/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4233 - accuracy: 0.7830 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 749/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4233 - accuracy: 0.7830 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
      "Epoch 750/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4232 - accuracy: 0.7847 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
      "Epoch 751/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4232 - accuracy: 0.7830 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
      "Epoch 752/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4232 - accuracy: 0.7847 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
      "Epoch 753/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4232 - accuracy: 0.7830 - val_loss: 0.5225 - val_accuracy: 0.7500\n",
      "Epoch 754/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4231 - accuracy: 0.7847 - val_loss: 0.5225 - val_accuracy: 0.7500\n",
      "Epoch 755/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4231 - accuracy: 0.7830 - val_loss: 0.5225 - val_accuracy: 0.7500\n",
      "Epoch 756/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4231 - accuracy: 0.7830 - val_loss: 0.5226 - val_accuracy: 0.7500\n",
      "Epoch 757/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4231 - accuracy: 0.7830 - val_loss: 0.5226 - val_accuracy: 0.7500\n",
      "Epoch 758/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4230 - accuracy: 0.7830 - val_loss: 0.5226 - val_accuracy: 0.7500\n",
      "Epoch 759/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4230 - accuracy: 0.7847 - val_loss: 0.5226 - val_accuracy: 0.7500\n",
      "Epoch 760/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4230 - accuracy: 0.7847 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
      "Epoch 761/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4230 - accuracy: 0.7847 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
      "Epoch 762/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4230 - accuracy: 0.7830 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
      "Epoch 763/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4229 - accuracy: 0.7830 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
      "Epoch 764/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4229 - accuracy: 0.7830 - val_loss: 0.5228 - val_accuracy: 0.7500\n",
      "Epoch 765/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4228 - accuracy: 0.7830 - val_loss: 0.5228 - val_accuracy: 0.7500\n",
      "Epoch 766/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4229 - accuracy: 0.7847 - val_loss: 0.5228 - val_accuracy: 0.7500\n",
      "Epoch 767/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4228 - accuracy: 0.7847 - val_loss: 0.5229 - val_accuracy: 0.7500\n",
      "Epoch 768/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4228 - accuracy: 0.7847 - val_loss: 0.5229 - val_accuracy: 0.7500\n",
      "Epoch 769/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4228 - accuracy: 0.7812 - val_loss: 0.5229 - val_accuracy: 0.7500\n",
      "Epoch 770/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4227 - accuracy: 0.7847 - val_loss: 0.5229 - val_accuracy: 0.7500\n",
      "Epoch 771/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4228 - accuracy: 0.7830 - val_loss: 0.5229 - val_accuracy: 0.7500\n",
      "Epoch 772/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4227 - accuracy: 0.7830 - val_loss: 0.5230 - val_accuracy: 0.7500\n",
      "Epoch 773/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4227 - accuracy: 0.7847 - val_loss: 0.5230 - val_accuracy: 0.7500\n",
      "Epoch 774/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4227 - accuracy: 0.7830 - val_loss: 0.5230 - val_accuracy: 0.7500\n",
      "Epoch 775/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4227 - accuracy: 0.7830 - val_loss: 0.5231 - val_accuracy: 0.7500\n",
      "Epoch 776/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4226 - accuracy: 0.7847 - val_loss: 0.5231 - val_accuracy: 0.7500\n",
      "Epoch 777/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4226 - accuracy: 0.7830 - val_loss: 0.5231 - val_accuracy: 0.7500\n",
      "Epoch 778/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4225 - accuracy: 0.7847 - val_loss: 0.5231 - val_accuracy: 0.7552\n",
      "Epoch 779/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4225 - accuracy: 0.7847 - val_loss: 0.5232 - val_accuracy: 0.7552\n",
      "Epoch 780/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4225 - accuracy: 0.7847 - val_loss: 0.5232 - val_accuracy: 0.7552\n",
      "Epoch 781/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4225 - accuracy: 0.7830 - val_loss: 0.5232 - val_accuracy: 0.7552\n",
      "Epoch 782/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4225 - accuracy: 0.7830 - val_loss: 0.5232 - val_accuracy: 0.7552\n",
      "Epoch 783/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4225 - accuracy: 0.7830 - val_loss: 0.5232 - val_accuracy: 0.7552\n",
      "Epoch 784/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4224 - accuracy: 0.7830 - val_loss: 0.5232 - val_accuracy: 0.7552\n",
      "Epoch 785/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4224 - accuracy: 0.7830 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
      "Epoch 786/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4224 - accuracy: 0.7830 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
      "Epoch 787/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4223 - accuracy: 0.7847 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
      "Epoch 788/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4224 - accuracy: 0.7847 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
      "Epoch 789/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4223 - accuracy: 0.7830 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
      "Epoch 790/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4223 - accuracy: 0.7830 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
      "Epoch 791/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4222 - accuracy: 0.7830 - val_loss: 0.5234 - val_accuracy: 0.7552\n",
      "Epoch 792/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4222 - accuracy: 0.7830 - val_loss: 0.5234 - val_accuracy: 0.7552\n",
      "Epoch 793/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4222 - accuracy: 0.7830 - val_loss: 0.5234 - val_accuracy: 0.7552\n",
      "Epoch 794/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4222 - accuracy: 0.7847 - val_loss: 0.5234 - val_accuracy: 0.7552\n",
      "Epoch 795/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4221 - accuracy: 0.7830 - val_loss: 0.5235 - val_accuracy: 0.7552\n",
      "Epoch 796/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4221 - accuracy: 0.7847 - val_loss: 0.5235 - val_accuracy: 0.7552\n",
      "Epoch 797/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4221 - accuracy: 0.7830 - val_loss: 0.5235 - val_accuracy: 0.7552\n",
      "Epoch 798/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4221 - accuracy: 0.7830 - val_loss: 0.5235 - val_accuracy: 0.7552\n",
      "Epoch 799/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4220 - accuracy: 0.7830 - val_loss: 0.5235 - val_accuracy: 0.7552\n",
      "Epoch 800/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4220 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
      "Epoch 801/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5058 - accuracy: 0.71 - 0s 38us/step - loss: 0.4220 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
      "Epoch 802/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4220 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
      "Epoch 803/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4219 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
      "Epoch 804/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4219 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
      "Epoch 805/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4219 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
      "Epoch 806/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4218 - accuracy: 0.7830 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
      "Epoch 807/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4218 - accuracy: 0.7830 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
      "Epoch 808/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4218 - accuracy: 0.7830 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
      "Epoch 809/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4218 - accuracy: 0.7830 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
      "Epoch 810/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4217 - accuracy: 0.7830 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
      "Epoch 811/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4217 - accuracy: 0.7830 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
      "Epoch 812/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4217 - accuracy: 0.7847 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
      "Epoch 813/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4217 - accuracy: 0.7830 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
      "Epoch 814/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4217 - accuracy: 0.7847 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
      "Epoch 815/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4216 - accuracy: 0.7847 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
      "Epoch 816/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4216 - accuracy: 0.7830 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
      "Epoch 817/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4216 - accuracy: 0.7847 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
      "Epoch 818/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.2968 - accuracy: 0.90 - 0s 35us/step - loss: 0.4216 - accuracy: 0.7847 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
      "Epoch 819/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4216 - accuracy: 0.7847 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
      "Epoch 820/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4215 - accuracy: 0.7830 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
      "Epoch 821/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4215 - accuracy: 0.7830 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
      "Epoch 822/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4215 - accuracy: 0.7847 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
      "Epoch 823/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4214 - accuracy: 0.7830 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
      "Epoch 824/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4214 - accuracy: 0.7830 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
      "Epoch 825/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4214 - accuracy: 0.7812 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
      "Epoch 826/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4214 - accuracy: 0.7830 - val_loss: 0.5241 - val_accuracy: 0.7552\n",
      "Epoch 827/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4214 - accuracy: 0.7830 - val_loss: 0.5241 - val_accuracy: 0.7552\n",
      "Epoch 828/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4214 - accuracy: 0.7812 - val_loss: 0.5241 - val_accuracy: 0.7552\n",
      "Epoch 829/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4213 - accuracy: 0.7812 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 830/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4213 - accuracy: 0.7830 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 831/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4213 - accuracy: 0.7830 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 832/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4213 - accuracy: 0.7812 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 833/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4212 - accuracy: 0.7830 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
      "Epoch 834/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4212 - accuracy: 0.7812 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
      "Epoch 835/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4212 - accuracy: 0.7812 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
      "Epoch 836/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4212 - accuracy: 0.7812 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
      "Epoch 837/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4211 - accuracy: 0.7812 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 838/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4212 - accuracy: 0.7812 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 839/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4212 - accuracy: 0.7812 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 840/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4211 - accuracy: 0.7830 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 841/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4211 - accuracy: 0.7812 - val_loss: 0.5245 - val_accuracy: 0.7552\n",
      "Epoch 842/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4211 - accuracy: 0.7812 - val_loss: 0.5245 - val_accuracy: 0.7552\n",
      "Epoch 843/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4211 - accuracy: 0.7812 - val_loss: 0.5245 - val_accuracy: 0.7552\n",
      "Epoch 844/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4211 - accuracy: 0.7812 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 845/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4210 - accuracy: 0.7812 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 846/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4210 - accuracy: 0.7812 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 847/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4210 - accuracy: 0.7812 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 848/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4210 - accuracy: 0.7812 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
      "Epoch 849/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4210 - accuracy: 0.7812 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
      "Epoch 850/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4209 - accuracy: 0.7812 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
      "Epoch 851/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4209 - accuracy: 0.7830 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
      "Epoch 852/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4209 - accuracy: 0.7812 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
      "Epoch 853/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4209 - accuracy: 0.7847 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
      "Epoch 854/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4209 - accuracy: 0.7812 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
      "Epoch 855/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4209 - accuracy: 0.7812 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
      "Epoch 856/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4209 - accuracy: 0.7812 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
      "Epoch 857/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4209 - accuracy: 0.7830 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
      "Epoch 858/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4208 - accuracy: 0.7830 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
      "Epoch 859/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4208 - accuracy: 0.7847 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
      "Epoch 860/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4922 - accuracy: 0.71 - 0s 35us/step - loss: 0.4208 - accuracy: 0.7830 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
      "Epoch 861/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4208 - accuracy: 0.7830 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
      "Epoch 862/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4208 - accuracy: 0.7847 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
      "Epoch 863/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4207 - accuracy: 0.7812 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
      "Epoch 864/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4207 - accuracy: 0.7865 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
      "Epoch 865/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4207 - accuracy: 0.7830 - val_loss: 0.5252 - val_accuracy: 0.7552\n",
      "Epoch 866/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3914 - accuracy: 0.75 - 0s 35us/step - loss: 0.4207 - accuracy: 0.7830 - val_loss: 0.5252 - val_accuracy: 0.7552\n",
      "Epoch 867/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4206 - accuracy: 0.7830 - val_loss: 0.5252 - val_accuracy: 0.7552\n",
      "Epoch 868/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4206 - accuracy: 0.7830 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
      "Epoch 869/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4207 - accuracy: 0.7830 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
      "Epoch 870/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4206 - accuracy: 0.7830 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
      "Epoch 871/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4206 - accuracy: 0.7830 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
      "Epoch 872/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4206 - accuracy: 0.7830 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
      "Epoch 873/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4206 - accuracy: 0.7830 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
      "Epoch 874/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4205 - accuracy: 0.7830 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
      "Epoch 875/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3316 - accuracy: 0.87 - 0s 33us/step - loss: 0.4206 - accuracy: 0.7812 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
      "Epoch 876/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4205 - accuracy: 0.7812 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
      "Epoch 877/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4205 - accuracy: 0.7812 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
      "Epoch 878/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4205 - accuracy: 0.7830 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
      "Epoch 879/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4205 - accuracy: 0.7812 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
      "Epoch 880/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4205 - accuracy: 0.7812 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
      "Epoch 881/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4204 - accuracy: 0.7812 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
      "Epoch 882/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4204 - accuracy: 0.7812 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
      "Epoch 883/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4204 - accuracy: 0.7830 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
      "Epoch 884/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4204 - accuracy: 0.7830 - val_loss: 0.5258 - val_accuracy: 0.7552\n",
      "Epoch 885/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4204 - accuracy: 0.7812 - val_loss: 0.5258 - val_accuracy: 0.7552\n",
      "Epoch 886/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4204 - accuracy: 0.7812 - val_loss: 0.5258 - val_accuracy: 0.7552\n",
      "Epoch 887/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4203 - accuracy: 0.7812 - val_loss: 0.5259 - val_accuracy: 0.7552\n",
      "Epoch 888/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4203 - accuracy: 0.7812 - val_loss: 0.5259 - val_accuracy: 0.7552\n",
      "Epoch 889/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4203 - accuracy: 0.7812 - val_loss: 0.5259 - val_accuracy: 0.7552\n",
      "Epoch 890/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4203 - accuracy: 0.7830 - val_loss: 0.5259 - val_accuracy: 0.7552\n",
      "Epoch 891/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4203 - accuracy: 0.7830 - val_loss: 0.5260 - val_accuracy: 0.7552\n",
      "Epoch 892/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4203 - accuracy: 0.7830 - val_loss: 0.5260 - val_accuracy: 0.7552\n",
      "Epoch 893/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4203 - accuracy: 0.7830 - val_loss: 0.5260 - val_accuracy: 0.7552\n",
      "Epoch 894/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4202 - accuracy: 0.7830 - val_loss: 0.5261 - val_accuracy: 0.7552\n",
      "Epoch 895/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4202 - accuracy: 0.7812 - val_loss: 0.5261 - val_accuracy: 0.7604\n",
      "Epoch 896/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4202 - accuracy: 0.7830 - val_loss: 0.5261 - val_accuracy: 0.7552\n",
      "Epoch 897/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4202 - accuracy: 0.7830 - val_loss: 0.5262 - val_accuracy: 0.7552\n",
      "Epoch 898/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4202 - accuracy: 0.7812 - val_loss: 0.5262 - val_accuracy: 0.7604\n",
      "Epoch 899/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4202 - accuracy: 0.7830 - val_loss: 0.5262 - val_accuracy: 0.7604\n",
      "Epoch 900/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4202 - accuracy: 0.7830 - val_loss: 0.5262 - val_accuracy: 0.7604\n",
      "Epoch 901/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4201 - accuracy: 0.7830 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
      "Epoch 902/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4201 - accuracy: 0.7830 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
      "Epoch 903/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4201 - accuracy: 0.7812 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
      "Epoch 904/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4201 - accuracy: 0.7830 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 905/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4201 - accuracy: 0.7830 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 906/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4201 - accuracy: 0.7812 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 907/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4200 - accuracy: 0.7830 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 908/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4200 - accuracy: 0.7830 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 909/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4200 - accuracy: 0.7812 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 910/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4200 - accuracy: 0.7830 - val_loss: 0.5266 - val_accuracy: 0.7604\n",
      "Epoch 911/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4200 - accuracy: 0.7812 - val_loss: 0.5266 - val_accuracy: 0.7604\n",
      "Epoch 912/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4200 - accuracy: 0.7830 - val_loss: 0.5266 - val_accuracy: 0.7604\n",
      "Epoch 913/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4200 - accuracy: 0.7830 - val_loss: 0.5267 - val_accuracy: 0.7604\n",
      "Epoch 914/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4199 - accuracy: 0.7812 - val_loss: 0.5267 - val_accuracy: 0.7604\n",
      "Epoch 915/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4199 - accuracy: 0.7812 - val_loss: 0.5267 - val_accuracy: 0.7604\n",
      "Epoch 916/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4199 - accuracy: 0.7830 - val_loss: 0.5267 - val_accuracy: 0.7604\n",
      "Epoch 917/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4199 - accuracy: 0.7830 - val_loss: 0.5268 - val_accuracy: 0.7604\n",
      "Epoch 918/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4199 - accuracy: 0.7847 - val_loss: 0.5268 - val_accuracy: 0.7604\n",
      "Epoch 919/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4199 - accuracy: 0.7830 - val_loss: 0.5269 - val_accuracy: 0.7604\n",
      "Epoch 920/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4199 - accuracy: 0.7830 - val_loss: 0.5269 - val_accuracy: 0.7604\n",
      "Epoch 921/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4199 - accuracy: 0.7830 - val_loss: 0.5269 - val_accuracy: 0.7604\n",
      "Epoch 922/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4198 - accuracy: 0.7830 - val_loss: 0.5269 - val_accuracy: 0.7604\n",
      "Epoch 923/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4198 - accuracy: 0.7830 - val_loss: 0.5270 - val_accuracy: 0.7604\n",
      "Epoch 924/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4198 - accuracy: 0.7830 - val_loss: 0.5270 - val_accuracy: 0.7604\n",
      "Epoch 925/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4198 - accuracy: 0.7830 - val_loss: 0.5271 - val_accuracy: 0.7604\n",
      "Epoch 926/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4198 - accuracy: 0.7812 - val_loss: 0.5271 - val_accuracy: 0.7604\n",
      "Epoch 927/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5272 - accuracy: 0.78 - 0s 36us/step - loss: 0.4198 - accuracy: 0.7830 - val_loss: 0.5271 - val_accuracy: 0.7604\n",
      "Epoch 928/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4197 - accuracy: 0.7812 - val_loss: 0.5272 - val_accuracy: 0.7604\n",
      "Epoch 929/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4198 - accuracy: 0.7830 - val_loss: 0.5272 - val_accuracy: 0.7604\n",
      "Epoch 930/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4198 - accuracy: 0.7830 - val_loss: 0.5272 - val_accuracy: 0.7604\n",
      "Epoch 931/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4197 - accuracy: 0.7830 - val_loss: 0.5272 - val_accuracy: 0.7604\n",
      "Epoch 932/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4197 - accuracy: 0.7812 - val_loss: 0.5273 - val_accuracy: 0.7604\n",
      "Epoch 933/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4197 - accuracy: 0.7812 - val_loss: 0.5273 - val_accuracy: 0.7604\n",
      "Epoch 934/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4197 - accuracy: 0.7830 - val_loss: 0.5273 - val_accuracy: 0.7604\n",
      "Epoch 935/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4197 - accuracy: 0.7812 - val_loss: 0.5274 - val_accuracy: 0.7604\n",
      "Epoch 936/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4196 - accuracy: 0.7847 - val_loss: 0.5274 - val_accuracy: 0.7604\n",
      "Epoch 937/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4197 - accuracy: 0.7847 - val_loss: 0.5274 - val_accuracy: 0.7604\n",
      "Epoch 938/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3993 - accuracy: 0.81 - 0s 38us/step - loss: 0.4196 - accuracy: 0.7830 - val_loss: 0.5274 - val_accuracy: 0.7604\n",
      "Epoch 939/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4197 - accuracy: 0.7847 - val_loss: 0.5274 - val_accuracy: 0.7604\n",
      "Epoch 940/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4196 - accuracy: 0.7830 - val_loss: 0.5275 - val_accuracy: 0.7604\n",
      "Epoch 941/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4196 - accuracy: 0.7847 - val_loss: 0.5275 - val_accuracy: 0.7604\n",
      "Epoch 942/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4196 - accuracy: 0.7847 - val_loss: 0.5275 - val_accuracy: 0.7604\n",
      "Epoch 943/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4196 - accuracy: 0.7847 - val_loss: 0.5276 - val_accuracy: 0.7604\n",
      "Epoch 944/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4196 - accuracy: 0.7847 - val_loss: 0.5276 - val_accuracy: 0.7604\n",
      "Epoch 945/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4196 - accuracy: 0.7830 - val_loss: 0.5276 - val_accuracy: 0.7604\n",
      "Epoch 946/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5276 - val_accuracy: 0.7604\n",
      "Epoch 947/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5277 - val_accuracy: 0.7604\n",
      "Epoch 948/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5277 - val_accuracy: 0.7604\n",
      "Epoch 949/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5277 - val_accuracy: 0.7604\n",
      "Epoch 950/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5277 - val_accuracy: 0.7604\n",
      "Epoch 951/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3148 - accuracy: 0.87 - 0s 36us/step - loss: 0.4194 - accuracy: 0.7847 - val_loss: 0.5278 - val_accuracy: 0.7604\n",
      "Epoch 952/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5278 - val_accuracy: 0.7604\n",
      "Epoch 953/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5278 - val_accuracy: 0.7604\n",
      "Epoch 954/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4194 - accuracy: 0.7847 - val_loss: 0.5279 - val_accuracy: 0.7604\n",
      "Epoch 955/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5279 - val_accuracy: 0.7604\n",
      "Epoch 956/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4194 - accuracy: 0.7847 - val_loss: 0.5279 - val_accuracy: 0.7604\n",
      "Epoch 957/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4194 - accuracy: 0.7847 - val_loss: 0.5279 - val_accuracy: 0.7604\n",
      "Epoch 958/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4194 - accuracy: 0.7847 - val_loss: 0.5280 - val_accuracy: 0.7604\n",
      "Epoch 959/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4194 - accuracy: 0.7847 - val_loss: 0.5280 - val_accuracy: 0.7604\n",
      "Epoch 960/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4193 - accuracy: 0.7830 - val_loss: 0.5280 - val_accuracy: 0.7604\n",
      "Epoch 961/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4193 - accuracy: 0.7847 - val_loss: 0.5281 - val_accuracy: 0.7604\n",
      "Epoch 962/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4193 - accuracy: 0.7847 - val_loss: 0.5281 - val_accuracy: 0.7604\n",
      "Epoch 963/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4193 - accuracy: 0.7847 - val_loss: 0.5281 - val_accuracy: 0.7604\n",
      "Epoch 964/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4193 - accuracy: 0.7847 - val_loss: 0.5281 - val_accuracy: 0.7604\n",
      "Epoch 965/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4193 - accuracy: 0.7847 - val_loss: 0.5281 - val_accuracy: 0.7604\n",
      "Epoch 966/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4193 - accuracy: 0.7847 - val_loss: 0.5282 - val_accuracy: 0.7604\n",
      "Epoch 967/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4035 - accuracy: 0.87 - 0s 33us/step - loss: 0.4193 - accuracy: 0.7847 - val_loss: 0.5282 - val_accuracy: 0.7604\n",
      "Epoch 968/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4192 - accuracy: 0.7847 - val_loss: 0.5282 - val_accuracy: 0.7604\n",
      "Epoch 969/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4193 - accuracy: 0.7847 - val_loss: 0.5283 - val_accuracy: 0.7604\n",
      "Epoch 970/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4192 - accuracy: 0.7847 - val_loss: 0.5283 - val_accuracy: 0.7604\n",
      "Epoch 971/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4192 - accuracy: 0.7847 - val_loss: 0.5283 - val_accuracy: 0.7604\n",
      "Epoch 972/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4192 - accuracy: 0.7847 - val_loss: 0.5283 - val_accuracy: 0.7604\n",
      "Epoch 973/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4192 - accuracy: 0.7847 - val_loss: 0.5284 - val_accuracy: 0.7604\n",
      "Epoch 974/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5284 - val_accuracy: 0.7604\n",
      "Epoch 975/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5284 - val_accuracy: 0.7604\n",
      "Epoch 976/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3522 - accuracy: 0.84 - 0s 35us/step - loss: 0.4192 - accuracy: 0.7847 - val_loss: 0.5284 - val_accuracy: 0.7604\n",
      "Epoch 977/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5285 - val_accuracy: 0.7552\n",
      "Epoch 978/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5285 - val_accuracy: 0.7552\n",
      "Epoch 979/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5285 - val_accuracy: 0.7552\n",
      "Epoch 980/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4191 - accuracy: 0.7830 - val_loss: 0.5285 - val_accuracy: 0.7552\n",
      "Epoch 981/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5286 - val_accuracy: 0.7552\n",
      "Epoch 982/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5286 - val_accuracy: 0.7552\n",
      "Epoch 983/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5286 - val_accuracy: 0.7552\n",
      "Epoch 984/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4190 - accuracy: 0.7847 - val_loss: 0.5287 - val_accuracy: 0.7552\n",
      "Epoch 985/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5287 - val_accuracy: 0.7552\n",
      "Epoch 986/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4190 - accuracy: 0.7847 - val_loss: 0.5287 - val_accuracy: 0.7552\n",
      "Epoch 987/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4190 - accuracy: 0.7830 - val_loss: 0.5287 - val_accuracy: 0.7552\n",
      "Epoch 988/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4190 - accuracy: 0.7847 - val_loss: 0.5287 - val_accuracy: 0.7552\n",
      "Epoch 989/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4190 - accuracy: 0.7830 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 990/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4190 - accuracy: 0.7847 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 991/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4190 - accuracy: 0.7847 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 992/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4189 - accuracy: 0.7847 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 993/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4190 - accuracy: 0.7830 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 994/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4190 - accuracy: 0.7847 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 995/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4189 - accuracy: 0.7865 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 996/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4189 - accuracy: 0.7847 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 997/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4189 - accuracy: 0.7847 - val_loss: 0.5290 - val_accuracy: 0.7552\n",
      "Epoch 998/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4189 - accuracy: 0.7830 - val_loss: 0.5290 - val_accuracy: 0.7552\n",
      "Epoch 999/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4189 - accuracy: 0.7847 - val_loss: 0.5290 - val_accuracy: 0.7552\n",
      "Epoch 1000/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4189 - accuracy: 0.7865 - val_loss: 0.5290 - val_accuracy: 0.7552\n",
      "Epoch 1001/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4188 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7552\n",
      "Epoch 1002/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4188 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7552\n",
      "Epoch 1003/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4188 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7552\n",
      "Epoch 1004/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4188 - accuracy: 0.7830 - val_loss: 0.5291 - val_accuracy: 0.7552\n",
      "Epoch 1005/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4188 - accuracy: 0.7830 - val_loss: 0.5292 - val_accuracy: 0.7552\n",
      "Epoch 1006/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4188 - accuracy: 0.7830 - val_loss: 0.5292 - val_accuracy: 0.7552\n",
      "Epoch 1007/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4187 - accuracy: 0.7830 - val_loss: 0.5292 - val_accuracy: 0.7552\n",
      "Epoch 1008/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4188 - accuracy: 0.7847 - val_loss: 0.5292 - val_accuracy: 0.7552\n",
      "Epoch 1009/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4188 - accuracy: 0.7830 - val_loss: 0.5293 - val_accuracy: 0.7552\n",
      "Epoch 1010/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4187 - accuracy: 0.7847 - val_loss: 0.5293 - val_accuracy: 0.7552\n",
      "Epoch 1011/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4187 - accuracy: 0.7865 - val_loss: 0.5293 - val_accuracy: 0.7552\n",
      "Epoch 1012/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4187 - accuracy: 0.7812 - val_loss: 0.5293 - val_accuracy: 0.7552\n",
      "Epoch 1013/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4187 - accuracy: 0.7865 - val_loss: 0.5293 - val_accuracy: 0.7552\n",
      "Epoch 1014/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4187 - accuracy: 0.7847 - val_loss: 0.5294 - val_accuracy: 0.7552\n",
      "Epoch 1015/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4187 - accuracy: 0.7865 - val_loss: 0.5294 - val_accuracy: 0.7552\n",
      "Epoch 1016/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4187 - accuracy: 0.7830 - val_loss: 0.5294 - val_accuracy: 0.7552\n",
      "Epoch 1017/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4187 - accuracy: 0.7865 - val_loss: 0.5294 - val_accuracy: 0.7552\n",
      "Epoch 1018/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4187 - accuracy: 0.7865 - val_loss: 0.5295 - val_accuracy: 0.7552\n",
      "Epoch 1019/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4186 - accuracy: 0.7847 - val_loss: 0.5295 - val_accuracy: 0.7552\n",
      "Epoch 1020/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4186 - accuracy: 0.7847 - val_loss: 0.5295 - val_accuracy: 0.7552\n",
      "Epoch 1021/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4186 - accuracy: 0.7865 - val_loss: 0.5295 - val_accuracy: 0.7552\n",
      "Epoch 1022/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4186 - accuracy: 0.7865 - val_loss: 0.5295 - val_accuracy: 0.7552\n",
      "Epoch 1023/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4186 - accuracy: 0.7847 - val_loss: 0.5296 - val_accuracy: 0.7552\n",
      "Epoch 1024/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4186 - accuracy: 0.7847 - val_loss: 0.5296 - val_accuracy: 0.7552\n",
      "Epoch 1025/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4185 - accuracy: 0.7847 - val_loss: 0.5296 - val_accuracy: 0.7552\n",
      "Epoch 1026/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4186 - accuracy: 0.7847 - val_loss: 0.5296 - val_accuracy: 0.7552\n",
      "Epoch 1027/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4185 - accuracy: 0.7847 - val_loss: 0.5297 - val_accuracy: 0.7552\n",
      "Epoch 1028/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4185 - accuracy: 0.7865 - val_loss: 0.5297 - val_accuracy: 0.7552\n",
      "Epoch 1029/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4186 - accuracy: 0.7865 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
      "Epoch 1030/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4185 - accuracy: 0.7847 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
      "Epoch 1031/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4185 - accuracy: 0.7847 - val_loss: 0.5298 - val_accuracy: 0.7500\n",
      "Epoch 1032/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4185 - accuracy: 0.7847 - val_loss: 0.5298 - val_accuracy: 0.7500\n",
      "Epoch 1033/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4185 - accuracy: 0.7830 - val_loss: 0.5298 - val_accuracy: 0.7500\n",
      "Epoch 1034/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4185 - accuracy: 0.7847 - val_loss: 0.5298 - val_accuracy: 0.7500\n",
      "Epoch 1035/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4185 - accuracy: 0.7830 - val_loss: 0.5298 - val_accuracy: 0.7500\n",
      "Epoch 1036/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4184 - accuracy: 0.7847 - val_loss: 0.5299 - val_accuracy: 0.7500\n",
      "Epoch 1037/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4184 - accuracy: 0.7847 - val_loss: 0.5299 - val_accuracy: 0.7500\n",
      "Epoch 1038/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4184 - accuracy: 0.7847 - val_loss: 0.5299 - val_accuracy: 0.7500\n",
      "Epoch 1039/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4184 - accuracy: 0.7847 - val_loss: 0.5299 - val_accuracy: 0.7500\n",
      "Epoch 1040/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4184 - accuracy: 0.7830 - val_loss: 0.5300 - val_accuracy: 0.7500\n",
      "Epoch 1041/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4184 - accuracy: 0.7847 - val_loss: 0.5300 - val_accuracy: 0.7500\n",
      "Epoch 1042/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4184 - accuracy: 0.7847 - val_loss: 0.5300 - val_accuracy: 0.7500\n",
      "Epoch 1043/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4184 - accuracy: 0.7847 - val_loss: 0.5300 - val_accuracy: 0.7500\n",
      "Epoch 1044/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4183 - accuracy: 0.7830 - val_loss: 0.5301 - val_accuracy: 0.7500\n",
      "Epoch 1045/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4184 - accuracy: 0.7847 - val_loss: 0.5301 - val_accuracy: 0.7500\n",
      "Epoch 1046/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4183 - accuracy: 0.7830 - val_loss: 0.5301 - val_accuracy: 0.7500\n",
      "Epoch 1047/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4183 - accuracy: 0.7847 - val_loss: 0.5301 - val_accuracy: 0.7500\n",
      "Epoch 1048/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4184 - accuracy: 0.7830 - val_loss: 0.5301 - val_accuracy: 0.7500\n",
      "Epoch 1049/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4183 - accuracy: 0.7847 - val_loss: 0.5302 - val_accuracy: 0.7500\n",
      "Epoch 1050/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4183 - accuracy: 0.7847 - val_loss: 0.5302 - val_accuracy: 0.7500\n",
      "Epoch 1051/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4183 - accuracy: 0.7847 - val_loss: 0.5302 - val_accuracy: 0.7500\n",
      "Epoch 1052/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4183 - accuracy: 0.7847 - val_loss: 0.5302 - val_accuracy: 0.7500\n",
      "Epoch 1053/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4183 - accuracy: 0.7847 - val_loss: 0.5302 - val_accuracy: 0.7500\n",
      "Epoch 1054/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5302 - val_accuracy: 0.7500\n",
      "Epoch 1055/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5303 - val_accuracy: 0.7500\n",
      "Epoch 1056/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5303 - val_accuracy: 0.7500\n",
      "Epoch 1057/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5303 - val_accuracy: 0.7500\n",
      "Epoch 1058/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5303 - val_accuracy: 0.7500\n",
      "Epoch 1059/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5303 - val_accuracy: 0.7500\n",
      "Epoch 1060/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5304 - val_accuracy: 0.7500\n",
      "Epoch 1061/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5304 - val_accuracy: 0.7500\n",
      "Epoch 1062/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4182 - accuracy: 0.7830 - val_loss: 0.5304 - val_accuracy: 0.7500\n",
      "Epoch 1063/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5304 - val_accuracy: 0.7500\n",
      "Epoch 1064/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5304 - val_accuracy: 0.7500\n",
      "Epoch 1065/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4182 - accuracy: 0.7865 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
      "Epoch 1066/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
      "Epoch 1067/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4181 - accuracy: 0.7847 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
      "Epoch 1068/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4077 - accuracy: 0.71 - 0s 38us/step - loss: 0.4181 - accuracy: 0.7847 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
      "Epoch 1069/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4181 - accuracy: 0.7847 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
      "Epoch 1070/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4181 - accuracy: 0.7847 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
      "Epoch 1071/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4181 - accuracy: 0.7847 - val_loss: 0.5306 - val_accuracy: 0.7500\n",
      "Epoch 1072/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4181 - accuracy: 0.7847 - val_loss: 0.5306 - val_accuracy: 0.7500\n",
      "Epoch 1073/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4180 - accuracy: 0.7847 - val_loss: 0.5306 - val_accuracy: 0.7500\n",
      "Epoch 1074/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4180 - accuracy: 0.7847 - val_loss: 0.5306 - val_accuracy: 0.7500\n",
      "Epoch 1075/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4180 - accuracy: 0.7847 - val_loss: 0.5307 - val_accuracy: 0.7500\n",
      "Epoch 1076/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4181 - accuracy: 0.7847 - val_loss: 0.5307 - val_accuracy: 0.7500\n",
      "Epoch 1077/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4180 - accuracy: 0.7830 - val_loss: 0.5307 - val_accuracy: 0.7500\n",
      "Epoch 1078/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4180 - accuracy: 0.7847 - val_loss: 0.5307 - val_accuracy: 0.7500\n",
      "Epoch 1079/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4180 - accuracy: 0.7847 - val_loss: 0.5308 - val_accuracy: 0.7500\n",
      "Epoch 1080/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4180 - accuracy: 0.7847 - val_loss: 0.5308 - val_accuracy: 0.7500\n",
      "Epoch 1081/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4180 - accuracy: 0.7847 - val_loss: 0.5308 - val_accuracy: 0.7500\n",
      "Epoch 1082/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4180 - accuracy: 0.7847 - val_loss: 0.5308 - val_accuracy: 0.7500\n",
      "Epoch 1083/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4644 - accuracy: 0.81 - 0s 43us/step - loss: 0.4180 - accuracy: 0.7847 - val_loss: 0.5308 - val_accuracy: 0.7500\n",
      "Epoch 1084/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4180 - accuracy: 0.7830 - val_loss: 0.5309 - val_accuracy: 0.7500\n",
      "Epoch 1085/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4180 - accuracy: 0.7830 - val_loss: 0.5309 - val_accuracy: 0.7500\n",
      "Epoch 1086/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4179 - accuracy: 0.7847 - val_loss: 0.5309 - val_accuracy: 0.7500\n",
      "Epoch 1087/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4179 - accuracy: 0.7847 - val_loss: 0.5309 - val_accuracy: 0.7500\n",
      "Epoch 1088/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4179 - accuracy: 0.7865 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 1089/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4179 - accuracy: 0.7847 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 1090/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4179 - accuracy: 0.7830 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 1091/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4179 - accuracy: 0.7812 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 1092/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4179 - accuracy: 0.7812 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 1093/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4179 - accuracy: 0.7847 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 1094/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4178 - accuracy: 0.7830 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 1095/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4178 - accuracy: 0.7847 - val_loss: 0.5311 - val_accuracy: 0.7500\n",
      "Epoch 1096/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4179 - accuracy: 0.7830 - val_loss: 0.5311 - val_accuracy: 0.7500\n",
      "Epoch 1097/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4178 - accuracy: 0.7847 - val_loss: 0.5311 - val_accuracy: 0.7500\n",
      "Epoch 1098/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4178 - accuracy: 0.7830 - val_loss: 0.5311 - val_accuracy: 0.7500\n",
      "Epoch 1099/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4178 - accuracy: 0.7847 - val_loss: 0.5312 - val_accuracy: 0.7500\n",
      "Epoch 1100/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4178 - accuracy: 0.7812 - val_loss: 0.5312 - val_accuracy: 0.7500\n",
      "Epoch 1101/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4178 - accuracy: 0.7812 - val_loss: 0.5312 - val_accuracy: 0.7500\n",
      "Epoch 1102/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4178 - accuracy: 0.7830 - val_loss: 0.5312 - val_accuracy: 0.7500\n",
      "Epoch 1103/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4178 - accuracy: 0.7830 - val_loss: 0.5312 - val_accuracy: 0.7500\n",
      "Epoch 1104/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4177 - accuracy: 0.7830 - val_loss: 0.5313 - val_accuracy: 0.7500\n",
      "Epoch 1105/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4177 - accuracy: 0.7830 - val_loss: 0.5313 - val_accuracy: 0.7500\n",
      "Epoch 1106/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4177 - accuracy: 0.7830 - val_loss: 0.5313 - val_accuracy: 0.7500\n",
      "Epoch 1107/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4178 - accuracy: 0.7830 - val_loss: 0.5313 - val_accuracy: 0.7500\n",
      "Epoch 1108/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4177 - accuracy: 0.7830 - val_loss: 0.5313 - val_accuracy: 0.7500\n",
      "Epoch 1109/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4177 - accuracy: 0.7830 - val_loss: 0.5313 - val_accuracy: 0.7500\n",
      "Epoch 1110/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4177 - accuracy: 0.7830 - val_loss: 0.5314 - val_accuracy: 0.7500\n",
      "Epoch 1111/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4177 - accuracy: 0.7830 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1112/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4177 - accuracy: 0.7812 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1113/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4176 - accuracy: 0.7830 - val_loss: 0.5314 - val_accuracy: 0.7396\n",
      "Epoch 1114/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4176 - accuracy: 0.7847 - val_loss: 0.5314 - val_accuracy: 0.7396\n",
      "Epoch 1115/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4177 - accuracy: 0.7830 - val_loss: 0.5315 - val_accuracy: 0.7396\n",
      "Epoch 1116/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4176 - accuracy: 0.7830 - val_loss: 0.5315 - val_accuracy: 0.7396\n",
      "Epoch 1117/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4177 - accuracy: 0.7830 - val_loss: 0.5316 - val_accuracy: 0.7396\n",
      "Epoch 1118/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4176 - accuracy: 0.7795 - val_loss: 0.5316 - val_accuracy: 0.7396\n",
      "Epoch 1119/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4176 - accuracy: 0.7795 - val_loss: 0.5316 - val_accuracy: 0.7396\n",
      "Epoch 1120/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4176 - accuracy: 0.7812 - val_loss: 0.5316 - val_accuracy: 0.7396\n",
      "Epoch 1121/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4176 - accuracy: 0.7795 - val_loss: 0.5316 - val_accuracy: 0.7396\n",
      "Epoch 1122/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4176 - accuracy: 0.7812 - val_loss: 0.5316 - val_accuracy: 0.7396\n",
      "Epoch 1123/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4175 - accuracy: 0.7795 - val_loss: 0.5317 - val_accuracy: 0.7396\n",
      "Epoch 1124/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4176 - accuracy: 0.7812 - val_loss: 0.5317 - val_accuracy: 0.7396\n",
      "Epoch 1125/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4176 - accuracy: 0.7795 - val_loss: 0.5317 - val_accuracy: 0.7396\n",
      "Epoch 1126/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4175 - accuracy: 0.7812 - val_loss: 0.5317 - val_accuracy: 0.7396\n",
      "Epoch 1127/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4175 - accuracy: 0.7812 - val_loss: 0.5317 - val_accuracy: 0.7396\n",
      "Epoch 1128/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4175 - accuracy: 0.7812 - val_loss: 0.5318 - val_accuracy: 0.7396\n",
      "Epoch 1129/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4175 - accuracy: 0.7812 - val_loss: 0.5318 - val_accuracy: 0.7396\n",
      "Epoch 1130/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4175 - accuracy: 0.7812 - val_loss: 0.5318 - val_accuracy: 0.7396\n",
      "Epoch 1131/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4175 - accuracy: 0.7812 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
      "Epoch 1132/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4175 - accuracy: 0.7812 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
      "Epoch 1133/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4174 - accuracy: 0.7812 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
      "Epoch 1134/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4175 - accuracy: 0.7795 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
      "Epoch 1135/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4174 - accuracy: 0.7778 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
      "Epoch 1136/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4174 - accuracy: 0.7812 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
      "Epoch 1137/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4174 - accuracy: 0.7812 - val_loss: 0.5320 - val_accuracy: 0.7396\n",
      "Epoch 1138/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4174 - accuracy: 0.7795 - val_loss: 0.5320 - val_accuracy: 0.7396\n",
      "Epoch 1139/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4174 - accuracy: 0.7812 - val_loss: 0.5320 - val_accuracy: 0.7396\n",
      "Epoch 1140/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4174 - accuracy: 0.7795 - val_loss: 0.5320 - val_accuracy: 0.7396\n",
      "Epoch 1141/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4174 - accuracy: 0.7795 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
      "Epoch 1142/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4174 - accuracy: 0.7812 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
      "Epoch 1143/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4173 - accuracy: 0.7795 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
      "Epoch 1144/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4173 - accuracy: 0.7812 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
      "Epoch 1145/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4173 - accuracy: 0.7795 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
      "Epoch 1146/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4173 - accuracy: 0.7812 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
      "Epoch 1147/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4173 - accuracy: 0.7812 - val_loss: 0.5322 - val_accuracy: 0.7396\n",
      "Epoch 1148/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4173 - accuracy: 0.7795 - val_loss: 0.5322 - val_accuracy: 0.7396\n",
      "Epoch 1149/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4173 - accuracy: 0.7812 - val_loss: 0.5322 - val_accuracy: 0.7396\n",
      "Epoch 1150/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4173 - accuracy: 0.7812 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 1151/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4173 - accuracy: 0.7795 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 1152/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4173 - accuracy: 0.7795 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 1153/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4173 - accuracy: 0.7812 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 1154/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4172 - accuracy: 0.7812 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 1155/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4173 - accuracy: 0.7795 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 1156/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4173 - accuracy: 0.7812 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 1157/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4172 - accuracy: 0.7795 - val_loss: 0.5324 - val_accuracy: 0.7396\n",
      "Epoch 1158/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4173 - accuracy: 0.7795 - val_loss: 0.5324 - val_accuracy: 0.7396\n",
      "Epoch 1159/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4172 - accuracy: 0.7795 - val_loss: 0.5324 - val_accuracy: 0.7396\n",
      "Epoch 1160/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4172 - accuracy: 0.7812 - val_loss: 0.5324 - val_accuracy: 0.7396\n",
      "Epoch 1161/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4172 - accuracy: 0.7795 - val_loss: 0.5324 - val_accuracy: 0.7396\n",
      "Epoch 1162/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4172 - accuracy: 0.7795 - val_loss: 0.5324 - val_accuracy: 0.7396\n",
      "Epoch 1163/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4172 - accuracy: 0.7812 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
      "Epoch 1164/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4172 - accuracy: 0.7795 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
      "Epoch 1165/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4171 - accuracy: 0.7812 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
      "Epoch 1166/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4171 - accuracy: 0.7795 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
      "Epoch 1167/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4172 - accuracy: 0.7812 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
      "Epoch 1168/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4171 - accuracy: 0.7812 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
      "Epoch 1169/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4171 - accuracy: 0.7812 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
      "Epoch 1170/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4171 - accuracy: 0.7795 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
      "Epoch 1171/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4171 - accuracy: 0.7795 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
      "Epoch 1172/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4171 - accuracy: 0.7795 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
      "Epoch 1173/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4171 - accuracy: 0.7812 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
      "Epoch 1174/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4171 - accuracy: 0.7795 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
      "Epoch 1175/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4171 - accuracy: 0.7812 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
      "Epoch 1176/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4171 - accuracy: 0.7795 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1177/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4170 - accuracy: 0.7795 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1178/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4171 - accuracy: 0.7812 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1179/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4170 - accuracy: 0.7812 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1180/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4171 - accuracy: 0.7830 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1181/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4170 - accuracy: 0.7830 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1182/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4170 - accuracy: 0.7830 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1183/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4170 - accuracy: 0.7830 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1184/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4170 - accuracy: 0.7830 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1185/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4170 - accuracy: 0.7812 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1186/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4170 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1187/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4169 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1188/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4169 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1189/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4169 - accuracy: 0.7812 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1190/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4169 - accuracy: 0.7812 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1191/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4169 - accuracy: 0.7812 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1192/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4169 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1193/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4169 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1194/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4169 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1195/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4168 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1196/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4168 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1197/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4168 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1198/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4168 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1199/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4168 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1200/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4168 - accuracy: 0.7812 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1201/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4168 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1202/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4167 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1203/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4168 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1204/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4167 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1205/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4167 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1206/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4167 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1207/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4167 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1208/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4167 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1209/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4167 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1210/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4167 - accuracy: 0.7830 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 1211/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4167 - accuracy: 0.7830 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 1212/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 1213/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 1214/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 1215/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 1216/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 1217/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 1218/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 1219/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 1220/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4166 - accuracy: 0.7847 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 1221/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 1222/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 1223/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 1224/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4166 - accuracy: 0.7847 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 1225/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4165 - accuracy: 0.7847 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 1226/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4165 - accuracy: 0.7847 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 1227/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4165 - accuracy: 0.7847 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 1228/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 1229/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4165 - accuracy: 0.7847 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 1230/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4165 - accuracy: 0.7847 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 1231/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4165 - accuracy: 0.7847 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 1232/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4165 - accuracy: 0.7830 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 1233/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4165 - accuracy: 0.7830 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 1234/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4165 - accuracy: 0.7830 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1235/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4164 - accuracy: 0.7830 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1236/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4164 - accuracy: 0.7847 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1237/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4164 - accuracy: 0.7847 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1238/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4164 - accuracy: 0.7847 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1239/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4164 - accuracy: 0.7847 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1240/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4164 - accuracy: 0.7830 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1241/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4164 - accuracy: 0.7847 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1242/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4164 - accuracy: 0.7847 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1243/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4164 - accuracy: 0.7830 - val_loss: 0.5334 - val_accuracy: 0.7396\n",
      "Epoch 1244/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5334 - val_accuracy: 0.7396\n",
      "Epoch 1245/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4164 - accuracy: 0.7847 - val_loss: 0.5334 - val_accuracy: 0.7396\n",
      "Epoch 1246/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5334 - val_accuracy: 0.7396\n",
      "Epoch 1247/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5334 - val_accuracy: 0.7396\n",
      "Epoch 1248/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 1249/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 1250/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 1251/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 1252/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 1253/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 1254/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 1255/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 1256/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 1257/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 1258/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 1259/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 1260/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 1261/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 1262/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 1263/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 1264/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 1265/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 1266/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 1267/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 1268/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 1269/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 1270/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 1271/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 1272/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 1273/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 1274/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 1275/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 1276/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 1277/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 1278/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 1279/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 1280/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5339 - val_accuracy: 0.7396\n",
      "Epoch 1281/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5339 - val_accuracy: 0.7396\n",
      "Epoch 1282/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5339 - val_accuracy: 0.7396\n",
      "Epoch 1283/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5339 - val_accuracy: 0.7396\n",
      "Epoch 1284/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5339 - val_accuracy: 0.7396\n",
      "Epoch 1285/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 1286/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 1287/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4159 - accuracy: 0.7847 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 1288/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4159 - accuracy: 0.7847 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 1289/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 1290/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4159 - accuracy: 0.7847 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 1291/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4159 - accuracy: 0.7847 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 1292/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4159 - accuracy: 0.7847 - val_loss: 0.5341 - val_accuracy: 0.7396\n",
      "Epoch 1293/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4159 - accuracy: 0.7847 - val_loss: 0.5341 - val_accuracy: 0.7396\n",
      "Epoch 1294/1500\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4159 - accuracy: 0.7847 - val_loss: 0.5341 - val_accuracy: 0.7396\n",
      "Epoch 1295/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5341 - val_accuracy: 0.7396\n",
      "Epoch 1296/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4159 - accuracy: 0.7847 - val_loss: 0.5342 - val_accuracy: 0.7396\n",
      "Epoch 1297/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4159 - accuracy: 0.7847 - val_loss: 0.5342 - val_accuracy: 0.7344\n",
      "Epoch 1298/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5342 - val_accuracy: 0.7344\n",
      "Epoch 1299/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5343 - val_accuracy: 0.7344\n",
      "Epoch 1300/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5343 - val_accuracy: 0.7344\n",
      "Epoch 1301/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5343 - val_accuracy: 0.7344\n",
      "Epoch 1302/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
      "Epoch 1303/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
      "Epoch 1304/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
      "Epoch 1305/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
      "Epoch 1306/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
      "Epoch 1307/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 1308/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4157 - accuracy: 0.7847 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 1309/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4157 - accuracy: 0.7847 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 1310/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4157 - accuracy: 0.7847 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 1311/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4157 - accuracy: 0.7847 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 1312/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4157 - accuracy: 0.7847 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 1313/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4157 - accuracy: 0.7847 - val_loss: 0.5345 - val_accuracy: 0.7292\n",
      "Epoch 1314/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4157 - accuracy: 0.7847 - val_loss: 0.5346 - val_accuracy: 0.7292\n",
      "Epoch 1315/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5346 - val_accuracy: 0.7292\n",
      "Epoch 1316/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4157 - accuracy: 0.7847 - val_loss: 0.5346 - val_accuracy: 0.7292\n",
      "Epoch 1317/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5346 - val_accuracy: 0.7292\n",
      "Epoch 1318/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 1319/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 1320/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4157 - accuracy: 0.7847 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 1321/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 1322/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 1323/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5348 - val_accuracy: 0.7292\n",
      "Epoch 1324/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5348 - val_accuracy: 0.7292\n",
      "Epoch 1325/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5348 - val_accuracy: 0.7292\n",
      "Epoch 1326/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5348 - val_accuracy: 0.7292\n",
      "Epoch 1327/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4155 - accuracy: 0.7847 - val_loss: 0.5349 - val_accuracy: 0.7292\n",
      "Epoch 1328/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5349 - val_accuracy: 0.7292\n",
      "Epoch 1329/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5349 - val_accuracy: 0.7292\n",
      "Epoch 1330/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4155 - accuracy: 0.7847 - val_loss: 0.5349 - val_accuracy: 0.7292\n",
      "Epoch 1331/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4155 - accuracy: 0.7847 - val_loss: 0.5350 - val_accuracy: 0.7292\n",
      "Epoch 1332/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4155 - accuracy: 0.7830 - val_loss: 0.5350 - val_accuracy: 0.7292\n",
      "Epoch 1333/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4155 - accuracy: 0.7847 - val_loss: 0.5350 - val_accuracy: 0.7292\n",
      "Epoch 1334/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5350 - val_accuracy: 0.7292\n",
      "Epoch 1335/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4155 - accuracy: 0.7847 - val_loss: 0.5351 - val_accuracy: 0.7292\n",
      "Epoch 1336/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5351 - val_accuracy: 0.7292\n",
      "Epoch 1337/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5351 - val_accuracy: 0.7292\n",
      "Epoch 1338/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4155 - accuracy: 0.7847 - val_loss: 0.5351 - val_accuracy: 0.7292\n",
      "Epoch 1339/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4155 - accuracy: 0.7847 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 1340/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4155 - accuracy: 0.7847 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 1341/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 1342/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4155 - accuracy: 0.7847 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 1343/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 1344/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 1345/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 1346/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 1347/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 1348/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 1349/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 1350/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 1351/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 1352/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4153 - accuracy: 0.7847 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 1353/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4153 - accuracy: 0.7830 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 1354/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4153 - accuracy: 0.7830 - val_loss: 0.5354 - val_accuracy: 0.7292\n",
      "Epoch 1355/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4153 - accuracy: 0.7847 - val_loss: 0.5354 - val_accuracy: 0.7292\n",
      "Epoch 1356/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4153 - accuracy: 0.7847 - val_loss: 0.5354 - val_accuracy: 0.7292\n",
      "Epoch 1357/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4153 - accuracy: 0.7847 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 1358/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4153 - accuracy: 0.7847 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 1359/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4153 - accuracy: 0.7847 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 1360/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4153 - accuracy: 0.7847 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 1361/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4153 - accuracy: 0.7847 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 1362/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4153 - accuracy: 0.7847 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 1363/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4153 - accuracy: 0.7830 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 1364/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4152 - accuracy: 0.7847 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 1365/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4152 - accuracy: 0.7830 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 1366/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4152 - accuracy: 0.7847 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 1367/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4152 - accuracy: 0.7865 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 1368/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4152 - accuracy: 0.7847 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 1369/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4152 - accuracy: 0.7847 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 1370/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4152 - accuracy: 0.7847 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 1371/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4152 - accuracy: 0.7830 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 1372/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4152 - accuracy: 0.7847 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 1373/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4152 - accuracy: 0.7830 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 1374/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4152 - accuracy: 0.7865 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 1375/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4152 - accuracy: 0.7865 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 1376/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4152 - accuracy: 0.7865 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1377/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4152 - accuracy: 0.7865 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1378/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4152 - accuracy: 0.7847 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1379/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4152 - accuracy: 0.7865 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1380/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4152 - accuracy: 0.7847 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1381/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4152 - accuracy: 0.7865 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1382/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1383/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1384/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1385/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1386/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4151 - accuracy: 0.7847 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 1387/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 1388/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4151 - accuracy: 0.7847 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 1389/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 1390/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 1391/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5360 - val_accuracy: 0.7292\n",
      "Epoch 1392/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4151 - accuracy: 0.7847 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 1393/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 1394/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4151 - accuracy: 0.7847 - val_loss: 0.5360 - val_accuracy: 0.7292\n",
      "Epoch 1395/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5360 - val_accuracy: 0.7292\n",
      "Epoch 1396/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5360 - val_accuracy: 0.7292\n",
      "Epoch 1397/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4151 - accuracy: 0.7847 - val_loss: 0.5361 - val_accuracy: 0.7292\n",
      "Epoch 1398/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5361 - val_accuracy: 0.7292\n",
      "Epoch 1399/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5361 - val_accuracy: 0.7292\n",
      "Epoch 1400/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5361 - val_accuracy: 0.7292\n",
      "Epoch 1401/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 1402/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5361 - val_accuracy: 0.7292\n",
      "Epoch 1403/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 1404/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 1405/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 1406/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4149 - accuracy: 0.7847 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 1407/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4149 - accuracy: 0.7847 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 1408/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4149 - accuracy: 0.7847 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 1409/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4149 - accuracy: 0.7830 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 1410/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4149 - accuracy: 0.7830 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 1411/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4149 - accuracy: 0.7847 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 1412/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4149 - accuracy: 0.7847 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 1413/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4149 - accuracy: 0.7847 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 1414/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4149 - accuracy: 0.7847 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 1415/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4149 - accuracy: 0.7847 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 1416/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4149 - accuracy: 0.7847 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 1417/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 1418/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
      "Epoch 1419/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
      "Epoch 1420/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
      "Epoch 1421/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
      "Epoch 1422/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
      "Epoch 1423/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 1424/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 1425/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 1426/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 1427/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 1428/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 1429/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 1430/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1431/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1432/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1433/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4147 - accuracy: 0.7830 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1434/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1435/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1436/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1437/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1438/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1439/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1440/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1441/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5367 - val_accuracy: 0.7292\n",
      "Epoch 1442/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5367 - val_accuracy: 0.7292\n",
      "Epoch 1443/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5367 - val_accuracy: 0.7292\n",
      "Epoch 1444/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5367 - val_accuracy: 0.7292\n",
      "Epoch 1445/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 1446/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 1447/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 1448/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 1449/1500\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 1450/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 1451/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 1452/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 1453/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 1454/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 1455/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 1456/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 1457/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 1458/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 1459/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 1460/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5370 - val_accuracy: 0.7292\n",
      "Epoch 1461/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 1462/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5370 - val_accuracy: 0.7292\n",
      "Epoch 1463/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5370 - val_accuracy: 0.7292\n",
      "Epoch 1464/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5371 - val_accuracy: 0.7292\n",
      "Epoch 1465/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5371 - val_accuracy: 0.7292\n",
      "Epoch 1466/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5371 - val_accuracy: 0.7292\n",
      "Epoch 1467/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5371 - val_accuracy: 0.7292\n",
      "Epoch 1468/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5371 - val_accuracy: 0.7292\n",
      "Epoch 1469/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 1470/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4145 - accuracy: 0.7830 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 1471/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 1472/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 1473/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4144 - accuracy: 0.7830 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 1474/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 1475/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 1476/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 1477/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 1478/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 1479/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 1480/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 1481/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 1482/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 1483/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5374 - val_accuracy: 0.7292\n",
      "Epoch 1484/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5374 - val_accuracy: 0.7292\n",
      "Epoch 1485/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 1486/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5374 - val_accuracy: 0.7292\n",
      "Epoch 1487/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 1488/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 1489/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 1490/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 1491/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 1492/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 1493/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 1494/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4143 - accuracy: 0.7830 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 1495/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 1496/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4142 - accuracy: 0.7847 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
      "Epoch 1497/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
      "Epoch 1498/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4142 - accuracy: 0.7830 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 1499/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 1500/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4142 - accuracy: 0.7847 - val_loss: 0.5376 - val_accuracy: 0.7292\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(6, input_shape=(8,), activation=\"relu\"))\n",
    "model_2.add(Dense(6,  activation=\"relu\"))\n",
    "model_2.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_2.compile(sgd(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy over iterations')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(range(n), (run_hist_2.history[\"accuracy\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_accuracy\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy is 0.729\n",
      "roc-auc is 0.796\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAHiCAYAAADSwATnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXyU1dn/8e/FrsgiiyC7CoiIbbAg1gc1dbdYrbX2B6igj63drArKIgKCKKioqC22xvVBG/cNFXeNKIqAGNlRNiFssoUdsp3fH/eAMWaZJDNzZvm8X6+8yGTuzHznZJhrrnOfuW9zzgkAAMSPGr4DAACAH6M4AwAQZyjOAADEGYozAABxhuIMAECcoTgDABBnKM5IWmZ2iJm9bmbbzewF33kQHjN70sxuD31/qpktDfP3rjSzT6Obzi8z62BmzsxqlXH9GDN7Ota5EHkU5yRhZqvMbK+Z7TKzDaEXuMNKbHOKmX1oZjtDBet1M+taYpuGZna/ma0O3day0OVmZdyvmdl1ZrbAzHabWY6ZvWBmJ0Tz8Ybp95JaSGrqnLu0ujdmZumhF8bJJX7+qZldGfr+ytA2Q0psk2Nm6WXcbmcze83MNpnZVjN7x8yOrW7ecJR43mw0sycOPG/MLMvM/hj6/sBjf7nE7/889POsEj83M1thZouqk88594lzLupjkQqFHYmF4pxcfuOcO0xSmqTukm4+cIWZ/VLSu5Jek9RK0lGSvpY0w8yODm1TR9IHko6XdJ6khpJOkbRF0kll3OcDkq6XdJ2kJpI6S3pVUp/Khi+rG6iG9pK+cc4VRDDLbkkDzKxDOb++VdIwM2sY5t01ljRV0rEK3kzMUvB3ipUDz5sTJfWUNLKM7TZJOsXMmhb72UBJ35Sy7WmSjpB0tJn1jGTYZBaF/wNIUBTnJOSc2yDpHQVF+oC7JU1xzj3gnNvpnNvqnBspaaakMaFtBkhqJ+li59wi51yRc+5759w459y0kvdjZp0k/V1SP+fch865/c65Pc65/zrn7gxtc7D7Cl3+UYcS6rr+bmbfSvrWzP5jZveUuJ/XzGxw6PtWZvZSqMtcaWbXlTYGZjZW0mhJ/y/UFV5tZjXMbKSZfWdm35vZFDNrFNr+wHTh1Wa2WtKHZQxvrqQnJd1axvWStFjS55IGlbPNQc65Wc65x0J/k3xJkyQdW6IIFn9sjULZN4Uey0gzqxG67spQJ3+PmW0LjdH5YeZYK+ktSd3K2CRPwRuvvqH7qinpD5L+W8q2AxW8wZgW+r5MZtbdzOaGZnSek1Sv2HXpZpZT7PJwM1se2naRmV3805uzf4ZmhpaY2ZnFrmhkZo+Z2XozW2tmt5tZTTM7TtJ/JP0y9FzJDW1fNzSOq0OzCv8xs0NC1zUzszfMLDc02/HJgb9BKY/PWTC7tMLMNpvZxBJ/rxlmNsnMtkoaU97ztJj/NbN1ocdyYzlje7KZfRbK+bUVm70J/d+8PXT9Lgtm0pqa2X/NbIeZza7gTSiiiOKchMysjaTzJS0LXT5UQQdc2n7X5yWdHfr+LElvO+d2hXlXZ0rKcc7Nql5i/VZSL0ldJWUqKKgmSWZ2uKRzJD0bekF7XUHH3zp0/zeY2bklb9A5d6uk8ZKec84d5px7TNKVoa9fSTpa0mGS/lXiV0+XdJykn9xmMXdIusTKn3oeJWmQmTUpZ5uynCZpg3NuSxnX/1NSIwWP4XQFb6quKnZ9L0lLJTVT8KbssQPjWR4zayvp15K+KmezKaH7k4IxWihpXYnbOVTBLoX/hr76WjArU9p91lFQ8J9SMPPygqRLyrn/5ZJOVfD4x0p62syOLHZ9L0krFDz2WyW9XOxv8H+SCiR1VDCzdI6kPzrnFkv6i6TPQ8+VxqHt71IwE5QW+p3WCt7wSdKNknIkNVcw2zFCUnnHQr5YUg8FsxMXSfrfUjIfoeC5daUqfp7+SlKn0GMYbmZnlbxDM2st6U1JtysY25skvWRmzYtt1lfSFaHHdoyCN5VPhLZfrPLfhCKKKM7J5VUz2ylpjaTv9cN/rCYK/tbrS/md9QpeyCSpaRnblKWy25dlQqhr3CvpEwUvcqeGrvu9ghfNdQqmXJs7525zzuU551ZIekShTi4Ml0m6zzm3IvQG5GYFhaP4VOIY59zuUJZShWYm/iPptnK2yVawG2FYmNkkHXxjNVnS4DKurynp/0m6OTQDskrSvQpeYA/4zjn3iHOuUEFBOlJBASnLq6Fu8VNJHyt4U1Mq59xnkpqE3pgMUFCsS/qdpP0KHv8bkmqp7N0cJ0uqLel+51y+c+5FSbPLuf8XnHPrQrM6z0n6Vj/e5fJ9sdt6TsGblD5m1kLBG9YbQn/f7xXMUJT63Am9mfmTpEGh5+ZOBeNyYPt8BePaPnRfn7jyT1RwV+h2Vku6X1K/Ytetc8790zlXEHrehfM8HRt6HPMVFNPit3fA5ZKmOeemhcbrPUlzFLwBO+AJ59xy59x2BbMmy51z74d2Bb2g4E0MPKA4J5ffOucaSEqX1EU/FN1tkooUvJiUdKSkzaHvt5SxTVkqu31Z1hz4JvQC96x+eLHprx+mTdtLahWaossNFZQRKr/wFNdK0nfFLn+noHAU//01Cs9dks41s5+Xs81oSX81s5bFfxiaQjzw1a7Yz5srKGgPOeeeKeM2m0mqU8rjaF3s8oYD3zjn9oS+/dHiwBJ+65xr7Jxr75z7W3lvTEKeknStgu7tlVKuHyjp+VCx2S/pZZU9td1K0toShe27MraVmQ0ws+xif/9u+uF5rjJuq5WC505tSeuL/e7DCrrV0jSXdKikL4tt/3bo55I0UcHM1Luh6erhZWUOKf68OpCptOukyj9PS97eAe0lXVri/0tv/fj/7MZi3+8t5XJ5zxtEEcU5CTnnPlawX/Se0OXdCqarSlux/AcFi8Ak6X0FBad+mHf1gaQ2ZtajnG12K3iRO6BlKduU7DiekfR7M2uvYMrvpdDP10haGSokB74aOOd+rfCsU/CCdUA7BdOcxV+QwjpNW2jK+X5J48rZZomCwjSixM8PK/a1Wjo4ff+upKnOuTvKuevNCrq2ko9jbTi5I+QpSX9T0JXtKX5FqPM/Q9LlFnxqYIOC2Y9fW+kr/tdLal1i2r1dKdsp9Hx4RMEbg6ah6ecFkor/bmm3tU7Bc2e/pGbFnjsNnXPHh7Yr+XffrKA4HV9s+0ahhXMKzVrc6Jw7WtJvJA0uvn+7FG1LyXRAyfsO53la3u0dsEbSUyX+v9Q/sB4E8Y3inLzul3S2mR1YFDZc0sDQwpQGZna4BZ8l/aWCfXdS8KK7RsF+qS6hhSlNzWyEmf2kADrnvpX0kKRnLFi4U8fM6plZ32KdRLak35nZoWbWUdLVFQV3zn2lYGXwo5Lecc7lhq6aJWmHmQ2z4DPMNc2sm4W/GvgZBfuBj7Lg40IH9klXejV3yH0K9uUfV842YxXsD25c1gYWrOp+R9IM51y5HVhoqvp5SXeE/o7tFUyBx+yzrc65lQr2dd9SytVXKFi9fayCfbVpCvbb5qj0qdfPFRSe68yslpn9TmV/MqC+gkK2SZLM7Cr9dPHaEaHbqm1mlyr420xzzq1X8ObnXgs+LljDzI4xs9NDv7dRwRvNOqHHWKTgjcAkMzsidH+tD6xvMLMLzKxj6I3ADkmFoa+yDAn9n2ur4NMNz5WzbTjP01Gh/1PHK3h+lXZ7T0v6jZmdG/q/Ui/0/7RNOfeNOEFxTlLOuU0K9geOCl3+VMECnt8p6Fa+U7A/qXeoyCo0BXmWpCWS3lPwojNLwbThF2Xc1XUKFqtMVrCSebmCxS+vh66fpGCV70YF+z9LW9lbmmdCWTKLPaZCBV1KmqSVCrqbRxUsDgrH4wregEwP/f4+Sf8I83d/wjm3Q8GCqzIXfYUK2VMKCktZLlawP/2qsqa8S/iHghmJFQr2E2cqeGwx45z7NLQOoKSBCqblNxT/UrCP/idT2865PAXPySsV7H75fwpmG0q7z0UK9q9/ruD5dIKkGSU2+0LBQqnNChZX/d79sLBugIJdAotC9/Wifpji/VDB4rYNZnZgN88wBVPXM81sh4KZpQOLADuFLu8K5XnIOZdVWu6Q1yR9qeDN6puSHitn23Cepx+Hsn0g6R7n3Lslb8Q5t0bB4rMRCt7QrJE0RLzuJwQrfw0DAKA6zMxJ6uScW+Y7CxIH76AAAIgzFGcAAOIM09oAAMQZOmcAAOIMxRkAgDhT4RlQzOxxSRdI+t4595MD4oc+5/eAgkPC7ZF0pXNubkW326xZM9ehQ4eDl3fv3q369cM99gUqi/GNLsY3ehjb6GJ8o6fk2H755ZebnXPNy/mVg8I5PdmTCj7HWtoxdKXgeLWdQl+9JP079G+5OnTooDlz5hy8nJWVpfT09DDioCoY3+hifKOHsY0uxjd6So6tmZV5aNqSKpzWds5NV3B+2rJcpOBUhM45N1NS4xJniQEAAJUQiRN7t9aPD8KeE/pZJM5WBABIMhkZGcrMzKx4wwTXrFmzKs9KRKI4l3ae2FI/n2Vm10i6RpJatGihrKysg9ft2rXrR5cRWYxvdDG+0cPYRpeP8X3ooYe0bNkydezYMab3GyvOOW3cuFFpaWlVHttIFOcc/fgMKW1U+hlS5JzLkJQhST169HDF31Gw3yO6GN/oYnyjh7GNLh/j27hxY/Xo0SMp33QVFRVp8eLFqlOnjtauXVvlsY3ER6mmShpggZMlbQ+dAQYAgJThnNPNN98s55w6depUrdsK56NUz0hKl9TMzHIk3argpOVyzv1H0jQFH6NapuCjVFdVKxEAAAkmPz9fM2bM0PDhw3X44YdX+/YqLM7OudLOwVr8eifp79VOAgBAgho3bpwGDBgQkcIsRWafMwAgzoS7Ijo3N1eNGzeOQaIfZGdnKy0tLab3GS379+/XSy+9pFtvvVU1a9aM2O1y+E4ASEKZmZnKzs72HaNUaWlp6t+/v+8YEfHQQw+pd+/eES3MEp0zACStcD7Kw2r4qtm9e7cefvhhDR48OCq3T+cMAEAlvfrqq1Ht/inOAACEafv27Ro2bJj69++vli1bRu1+KM4AAIQhLy9Ps2bN0rBhwxSckDF6KM4AAFRg8+bNGjRokE4//XQ1adIk6vfHgjAAKEeinqQhmT6u5NuWLVv03XffacKECapTp05M7pPOGQDKEc8fSSpPMn1cyaf169dr9OjR6tKlixo2bBiz+6VzBoAKVOfsQkhcOTk52rZtmyZOnKhDDz00pvdN5wwAQAnr16/X3XffrU6dOsW8MEt0zgAA/Mjy5cu1c+dOTZw4UXXr1vWSgc4ZAICQHTt26N///reOP/54b4VZonMGkCKquuqaVc+pY9GiRdq4caMmTpwY9c8xV4TOGUBKqOqqa1Y9p4aCggK99NJLOu2007wXZonOGUAKYdU1SjN37lytWLFCo0aN8h3lIDpnAEDKcs5p9uzZuuSSS3xH+RE6ZwBASpoxY4YWLFigP//5z76j/ASdMwAg5ezevVvbtm3TNddc4ztKqeicASSFilZjs+oaB7z//vtauHChrr/+et9RykTnDCApVLQam1XXkKSVK1eqadOmcV2YJTpnAEmE1dgozxtvvKHVq1frb3/7m+8oFaI4AwCS3qeffqqePXvqggsu8B0lLExrAwCS2rRp07Rs2TK1aNHCd5Sw0TkDAJLWyy+/rHPOOUeHHXaY7yiVQnEGUGVVPV51ZeTm5qpx48YVbsdqbJQ0ffp05eXlJVxhlpjWBlANVT1edTSwGhvFPfbYY+rWrZv69u3rO0qV0DkDqJZor5DOyspSenp61G4fyWfBggVq1qyZmjRp4jtKldE5AwCSxgMPPKBDDz1UF110ke8o1UJxBgAkhTVr1qhr1646+uijfUepNoozACChOed05513avPmzTr77LN9x4kI9jkDSSoWK6lZIQ3fnHPKycnRr371K3Xv3t13nIihcwaSVCxWUrNCGj455zR27Fht2LBBvXr18h0nouicgSTGsaaRrIqKirRw4UJdfvnl6tixo+84EUfnDABIKM45jRw5UkVFRUlZmCU6ZwBAAikoKFBWVpaGDRumRo0a+Y4TNXTOAICEMX78eLVt2zapC7NE5wzEhWisrGYlNZJJXl6ennvuOY0cOVI1aiR/X5n8jxBIANFYWc1KaiSTRx55RKeeempKFGaJzhmIG6ysBn5q7969+te//qUhQ4b4jhJTqfEWBACQcJxzev3113XZZZf5jhJzFGcAQNzZuXOnhgwZot///vdq1aqV7zgxR3EGAMSVffv26csvv9Tw4cNTZh9zSan5qAEAcWnr1q0aPHiwTj75ZDVr1sx3HG9YEAYAiAtbtmzR6tWrNWHCBNWrV893HK/onAEA3m3cuFGjR49Wx44dk/4AI+GgcwYAeLVu3Tpt3rxZd999t+rXr+87TlygcwYAeLNp0ybdeeed6tSpE4W5GDpnAIAXq1at0pYtWzRx4kTVrVvXd5y4QucMAIi5PXv26J///KdOOOEECnMp6JyRkiJ9oonc3Fw1bty4yr/PSSqQSpYuXapVq1bpnnvukZn5jhOX6JyRkqJxoonq4CQVSBWFhYV68cUXdeaZZ1KYy0HnjJQVyRNNZGVlKT09PSK3BSSrr7/+WgsWLNAtt9ziO0rco3MGAERdUVGRZs+erX79+vmOkhDonAEAUTVz5kzNnj1b//jHP3xHSRh0zgCAqNm5c6e2bduma6+91neUhELnjJRQcnU2q6OB6MvKytKcOXN00003+Y6ScOickRJKrs5mdTQQXcuWLVOTJk0ozFVE54yUEcnV2QDK9vbbb+ubb77Rdddd5ztKwqI4AwAiZvr06TrxxBN13nnn+Y6S0JjWBgBExLvvvqulS5fqiCOO8B0l4dE5AwCq7eWXX9ZZZ52lc845x3eUpEDnDAColi+++EJ79+5Vw4YNfUdJGhRnAECVPfHEE+rQoYMuu+wy31GSCsUZAFAl3377rRo2bKgWLVr4jpJ0KM4AgEqbPHmyCgsLdckll/iOkpQozgCAStmwYYM6duyoLl26+I6StCjOAICwOOd0zz33aPXq1Tr33HN9x0lqFGckrYyMDKWnpys9Pf1Hh+4EUHnOOa1du1a9e/fWSSed5DtO0qM4I2kVP542x9IGqs45p9tvv11r1qzRySef7DtOSuAgJEhqHE8bqB7nnObPn6/+/fvrmGOO8R0nZdA5AwDKNGbMGBUUFFCYY4zOGQDwE4WFhXr//fd10003qUGDBr7jpBw6ZwDAT9x9991q27YthdkTOmcAwEH5+fl6+umnNWzYMNWoQf/mCyMPADjoySef1GmnnUZh9ozOGQCgffv26d5779WIESNkZr7jpLyw3hqZ2XlmttTMlpnZ8FKub2dmH5nZV2Y2z8x+HfmoAIBocM7prbfe0sCBAynMcaLC4mxmNSVNlnS+pK6S+plZ1xKbjZT0vHOuu6S+kh6KdFAAQOTt3btXgwcP1m9+8xu1adPGdxyEhNM5nyRpmXNuhXMuT9Kzki4qsY2TdOAs240krYtcRABANOzdu1fLli3TzTffrFq12MsZT8L5a7SWtKbY5RxJvUpsM0bSu2b2D0n1JZ1V2g2Z2TWSrpGkFi1a/OjITbt27eJITlGUiuObm5srSTF53Kk4vrHC2EbHrl279Mgjj+jyyy/XokWLtGjRIt+Rkk51nrvhFOfSdkC4Epf7SXrSOXevmf1S0lNm1s05V/SjX3IuQ1KGJPXo0cOlp6cfvC4rK0vFLyOyUmF8MzIylJmZefDyqlWrlJaWFpPHnQrj6wtjG3lbt27VmjVr9OSTT+rrr79mfKOkOs/dcKa1cyS1LXa5jX46bX21pOclyTn3uaR6kppVKRFQRcVPdCFxsgugNJs3b9aoUaPUoUMHHX744b7joAzhdM6zJXUys6MkrVWw4KvkK95qSWdKetLMjlNQnDdFMigQDk50AZRtw4YN2rhxo+68806O/BXnKuycnXMFkq6V9I6kxQpWZS80s9vM7MLQZjdK+pOZfS3pGUlXOudKTn0DADzZtm2bxo0bp44dO1KYE0BYy/Occ9MkTSvxs9HFvl8k6X8iGw0AEAmrV6/WunXrdN9996lu3bq+4yAMHJ8NAJLY/v379cADD6h79+4U5gTCB9sQ90quwi5Ldna20tLSYpAISAzffvutli5dqnvuuYcjfyUYOmfEvZKrsMvC6mzgB845vfjiizrvvPMozAmIzhkJgVXYQPgWLFigOXPm6Oabb/YdBVVE5wwASaSoqEhz5szRgAEDfEdBNdA5A0CSmDNnjqZPn67Bgwf7joJqonMGgCSwfft2bd26VYMGDfIdBRFA54y4UN6KbFZhA+X75JNPNGPGDA0fPtx3FEQInTPiQnkrslmFDZRt6dKlatKkiYYNG+Y7CiKIzhlxgxXZQOW8//77mjdvHvuYkxDFGQAS0PTp0/Wzn/1MZ511lu8oiAKmtQEgwWRlZWnRokU64ogjfEdBlNA5A0ACeeWVV5Senq709HTfURBFFGd4UXJ1NiuygYplZ2drx44dOvzww31HQZQxrQ0vSq7OZkU2UL6nnnpKTZs21cCBA31HQQzQOcMbVmcD4Vm9erXq1q2rtm3b+o6CGKFzBoA49vDDD2vbtm36wx/+4DsKYojiDABxatOmTWrXrp1+/vOf+46CGKM4A0AcmjRpkpYuXarzzz/fdxR4wD5nxASrs4HwOOe0du1anXLKKerVq5fvOPCEzhkxwepsoGLOOU2YMEErV66kMKc4OmfEDKuzgbI555Sdna1+/frpqKOO8h0HntE5A0AcuP3221VQUEBhhiQ6ZwDwqqioSNOmTdPgwYNVv35933EQJ+icAcCj++67T+3bt6cw40fonAHAg4KCAj3xxBO68cYbZWa+4yDO0DkjajIyMg6ePaf4Sm0A0tNPP63TTz+dwoxSUZwRNcU/PsVHp4DA/v37ddttt2ngwIHq3Lmz7ziIU0xrI6r4+BTwA+ec3n//fQ0cOJCOGeWicwaAGNizZ48GDRqks88+W+3bt/cdB3GO4gwAUbZ3717Nnz9fw4cPV506dXzHQQKgOANAFO3YsUM33XSTunTpopYtW/qOgwTBPmcAiJJt27Zp9erVuu2229SoUSPfcZBA6JwBIAq2bt2qkSNHqn379mratKnvOEgwdM4AEGGbNm3S2rVrNWHCBDVs2NB3HCQgOmcAiKCdO3dq7Nix6tixI4UZVUbnDAARsnbtWq1cuVL33Xcfq7JRLXTOABABBQUFeuCBB9SjRw8KM6qNzhmSguNgZ2ZmRvQ2s7OzlZaWFtHbBOLRihUr9PXXX+vuu+/2HQVJgs4Zkn58HOxI4XjaSAXOOb300ku64IILfEdBEqFzxkEcBxuonMWLF+uTTz7RkCFDfEdBkqFzBoAqKCws1Jdffqmrr77adxQkITpnAKikr776Su+++66GDRvmOwqSFJ0zAFTCtm3btG3bNqayEVUUZwAI02effabJkyfrjDPOUI0avHwienh2AUAYFi9erMMPP1y33HKL7yhIARRnAKjAxx9/rDfeeENdunSRmfmOgxTAgjAAKMfHH3+sLl266PTTT/cdBSmEzhkAyvDZZ59p/vz5atGihe8oSDF0zgBQitdee02nnHKKTjnlFN9RkIIozkms+PGyc3Nz1bhx4zK35TjYwA8WLVqkzZs3q3nz5r6jIEUxrZ3EKnO8bI6DDQT++9//qm7duhz5C17ROSe5A8fLzsrKUnp6uu84QFzbsGGDatSooWOOOcZ3FKQ4OmcAkPToo49qzZo16tevn+8oAMUZALZu3aojjzxSPXv29B0FkMS0NoAU9+CDD+qEE05Qnz59fEcBDqI4A0hZOTk56tWrl3r16uU7CvAjTGsDSEl33nmnvv32Wwoz4hKdM4CU4pzTl19+qf79+6tdu3a+4wClonMGkFLuuusu5efnU5gR1+icAaSEoqIivf7667r++ut1yCGH+I4DlIvOGUBKmDx5stq3b09hRkKgcwaQ1AoLC/XII4/o2muv5VzMSBgU5yRS/EQXEiezACTpueeeU3p6OoUZCYVp7SRS8kQXnMwCqSwvL09jxoxR37591aVLF99xgEqhc04yB050AaSyoqIiffzxxxo4cKBq1KAHQeLhWQsgqezdu1eDBg1S7969ddRRR/mOA1QJnTOApLFnzx4tXrxYQ4cOZVU2EhqdM4CksHPnTg0ZMkQdOnRQ69atfccBqoXOOcGUXJFdHKuzkaq2b9+uVatWacyYMWratKnvOEC10TknmJIrsotjdTZSUW5urm6++Wa1bdtWzZs39x0HiAg65wTEimwgsHnzZq1evVoTJkxQo0aNfMcBIobOGUBC2rt3r8aMGaNOnTpRmJF06JwBJJz169dr8eLFmjRpkmrXru07DhBxdM4AEkpRUZHuv/9+nXzyyRRmJC06ZwAJY9WqVZo5c6buuusu31GAqAqrczaz88xsqZktM7PhZWzzBzNbZGYLzaz0z/oAQDW8/PLL+t3vfuc7BhB1FXbOZlZT0mRJZ0vKkTTbzKY65xYV26aTpJsl/Y9zbpuZHRGtwABSz9KlS/Xee+9p8ODBvqMAMRFO53ySpGXOuRXOuTxJz0q6qMQ2f5I02Tm3TZKcc99HNiaAVFVYWKi5c+fqL3/5i+8oQMyEU5xbS1pT7HJO6GfFdZbU2cxmmNlMMzsvUgEBpK558+YpMzNT/fr1U61aLJFB6gjn2V7aGcpdKbfTSVK6pDaSPjGzbs653B/dkNk1kq6RpBYtWvzoQBq7du3iwBphyM0NhrSyY8X4RhfjG3nbt2/XypUrddFFFzG2UcRzN3qqM7bhFOccSW2LXW4jaV0p28x0zuVLWmlmSxUU69nFN3LOZUjKkKQePXq49PT0g9dlZWWp+GWUrnHjxpJU6bFifKOL8Y2sWbNm6aOPPtLYsWMZ2yhjfKOnOmMbzrT2bEmdzOwoM6sjqa+kqSW2eVXSryTJzJopmOZeUaVEAFLawoUL1ahRI40ZM8Z3FMCbCouzc65A0rWS3pG0WNLzzrmFZnabmV0Y2uwdSVvMbJGkjyQNcc5tiS4YGcsAAB3RSURBVFZoAMlpxowZmjp1qjp37iyz0vaoAakhrBUWzrlpkqaV+NnoYt87SYNDXwBQadOnT1fnzp11yimnUJiR8jh8JwDv5syZo7lz56ply5YUZkAUZwCevf7662rVqpVuuOEG31GAuEFxBuDN8uXLtX79erVq1cp3FCCuUJwBePHcc89p//79uuaaa3xHAeIOxRlAzG3ZskUFBQXq2rWr7yhAXOJ4eABi6sknn1THjh112WWX+Y4CxC06ZwAxs337djVv3ly9e/f2HQWIa3TOAGLioYceUseOHdWnTx/fUYC4R3EGEHVr1qxRz5491bNnT99RgITAtHYCyMjIUHp6utLT05Wdne07DlAp9957r5YsWUJhBiqB4pwAMjMzDxbltLQ09e/f33MioGLOOX3xxRfq27evzj77bN9xgITCtHaCSEtL45yrSCj33XefTj75ZLVu3dp3FCDhUJwBRJRzTq+88or+/ve/q169er7jAAmJaW0AEZWRkaH27dtTmIFqoHMGEBGFhYV66KGHdO2113JmKaCa6JwBRMTLL7+sM844g8IMRADFGUC15Ofna9SoUbr44ot1/PHH+44DJAWKM4AqKyoq0owZMzRw4EDVqsVeMiBSKM4AqmTfvn0aNGiQfvGLX6hjx46+4wBJhbe6ACpt7969Wrp0qW666SY1aNDAdxwg6dA5A6iU3bt3a8iQIWrVqpXatm3rOw6QlOicAYRt586dWrlypUaNGqUjjjjCdxwgadE5AwjLzp07NXz4cLVq1UotWrTwHQdIanTOACq0detWrVixQuPHj1ejRo18xwGSHp0zgHLl5eVp9OjR6tSpE4UZiBE6ZwBl2rhxo7Kzs3X//ffzOWYghuicAZTKOacHH3xQvXv3pjADMcb/uDiUkZGhzMzMg5ezs7OVlpbmMRFSzZo1a5SVlaU77rjDdxQgJdE5x6HMzExlZ2cfvJyWlqb+/ft7TIRU8+qrr+rSSy/1HQNIWXTOcSotLU1ZWVm+YyDFLF++XFOnTtWgQYN8RwFSGp0zAEnB2aXmzp2ra6+91ncUIOXROQPQwoUL9fzzz2vs2LG+owAQnTOQ8r7//nvl5uZq9OjRvqMACKE4Aynsyy+/1IMPPqhTTjlFNWvW9B0HQAjFGUhRCxYsUIMGDTRu3DiZme84AIqhOAMpaNasWXr11VfVqVMnCjMQhyjOQIr55JNP1KZNG91yyy0UZiBOUZyBFDJv3jzNmjVLrVq1ojADcYziDKSIadOmqVGjRrrxxht9RwFQAYozkALWrFmjVatWqX379r6jAAgDxRlIci+++KK2bNmiv/3tb76jAAgTxRlIYtu3b9fevXs5qxmQYDh8J5CknnrqKbVu3VpXXHGF7ygAKonOGUhCO3bsUNOmTXXGGWf4jgKgCuicgSTz8MMPq02bNurTp4/vKACqiOIMJJHvvvtOPXr00C9+8QvfUQBUA9PaQJJ44IEHtGjRIgozkATonIEE55zTZ599pj/84Q868sgjfccBEAF0zkCCe/DBB1VQUEBhBpIInTOQoJxzeuGFF/SXv/xFdevW9R0HQATROQMJ6oknnlD79u0pzEASonMGEkxRUZEefPBBXX/99ZxZCkhSFOc4kJGRoczMzIOXs7OzOdwiyvTGG2/ojDPOoDADSYxp7TiQmZmp7Ozsg5fT0tLUv39/j4kQjwoKCjRq1Cide+65+tnPfuY7DoAoonOOE2lpacrKyvIdA3GqsLBQs2bN0hVXXME+ZiAF0DkDcS4vL0833XSTjjvuOHXu3Nl3HAAxQOcMxLF9+/bpm2++0Q033KDDDz/cdxwAMULnDMSpPXv2aMiQIWrevLnat2/vOw6AGKJzBuLQ7t27tXz5co0YMYIjfwEpiM4ZiDO7d+/W0KFD1bJlSwozkKLonIE4kpubq6VLl2r8+PFq1KiR7zgAPKFzBuJEQUGBRo8erc6dO1OYgRRH5wzEgU2bNumLL77QpEmTVLNmTd9xAHhG5wx45pzTv/71L6Wnp1OYAUiicwa8Wrt2rd555x2NHTvWdxQAcYTOGfDEOaepU6eqX79+vqMAiDN0zoAHK1eu1HPPPafhw4f7jgIgDtE5AzG2f/9+ZWdna/Dgwb6jAIhTFGcghhYvXqyxY8fq4osvVp06dXzHARCnKM5AjGzYsEHbt2/XuHHjfEcBEOcozkAMZGdn64EHHtBJJ53Ex6UAVIjiDETZggULVL9+fd1xxx2qUYP/cgAqxisFEEVz587Viy++qI4dO1KYAYSNVwsgSmbMmKFmzZrp1ltvlZn5jgMggVCcgShYsmSJPv30U7Vt25bCDKDSKM5AhL377ruqUaOGhg0bRmEGUCVhFWczO8/MlprZMjMr85BGZvZ7M3Nm1iNyEYHEsXHjRi1ZskSdO3f2HQVAAquwOJtZTUmTJZ0vqaukfmbWtZTtGki6TtIXkQ4JJIJXX31Vq1at0nXXXec7CoAEF07nfJKkZc65Fc65PEnPSrqolO3GSbpb0r4I5gMSwt69e7Vjxw716tXLdxQASSCc4txa0ppil3NCPzvIzLpLauuceyOC2YCE8Mwzz2j+/PkaMGCA7ygAkkQ4Z6UqbUWLO3ilWQ1JkyRdWeENmV0j6RpJatGihbKysg5et2vXrh9dTiW5ubmSFNXHn8rjG027d+/Wd999p27dujG+UcJzN7oY3+ipztiGU5xzJLUtdrmNpHXFLjeQ1E1SVmhlaktJU83sQufcnOI35JzLkJQhST169HDp6ekHr8vKylLxy6mkcePGkhTVx5/K4xstjz/+uJo0aaLhw4czvlHE2EYX4xs91RnbcIrzbEmdzOwoSWsl9ZXU/8CVzrntkpoduGxmWZJuKlmYgWSyYsUKnXjiiUpLS/MdBUASqrA4O+cKzOxaSe9IqinpcefcQjO7TdIc59zUaIdMFBkZGcrMzKz072VnZ/Min0AmT56sdu3a6Te/+Y3vKACSVDids5xz0yRNK/Gz0WVsm179WIkpMzOzSoU2LS1N/fv3r3hDePfJJ5/o0ksv1RFHHOE7CoAkFlZxRvjS0tJYXJGk/v3vf+vYY4+lMAOIOoozUAHnnJ599ln98Y9/VO3atX3HAZACOLY2UIHMzEx16NCBwgwgZuicgTIUFRXp/vvv1/XXX6+aNWv6jgMghdA5V1NGRobS09OVnp6u7Oxs33EQQe+++65+9atfUZgBxBzFuZoOrNCWWHWdLAoLCzVy5Eiddtpp6t69u+84AFIQ09oRwArt5FFYWKi5c+fqsssu06GHHuo7DoAURecMhOTn52vIkCFq3769jjvuON9xAKQwOmdA0v79+/Xtt9/q2muv5XPMALyjc0bK27dvn4YMGaLGjRvr6KOP9h0HAOickdr27NmjZcuWafjw4WrVqpXvOAAgic4ZKWzfvn0aOnSojjjiCAozgLhC54yUtGPHDs2fP1/jx49Xw4YNfccBgB+hc0bKKSoq0qhRo9SlSxcKM4C4ROeMlLJlyxZNnz5dkyZNUo0avDcFEJ94dUJKeeihh3TmmWdSmAHENTpnpIQNGzbotdde06hRo3xHAYAK0T4g6Tnn9Prrr+uKK67wHQUAwkLnjKT23XffacqUKXTMABIKnTOS1r59+zRv3jwNHTrUdxQAqBSKM5LSN998o9GjR+uCCy5Q3bp1fccBgEqhOCPprFu3Ttu3b9f48eNlZr7jAEClsc+5kjIyMpSZmXnwcnZ2ttLS0jwmQnHz58/X008/rfHjx6tmzZq+4wBAldA5V1JmZqays7MPXk5LS1P//v09JsIBCxYsUL169TRhwgQKM4CERudcBWlpacrKyvIdA8UsWLBAzz//vMaMGcMBRgAkPF7FkPA+//xz1a9fX2PHjqUwA0gKvJIhoa1YsUIfffSROnTowOIvAEmD4oyE9cEHH2jPnj26+eabKcwAkgrFGQlp69atWrBggbp160ZhBpB0WBCGhPPGG2+oUaNGuv76631HAYCooHNGQtm3b5+2bt2qU0891XcUAIgaOmckjOeff1716tXTgAEDfEcBgKiiOCMh7NixQw0bNtR5553nOwoARB3FGXHv//7v/3TooYfq0ksv9R0FAGKC4oy49u233+rEE0/UCSec4DsKAMQMxbkUJU9uURwnuoidhx9+WC1bttRFF13kOwoAxBTFuRQHTm5RWhHmRBex8dFHH+mSSy5Rs2bNfEcBgJijOJeBk1v48+ijj6pdu3YUZgApi+KMuOGc09NPP60rr7xStWrx1ASQujgICeLGiy++qA4dOlCYAaQ8XgXhnXNO9913n6677jrVrl3bdxwA8I7OGd599NFHOv300ynMABBCcYY3RUVFGjlypHr06KEePXr4jgMAcYNpbXhRWFio+fPnq2/fvmrYsKHvOAAQV+icEXP5+fkaNmyYmjdvrm7duvmOAwBxh84ZMZWXl6dly5bpz3/+s1q3bu07DgDEJTpnxMz+/fs1dOhQHXrooerUqZPvOAAQt+ic9dNjaXP87Mjbu3evvvnmGw0ZMoSOGQAqQOesH46lfQDHz46s/Px8DRkyRM2aNaMwA0AY6JxDOJZ2dOzcuVNz587VhAkT1KBBA99xACAh0DkjapxzGjNmjLp27UphBoBKoHNGVGzbtk3vvfeeJk6cqBo1eA8IAJXBqyaiIiMjQ+eccw6FGQCqIGU75+IrtFmdHTnff/+9nn/+eQ0bNsx3FABIWCnb1hRfoc3q7MhwzunNN9/UVVdd5TsKACS0lO2cJVZoR1JOTo4yMjJ02223+Y4CAAkvZTtnRM7evXu1YMECjRgxwncUAEgKFGdUy/Lly3XLLbfo3HPPVb169XzHAYCkQHFGleXk5Gj79u266667ZGa+4wBA0kiZ4pyRkaH09PSDX8UP14nKW7x4sR588EH97Gc/U+3atX3HAYCkkjLFmeNnR87ChQtVq1YtTZgwQbVqpfSaQgCIipR6ZWV1dvUtWbJEmZmZGjduHAcYAYAo4dUVYZs1a5Zq1qyp22+/ncIMAFHEKyzCkpOTo7ffflsdO3Zk8RcARFlKTWujaj7++GM1aNBAo0aNojADQAzQOaNcO3fu1FdffaXu3btTmAEgRhK+cy5+AovycHKLynvrrbdUu3Zt3XDDDb6jAEBKSfjOueRHpMrCR6cqJy8vT5s2bdJZZ53lOwoApJyE75wlPiIVaS+//LKKioo0YMAA31EAICUlRXFG5Gzfvl2HHXaYzjnnHN9RACBlUZxx0NNPP60aNWow/Q8AnlGcISk48teJJ56orl27+o4CACkv4ReEofoee+wxLVy4kMIMAHGCzjnFffDBB7r44ovVpEkT31EAACF0zilsypQp2r9/P4UZAOIMnXOKmjJlivr3788pHwEgDtE5p6CpU6eqXbt2FGYAiFNhFWczO8/MlprZMjMbXsr1g81skZnNM7MPzKx95KOiupxzuvfee3XuuecqPT3ddxwAQBkqLM5mVlPSZEnnS+oqqZ+ZlVzW+5WkHs65n0l6UdLdkQ6K6psxY4Z69+6tunXr+o4CAChHOJ3zSZKWOedWOOfyJD0r6aLiGzjnPnLO7QldnCmpTWRjojqKior0+OOP67jjjlOvXr18xwEAVCCcnY6tJa0pdjlHUnmv8FdLequ0K8zsGknXSFKLFi1+dDzsXbt2Ven42Lm5uZLEsbXLUFhYqNWrV6tnz56aP3++7zhJq6rPX1SMsY0uxjd6qjO24RTn0k7i60rd0OxyST0knV7a9c65DEkZktSjRw9XfL9nVlZWlfaDNm7cWJLYh1qKgoICjRgxQn//+9+1cuVKxiiKqvr8RcUY2+hifKOnOmMbzrR2jqS2xS63kbSu5EZmdpakWyRd6JzbX6U0iJj8/HwtW7ZMV199tdq3Z30eACSScIrzbEmdzOwoM6sjqa+kqcU3MLPukh5WUJi/j3xMVEZeXp6GDh2q2rVr69hjj/UdBwBQSRVOazvnCszsWknvSKop6XHn3EIzu03SHOfcVEkTJR0m6QUzk6TVzrkLo5gbZdi3b5+WLFmim266Sa1bt/YdBwBQBWEdhcI5N03StBI/G13s+7MinAtVUFhYqKFDh2rIkCEUZgBIYBwiKkns3r1bM2fO1IQJE1S/fn3fcQAA1cDhO5PEbbfdpm7dulGYASAJ0DknuNzcXL355pu68847FdrfDwBIcHTOCe6xxx7T+eefT2EGgCRC55ygNm/erClTpujGG2/0HQUAEGF0zgnIOae3335bf/rTn3xHAQBEAcU5waxbt04jRozQ5ZdfrgYNGviOAwCIAopzAtm9e7cWLVqk0aNHV7wxACBhUZwTxKpVqzRixAidccYZOuSQQ3zHAQBEEcU5AeTk5Cg3N1cTJ05UjRr8yQAg2fFKH+e++eYbTZo0Sccff7zq1KnjOw4AIAYoznFs0aJFkqS77rpLtWvX9pwGABArFOc4tXz5ck2ZMkXHHHOMatXi4+gAkEooznHoyy+/1P79+zV+/HjVrFnTdxwAQIxRnOPM999/r9dff13HHXcci78AIEUxXxpHPv30U9WqVUtjxozxHQUA4BGtWZzYu3evZs+erV69evmOAgDwLCE654yMDGVmZpZ6XXZ2ttLS0mKcKLLee+895eXladCgQb6jAADiQEJ0zpmZmcrOzi71urS0NPXv3z/GiSInPz9fGzduVJ8+fXxHAQDEiYTonKWgCGdlZfmOEVFTp07Vrl27dPnll/uOAgCIIwlTnJPNtm3bVL9+fV144YW+owAA4gzF2YNnn31WeXl5GjBggO8oAIA4RHGOsYULF6p79+469thjfUcBAMSphFgQliymTJmihQsXUpgBAOWic46Rd999VxdddJEaNWrkOwoAIM7ROcfAs88+q/3791OYAQBhoXOOsieffFKXXXYZp3wEAISNzjmK3n77bbVp04bCDACoFDrnKHDO6d5779Vf//pX1a9f33ccAECCoXOOMOecZs+erV/+8pcUZgBAlVCcI6ioqEi33nqr2rVrp//5n//xHQcAkKAozhFSVFSkb775Rr/97W/VsmVL33EAAAmM4hwBhYWFuvnmm1WrVi2deOKJvuMAABIcC8KqqaCgQMuXL9dVV12ljh07+o4DAEgCdM7VkJ+fr6FDh8rM1KVLF99xAABJgs65ivbv36+FCxfqxhtvVOvWrX3HAQAkETrnKigqKtKwYcPUtGlTCjMAIOLonCtpz549mj59uiZMmKBDDjnEdxwAQBKic66kO+64Qz//+c8pzACAqKFzDtOOHTv0yiuv6Pbbb5eZ+Y4DAEhidM5heuKJJ9SnTx8KMwAg6uKyc87IyFBmZubBy9nZ2UpLS/OSZevWrXr00Uc1dOhQL/cPAEg9cdk5Z2ZmKjs7++DltLQ09e/fP+Y5ioqK9N577+nPf/5zzO8bAJC64rJzloKCnJWV5e3+N2zYoHvvvVd33303U9kAgJiKy87Zt507d2rJkiUaM2YMhRkAEHMU5xJWr16tESNGqHfv3pyPGQDgBcW5mDVr1ig3N1f33HOPatWK2xl/AECSoziHLF++XJMmTVKXLl1Ut25d33EAACmM9lDSkiVLJEl33XWXateu7TkNACDVpXznvHr1aj3xxBPq1KkThRkAEBdSunPOzs5WjRo1NGHCBNWokfLvUwAAcSJlK1Jubq5eeeUVdevWjcIMAIgrKdk5z5w5U3l5eRo7dqzvKAAA/ETKtYx5eXn6/PPPdeqpp/qOAgBAqVKqc/7www+Vm5urQYMG+Y4CAECZUqZzzs/P1/r16/W73/3OdxQAAMqVEp3zm2++qU2bNunKK6/0HQUAgAolfXHevHmz6tevrz59+viOAgBAWJK6OL/wwgvauXOn/vd//9d3FAAAwpa0xXnevHnq3r27Onbs6DsKAACVkpQLwp555hnNnz+fwgwASEhJ1zm/9dZb6tOnjxo2bOg7CgAAVZJUxfmll15SjRo1KMwAgISWNMX5ySefVL9+/TgXMwAg4SXFPucPP/xQLVu2pDADAJJCQnfOzjndd999+uMf/6hGjRr5jgMAQEQkbOfsnNO8efPUs2dPCjMAIKkkZHF2zmncuHE6/PDDddppp/mOAwBARCXctHZRUZFWrFih888/X+3atfMdBwCAiEuozrmoqEgjR45Ufn6+evbs6TsOAABRkTCdc2FhoZYvX67LL79cxx13nO84AABETUJ0zgUFBRo2bJgKCwvVtWtX33EAAIiquO+c8/Pz9fXXX+vGG2/UkUce6TsOAABRF9eds3NOw4cPV5MmTSjMAICUEbedc1FRkd58803dcccdqlevnu84AADETNx2zqtXr1b37t0pzACAlBNWcTaz88xsqZktM7PhpVxf18yeC13/hZl1qGqgXbt2af369Wrfvr1at25d1ZsBACBhVViczaympMmSzpfUVVI/Myu5ZPpqSduccx0lTZJ0V1UDPfXUU2ratKnMrKo3AQBAQguncz5J0jLn3ArnXJ6kZyVdVGKbiyT9X+j7FyWdaZWsrjt37tQdd9yhv/71r6pTp05lfhUAgKQSzoKw1pLWFLucI6lXWds45wrMbLukppI2hxPihhtu0Kuvvqo2bdrovffeU3Z2ttLS0sL5VQAAkk44xbm0DthVYRuZ2TWSrpGkFi1aKCsrS5KUk5OjBg0aaNeuXZKkDh066Be/+MXB61F9u3btYjyjiPGNHsY2uhjf6KnO2IZTnHMktS12uY2kdWVsk2NmtSQ1krS15A055zIkZUhSjx49XHp6uiQpPT1dWVlZOnAZkcf4RhfjGz2MbXQxvtFTnbENZ5/zbEmdzOwoM6sjqa+kqSW2mSppYOj730v60Dn3k84ZAABUrMLOObQP+VpJ70iqKelx59xCM7tN0hzn3FRJj0l6ysyWKeiY+0YzNAAAycx8NbhmtknSd8V+1ExhLiBDlTC+0cX4Rg9jG12Mb/SUHNv2zrnm4fyit+JckpnNcc718J0jWTG+0cX4Rg9jG12Mb/RUZ2zj9vCdAACkKoozAABxJp6Kc4bvAEmO8Y0uxjd6GNvoYnyjp8pjGzf7nAEAQCCeOmcAACAPxTmWp59MRWGM72AzW2Rm88zsAzNr7yNnIqpobItt93szc2bGCthKCGd8zewPoefvQjPLjHXGRBXG60I7M/vIzL4KvTb82kfORGRmj5vZ92a2oIzrzcweDI39PDM7Mawbds7F7EvBQUyWSzpaUh1JX0vqWmKbv0n6T+j7vpKei2XGRP4Kc3x/JenQ0Pd/ZXwjN7ah7RpImi5ppqQevnMnyleYz91Okr6SdHjo8hG+cyfCV5hjmyHpr6Hvu0pa5Tt3onxJOk3SiZIWlHH9ryW9peAcFCdL+iKc24115xyT00+msArH1zn3kXNuT+jiTAXHSkfFwnnuStI4SXdL2hfLcEkgnPH9k6TJzrltkuSc+z7GGRNVOGPrJDUMfd9IPz1/AsrgnJuuUs4lUcxFkqa4wExJjc3syIpuN9bFubTTT7YuaxvnXIGkA6efRMXCGd/irlbwjg4Vq3Bszay7pLbOuTdiGSxJhPPc7Syps5nNMLOZZnZezNIltnDGdoyky80sR9I0Sf+ITbSUUNnXZUnhnZUqkiJ2+kmUKuyxM7PLJfWQdHpUEyWPcsfWzGpImiTpylgFSjLhPHdrKZjaTlcw4/OJmXVzzuVGOVuiC2ds+0l60jl3r5n9UsG5Ero554qiHy/pVammxbpzrszpJ1Xe6SdRqnDGV2Z2lqRbJF3onNsfo2yJrqKxbSCpm6QsM1ulYN/SVBaFhS3c14bXnHP5zrmVkpYqKNYoXzhje7Wk5yXJOfe5pHoKjguN6gvrdbmkWBdnTj8ZXRWOb2jq9WEFhZl9duErd2ydc9udc82ccx2ccx0U7M+/0Dk3x0/chBPOa8OrChY0ysyaKZjmXhHTlIkpnLFdLelMSTKz4xQU500xTZm8pkoaEFq1fbKk7c659RX9UkyntR2nn4yqMMd3oqTDJL0QWme32jl3obfQCSLMsUUVhTm+70g6x8wWSSqUNMQ5t8Vf6sQQ5tjeKOkRMxukYMr1Spqi8JjZMwp2tTQL7bO/VVJtSXLO/UfBPvxfS1omaY+kq8K6XcYfAID4whHCAACIMxRnAADiDMUZAIA4Q3EGACDOUJwBAIgzFGcAAOIMxRkAgDhDcQYAIM78fxauU3vcWee8AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_class_nn_2 = model_2.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
